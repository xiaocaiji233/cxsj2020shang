import nltk_fun
# import devide_issues
from pprint import pprint


def singlebody_process(piece: dict, key: str):
    a = nltk_fun.splitSentence(str(piece[key]))
    a = nltk_fun.p2w(a)
    for i in a:
        if len(i) < 3:
            a.remove(i)
    piece[key] = a
    # pprint(piece)
    return piece[key]


def bodies_process(pieces: dict):
    times = pieces.keys()
    # pprint(times)
    for i in times:
        bodies = []
        for j in pieces[i]:
            bodies += singlebody_process(j, 'body')
        # pprint(bodies)
        pieces[i] = bodies
    return pieces


if __name__ == '__main__':
    # piece = {'body': 'This commit mostly either enables or disables '
    #                  'unittests on the ROCM platform, details listed '
    #                  'below\r\n'
    #                  '* adding/removing no_rocm tag for tests in the '
    #                  '//tensorflow/compiler/mlir dir\r\n'
    #                  '* enabling / disabling subtests within '
    #                  '//tensorflow/core/grappler/optimizers:constant_folding_test '
    #                  'for the ROCm platform\r\n'
    #                  '* disabling a subtest within '
    #                  '//tensorflow/core/distributed_runtime:collective_param_resolver_distributed_test '
    #                  'fir the ROCm platform\r\n'
    #                  '* adding no_rocm tag to tests that are failing on the '
    #                  'ROCm platform\r\n'
    #                  '* minor bug fix to ensure that the '
    #                  '//tensorflow/compiler/mlir/tensorflow:error_util_test '
    #                  'passes on a consistent basis\r\n'
    #                  '\r\n'
    #                  '-----------------------\r\n'
    #                  '\r\n'
    #                  '/cc @whchung @chsigg ',
    #          'created_at': '2019-12-3'}
    # pprint(singlebody_process(piece, 'body'))
    test = {'2020-01-0': [{'body': 'This commit mostly either enables or disables '
                                   'unittests on the ROCM platform, details listed '
                                   'below\r\n'
                                   '* adding/removing no_rocm tag for tests in the '
                                   '//tensorflow/compiler/mlir dir\r\n'
                                   '* enabling / disabling subtests within '
                                   '//tensorflow/core/grappler/optimizers:constant_folding_test '
                                   'for the ROCm platform\r\n'
                                   '* disabling a subtest within '
                                   '//tensorflow/core/distributed_runtime:collective_param_resolver_distributed_test '
                                   'fir the ROCm platform\r\n'
                                   '* adding no_rocm tag to tests that are failing on the '
                                   'ROCm platform\r\n'
                                   '* minor bug fix to ensure that the '
                                   '//tensorflow/compiler/mlir/tensorflow:error_util_test '
                                   'passes on a consistent basis\r\n'
                                   '\r\n'
                                   '-----------------------\r\n'
                                   '\r\n'
                                   '/cc @whchung @chsigg ',
                           'created_at': '2019-12-3'},
                          {'body': '<em>Please make sure that this is a bug. As per our '
                                   '[GitHub '
                                   'Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), '
                                   'we only address code/doc bugs, performance issues, '
                                   'feature requests and build/installation issues on '
                                   'GitHub. tag:bug_template</em>\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): No\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): iPAD OS 13.2.2\r\n'
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device: iPAD '
                                   'Pro 2018\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'Binary (TfLiteGPUExperimental)\r\n'
                                   '- TensorFlow version (use command below):\r\n'
                                   '- Python version: NA\r\n'
                                   '- Bazel version (if compiling from source): NA\r\n'
                                   '- GCC/Compiler version (if compiling from source): '
                                   'NA\r\n'
                                   '- CUDA/cuDNN version: NA\r\n'
                                   '- GPU model and memory: iPAD GPU\r\n'
                                   '\r\n'
                                   'You can collect some of this information using our '
                                   'environment capture\r\n'
                                   '[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\n'
                                   'You can also obtain the TensorFlow version with: 1. '
                                   'TF 1.0: `python -c "import\r\n'
                                   'tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"` '
                                   '2. TF 2.0: `python -c\r\n'
                                   '"import tensorflow as tf; '
                                   'print(tf.version.GIT_VERSION, '
                                   'tf.version.VERSION)"`\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'When running the model on iPAD using CPU, we are able '
                                   'to get the output. But when doing GPU delegate, we '
                                   'get the error the following error:\r\n'
                                   '_failed assertion `Cannot create a buffer of zero '
                                   'length._\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   'No error\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   'Provide a reproducible test case that is the bare '
                                   'minimum necessary to generate the problem.\r\n'
                                   'delegate = NewGpuDelegate(nullptr);\r\n'
                                   '      '
                                   'interpreter->ModifyGraphWithDelegate(delegate);\r\n'
                                   '\r\n'
                                   '**Other info / logs**\r\n'
                                   'Include any logs or source code that would be helpful '
                                   'to diagnose the problem. If including tracebacks, '
                                   'please include the full traceback. Large logs and '
                                   'files should be attached.\r\n',
                           'created_at': '2019-12-3'},
                          {'body': 'hi, I find some bug. Code is\r\n'
                                   '\r\n'
                                   'import tensorflow as tf\r\n'
                                   '\r\n'
                                   '\r\n'
                                   "if __name__ == '__main__':\r\n"
                                   '    def Gen():\r\n'
                                   '        for i in range(10):\r\n'
                                   '            yield(i,2,3,4,5,6,7,8)\r\n'
                                   '\r\n'
                                   '    dataset = tf.data.Dataset.from_generator(Gen, '
                                   'output_types=(tf.float32,tf.float32,tf.int32,tf.int32,tf.int32,tf.float32,tf.int32,tf.int32),output_shapes=None,args=None)\r\n'
                                   '    for one_batch in dataset:\r\n'
                                   "        print('one batch',one_batch)\r\n"
                                   '\r\n'
                                   '    print("******end**********")\r\n'
                                   '\r\n'
                                   '    num_gpu=1\r\n'
                                   "    devices = ['/device:GPU:{}'.format(i) for i in "
                                   'range(num_gpu)]\r\n'
                                   '    strategy = '
                                   'tf.distribute.MirroredStrategy(devices)\r\n'
                                   '\r\n'
                                   '    input_context = '
                                   'tf.distribute.InputContext(num_input_pipelines=1,\r\n'
                                   '            input_pipeline_id=0,\r\n'
                                   '            num_replicas_in_sync=1)\r\n'
                                   '\r\n'
                                   '    with strategy.scope():\r\n'
                                   '        def dataset_fn(input_context):\r\n'
                                   '            dataset = '
                                   'tf.data.Dataset.from_generator(Gen, '
                                   'output_types=(tf.float32,tf.float32,tf.int32,tf.int32,tf.int32,tf.float32,tf.int32,tf.int32),output_shapes=None,args=None)\r\n'
                                   '            return dataset.shard(\r\n'
                                   '                    '
                                   'input_context.num_input_pipelines, '
                                   'input_context.input_pipeline_id)\r\n'
                                   '\r\n'
                                   '        train_dist_dataset = '
                                   'strategy.experimental_distribute_datasets_from_function(dataset_fn)\r\n'
                                   '\r\n'
                                   '        for one_batch  in train_dist_dataset:\r\n'
                                   "            print('****one "
                                   "batch*******',one_batch)\r\n"
                                   '\r\n'
                                   'The code can be run, but in distribut "for one_batch  '
                                   'in train_dist_dataset:" at the end batch will be '
                                   'error.\r\n'
                                   'Traceback (most recent call last):\r\n'
                                   '  File "/usr/local/python35/lib/python3.5/pdb.py", '
                                   'line 1665, in main\r\n'
                                   '    pdb._runscript(mainpyfile)\r\n'
                                   '  File "/usr/local/python35/lib/python3.5/pdb.py", '
                                   'line 1546, in _runscript\r\n'
                                   '    self.run(statement)\r\n'
                                   '  File "/usr/local/python35/lib/python3.5/bdb.py", '
                                   'line 431, in run\r\n'
                                   '    exec(cmd, globals, locals)\r\n'
                                   '  File "<string>", line 1, in <module>\r\n'
                                   '  File '
                                   '"/search/speech/hubo/git/tf-code-acoustics/tf2.0-model/io_test.py", '
                                   'line 45, in <module>\r\n'
                                   '    for one_batch  in train_dist_dataset:\r\n'
                                   '  File '
                                   '"/usr/local/python35/lib/python3.5/site-packages/tensorflow_core/python/distribute/input_lib.py", '
                                   'line 275, in __next__\r\n'
                                   '    return self.get_next()\r\n'
                                   '  File '
                                   '"/usr/local/python35/lib/python3.5/site-packages/tensorflow_core/python/distribute/input_lib.py", '
                                   'line 304, in get_next\r\n'
                                   '    global_has_value, replicas = '
                                   '_get_next_as_optional(self, self._strategy)\r\n'
                                   '  File '
                                   '"/usr/local/python35/lib/python3.5/site-packages/tensorflow_core/python/distribute/input_lib.py", '
                                   'line 200, in _get_next_as_optional\r\n'
                                   '    '
                                   'iterator._iterators[i].get_next_as_list(new_name))  # '
                                   'pylint: disable=protected-access\r\n'
                                   '  File '
                                   '"/usr/local/python35/lib/python3.5/site-packages/tensorflow_core/python/distribute/input_lib.py", '
                                   'line 878, in get_next_as_list\r\n'
                                   '    lambda: '
                                   '_dummy_tensor_fn(data.value_structure))\r\n'
                                   '  File '
                                   '"/usr/local/python35/lib/python3.5/site-packages/tensorflow_core/python/util/deprecation.py", '
                                   'line 507, in new_func\r\n'
                                   '    return func(*args, **kwargs)\r\n'
                                   '  File '
                                   '"/usr/local/python35/lib/python3.5/site-packages/tensorflow_core/python/ops/control_flow_ops.py", '
                                   'line 1204, in cond\r\n'
                                   '    result = false_fn()\r\n'
                                   '  File '
                                   '"/usr/local/python35/lib/python3.5/site-packages/tensorflow_core/python/distribute/input_lib.py", '
                                   'line 878, in <lambda>\r\n'
                                   '    lambda: '
                                   '_dummy_tensor_fn(data.value_structure))\r\n'
                                   '  File '
                                   '"/usr/local/python35/lib/python3.5/site-packages/tensorflow_core/python/distribute/input_lib.py", '
                                   'line 801, in _dummy_tensor_fn\r\n'
                                   '    result.append(create_dummy_tensor(feature_shape, '
                                   'feature_type))\r\n'
                                   '  File '
                                   '"/usr/local/python35/lib/python3.5/site-packages/tensorflow_core/python/distribute/input_lib.py", '
                                   'line 784, in create_dummy_tensor\r\n'
                                   '    for dim in feature_shape.dims:\r\n'
                                   "TypeError: 'NoneType' object is not iterable\r\n"
                                   'Uncaught exception. Entering post mortem debugging\r\n'
                                   "Running 'cont' or 'step' will restart the program\r\n"
                                   '\r\n'
                                   'I want to know why.',
                           'created_at': '2019-12-3'},
                          {'body': 'Getting below exception while following '
                                   '"https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android"\r\n'
                                   '\r\n'
                                   '\r\n'
                                   'org.gradle.api.InvalidUserDataException: Cannot '
                                   'expand TAR '
                                   "'D:\\WorkSpaces\\ML_WorkSpace\\TF_Android\\app\\build\\intermediates\\mobilenet_v1_1.0_224.tgz'.\r\n"
                                   '\tat '
                                   'org.gradle.api.internal.file.archive.TarFileTree.cannotExpand(TarFileTree.java:133)\r\n'
                                   '\t... 56 more\r\n'
                                   'Caused by: '
                                   'org.gradle.api.resources.ResourceException: Could not '
                                   'read '
                                   'D:\\WorkSpaces\\TF_Android\\app\\build\\intermediates\\mobilenet_v1_1.0_224.tgz.\r\n'
                                   '\tat '
                                   'org.gradle.internal.resource.ResourceExceptions.readFailed(ResourceExceptions.java:36)\r\n'
                                   '\tat '
                                   'org.gradle.api.internal.file.archive.compression.GzipArchiver.read(GzipArchiver.java:64)\r\n'
                                   '\tat '
                                   'org.gradle.api.internal.file.MaybeCompressedFileResource.read(MaybeCompressedFileResource.java:55)\r\n'
                                   '\tat '
                                   'org.gradle.api.internal.file.archive.TarFileTree.visit(TarFileTree.java:78)\r\n'
                                   '\t... 107 more\r\n'
                                   'Caused by: java.util.zip.ZipException: Not in GZIP '
                                   'format\r\n'
                                   '\tat '
                                   'java.util.zip.GZIPInputStream.readHeader(GZIPInputStream.java:165)\r\n'
                                   '\tat '
                                   'org.gradle.api.internal.file.archive.compression.GzipArchiver.read(GzipArchiver.java:61)\r\n'
                                   '\t... 109 more\r\n'
                                   '\r\n'
                                   "**Don't know, what could be the problem?**",
                           'created_at': '2019-12-3'},
                          {'body': '**System information**\r\n'
                                   'The bugs are not related to my system informations. '
                                   'They are caused by a bad coding style in the '
                                   'https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/non_max_suppression_op.cu.cc '
                                   'and '
                                   'https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/non_max_suppression_op.cc. '
                                   'Just to be sure those bugs could be easily reproduced '
                                   'on google colab. \r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'I ll mention two major bugs.\r\n'
                                   'The first one is a garbage output when the boxes '
                                   'coordinates are not logical. In fact given a '
                                   'box(y1,x1,y2,x2)  coordinates with y1 = y2 or x1 = x2 '
                                   '(the coordinates of a line) or even worst the '
                                   'coordinates of a point ( x1 = x2 = y1 = y2) the '
                                   'algorithme will only output the line when reaching '
                                   'it. \r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   'Here is the code to reproduce the behaviour on google '
                                   'colab: \r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'import numpy as np\r\n'
                                   '%tensorflow_version 2.x\r\n'
                                   'import tensorflow as tf\r\n'
                                   'tf.__version__\r\n'
                                   'boxes = np.array([[0.1,0.1,0.2,0.2], '
                                   '[0.3,0.3,0.3,0.4], [0.5,0.5,0.6,0.6], '
                                   '[0.7,0.7,0.8,0.8]], dtype= np.float32)\r\n'
                                   'scores = np.array([0.9,0.8,0.7,0.6], dtype = '
                                   'np.float32)\r\n'
                                   '(tf.image.non_max_suppression(boxes, scores, 8))\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'output:\r\n'
                                   '```\r\n'
                                   "'2.1.0-rc1'\r\n"
                                   '<tf.Tensor: shape=(8,), dtype=int32, numpy=array([0, '
                                   '1, 1, 1, 1, 1, 1, 1], dtype=int32)>\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'Now I ll explain brievely how the algorithm is coded '
                                   'in tensorflow. Given a list of candidate boxes '
                                   'containing in the beginning all the user boxes and a '
                                   'list of chosen boxes empty, if the box is chosen it '
                                   'will not immediately delete it from the candidate '
                                   'box. In fact, this box will be again processed as a '
                                   'candidate box in the next iteration. But because it '
                                   'is already in the chosen boxes it wont be chosen '
                                   'again . The reason for that is that the IOU of a box '
                                   'with himself is 1 which is always above the '
                                   'threshold. Unfortunately, the IOU of a line or a '
                                   'point with any box is 0. This is applied even when '
                                   'the IOU is calculated of the line with iteself. This '
                                   'will result in adding the line to the chosen boxes '
                                   'again and again. This behaviour is mentioned in this '
                                   "issue but wasn't clearly explained. "
                                   'https://github.com/tensorflow/tensorflow/issues/29628\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   'The expected behaviour must be decided by the '
                                   'tensorflow programer. He can chose between putting it '
                                   'only once in the result : \r\n'
                                   '-<tf.Tensor: shape=(8,), dtype=int32, numpy=array([0, '
                                   '1, 2, 3], dtype=int32)> \r\n'
                                   'or deleting the line box\r\n'
                                   ' -<tf.Tensor: shape=(8,), dtype=int32, '
                                   'numpy=array([0, 2, 3], dtype=int32)>\r\n'
                                   '\r\n'
                                   '- The second bug is really inexplainable. Why there '
                                   'is only the gpu specialisation of '
                                   'non_max_suppression_v2 ? Did the developer forgot '
                                   'about it? This was mentioned in several issues under '
                                   'the name : non max suppression work only on cpu. This '
                                   'is completely understandable because the default '
                                   'version of non_max_suppression is v3 which dosent '
                                   'have a gpu specialisation. \r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   'on colab u can just copy this code:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'import numpy as np\r\n'
                                   '%tensorflow_version 2.x\r\n'
                                   'import tensorflow as tf\r\n'
                                   'tf.debugging.set_log_device_placement(True)\r\n'
                                   'boxes = np.array([[0.1,0.1,0.2,0.2], '
                                   '[0.3,0.3,0.3,0.4], [0.5,0.5,0.6,0.6], '
                                   '[0.7,0.7,0.8,0.8]], dtype= np.float32)\r\n'
                                   'scores = np.array([0.9,0.8,0.7,0.6], dtype = '
                                   'np.float32)\r\n'
                                   "with tf.device('/GPU:0'):\r\n"
                                   '  print(tf.image.non_max_suppression(boxes, scores, '
                                   '8))\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'output:\r\n'
                                   '\r\n'
                                   '> Executing op NonMaxSuppressionV3 in device '
                                   '/job:localhost/replica:0/task:0/device:CPU:0\r\n'
                                   '> tf.Tensor([0 1 1 1 1 1 1 1], shape=(8,), '
                                   'dtype=int32)\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   '\r\n'
                                   '> Executing op NonMaxSuppressionV3 in device '
                                   '/job:localhost/replica:0/task:0/device:GPU:0\r\n'
                                   '\r\n'
                                   'Correcting this issue is quite simple and '
                                   'straightforward. Gpu specialisation must be made for '
                                   'non_max_suppression_v3 at least.',
                           'created_at': '2019-12-2'},
                          {'body': '<em>Please make sure that this is a '
                                   'build/installation issue. As per our [GitHub '
                                   'Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), '
                                   'we only address code/doc bugs, performance issues, '
                                   'feature requests and build/installation issues on '
                                   'GitHub. tag:build_template</em>\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Raspberry pi 4\r\n'
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device: No\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'binary in pip\r\n'
                                   '- TensorFlow version: 1.14\r\n'
                                   '- Python version: 3.7\r\n'
                                   '- Installed using  pip\r\n'
                                   '- Bazel version (if compiling from source): No\r\n'
                                   '- GCC/Compiler version (if compiling from source): '
                                   'No\r\n'
                                   '- CUDA/cuDNN version: No\r\n'
                                   '- GPU model and memory: No\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Describe the problem**\r\n'
                                   '****\r\n'
                                   'pi@raspberrypi:~/examples/lite/examples/object_detection/raspberry_pi '
                                   '$ python3 detect_picamera.py   --model '
                                   '/tmp/detect.tflite   --labels /tmp/coco_labels.txt\r\n'
                                   '2019-12-28 17:43:12.464130: E '
                                   'tensorflow/core/platform/hadoop/hadoop_file_system.cc:132] '
                                   'HadoopFileSystem load error: libhdfs.so: cannot open '
                                   'shared object file: No such file or directory\r\n'
                                   'Traceback (most recent call last):\r\n'
                                   '  File "detect_picamera.py", line 34, in <module>\r\n'
                                   '    from tf.lite.interpreter import Interpreter\r\n'
                                   "ModuleNotFoundError: No module named 'tf'\r\n"
                                   '***\r\n'
                                   '\r\n'
                                   '**Provide the exact sequence of commands / steps that '
                                   'you executed before running into the problem**\r\n'
                                   '***\r\n'
                                   ' Tensorflow model running issue replaced the code '
                                   'with in original source code\r\n'
                                   '\r\n'
                                   '> from_ tflite_runtime.interpreter import '
                                   'Interpreter\r\n'
                                   '\r\n'
                                   '***\r\n'
                                   '**WIth**\r\n'
                                   '***\r\n'
                                   '> from tf.lite import Interpreter\r\n'
                                   '***\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Any other info / logs**\r\n'
                                   'Include any logs or source code that would be helpful '
                                   'to diagnose the problem. If including tracebacks, '
                                   'please include the full traceback. Large logs and '
                                   'files should be attached.',
                           'created_at': '2019-12-2'},
                          {'body': '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow):\r\n'
                                   'example from '
                                   'https://www.tensorflow.org/tutorials/text/image_captioning\r\n'
                                   '\r\n'
                                   '- OS Platform and Distribution:Linux Ubuntu 18\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'bin\r\n'
                                   '- TensorFlow version (use command below): '
                                   'v2.0.0-rc2-26-g64c3d38 2.0.0 \r\n'
                                   '- Python version: 3.6.8\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   '> tf.saved_model.save(encoder, '
                                   '"./models/1/encoder")\r\n'
                                   '\r\n'
                                   'model get serialized with errors \r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   'encoder can be loaded without errors\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   '- train the model from '
                                   'https://www.tensorflow.org/tutorials/text/image_captioning '
                                   'example \r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'tf.saved_model.save(encoder, "./models/1/encoder")\r\n'
                                   'encoder = '
                                   'tf.saved_model.load("./models/1/encoder")\r\n'
                                   'encoder(img_tensor_val)\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'raises the error > \r\n'
                                   "'_UserObject' object is not callable\r\n"
                                   '\r\n'
                                   '\r\n'
                                   '`encoder.fc(img_tensor_val) \r\n'
                                   '`\r\n'
                                   'ValueError: Could not find matching function to call '
                                   'loaded from the SavedModel. Got:\r\n'
                                   '  Positional arguments (1 total):\r\n'
                                   '    * Tensor("inputs:0", shape=(1, 120, 64), '
                                   'dtype=float32)\r\n'
                                   '  Keyword arguments: {}\r\n'
                                   '\r\n'
                                   'Expected these arguments to match one of the '
                                   'following 0 option(s):\r\n'
                                   '\r\n'
                                   '**Other info / logs**\r\n'
                                   'W1227 00:41:32.831883 139767989909312 '
                                   'save_impl.py:77] Skipping full serialization of Keras '
                                   'model <__main__.CNN_Encoder object at '
                                   '0x7f1daf5354e0>, because its inputs are not '
                                   'defined.\r\n',
                           'created_at': '2019-12-2'},
                          {'body': '**System information**\r\n'
                                   '- Have I written custom code :\r\n'
                                   '```java\r\n'
                                   'private List<Delegate> mDelegates = new '
                                   'ArrayList<>();\r\n'
                                   'mDelegates.add(new GpuDelegate());\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '```java\r\n'
                                   '            Interpreter.Options options = null;\r\n'
                                   '            if (interpreterOptions != null) {\r\n'
                                   '                options = new '
                                   'Interpreter.Options().setNumThreads(interpreterOptions.getNumThreads());\r\n'
                                   '            }\r\n'
                                   '            if (!mDelegates.isEmpty()) {\r\n'
                                   '                Iterator<Delegate> it = '
                                   'mDelegates.iterator();\r\n'
                                   '                while (it.hasNext()) {\r\n'
                                   '                    Delegate delegate = it.next();\r\n'
                                   '                    mLogger.debug("addDelegate: " + '
                                   'delegate);\r\n'
                                   '                    options.addDelegate(delegate);\r\n'
                                   '                }\r\n'
                                   '            }\r\n'
                                   '            mInterpreter = new Interpreter(bb, '
                                   'options);\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '- Mobile device :\r\n'
                                   'MI 8 / MIUI 11.0.4\r\n'
                                   '\r\n'
                                   '- TensorFlow installed from (source or binary):\r\n'
                                   'implementation '
                                   "'org.tensorflow:tensorflow-lite:2.0.0'\r\n"
                                   'implementation '
                                   "'org.tensorflow:tensorflow-lite-gpu:2.0.0'\r\n"
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'crashed when load the attached file with '
                                   "'GpuDelegate'\r\n"
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   'load the attached file correct\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   'N/A\r\n'
                                   '\r\n'
                                   '**Other info / logs**\r\n'
                                   '```text\r\n'
                                   '    java.lang.IllegalStateException: Internal error: '
                                   'Unexpected failure when preparing tensor allocations: '
                                   'TfLiteGpuDelegate Init: FULLY_CONNECTED: Amount of '
                                   'input data should match weights width\r\n'
                                   '    TfLiteGpuDelegate Prepare: delegate is not '
                                   'initialized\r\n'
                                   '    Node number 3 (TfLiteGpuDelegateV2) failed to '
                                   'prepare.\r\n'
                                   '    \r\n'
                                   '    Restored previous execution plan after delegate '
                                   'application failure.\r\n'
                                   '        at '
                                   'org.tensorflow.lite.NativeInterpreterWrapper.allocateTensors(Native '
                                   'Method)\r\n'
                                   '        at '
                                   'org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:162)\r\n'
                                   '        at '
                                   'org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:275)\r\n'
                                   '        at '
                                   'com.didi.aoe.runtime.tensorflow.lite.TensorFlowMultipleInputsOutputsInterpreter.run(TensorFlowMultipleInputsOutputsInterpreter.java:159)\r\n'
                                   '        at '
                                   'com.didi.aoe.library.core.NativeProcessorWrapper.run(NativeProcessorWrapper.java:40)\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '[mnist_cnn_keras.tflite.zip](https://github.com/tensorflow/tensorflow/files/4004963/mnist_cnn_keras.tflite.zip)\r\n',
                           'created_at': '2019-12-2'},
                          {'body': '<em>Please make sure that this is a '
                                   'build/installation issue. As per our [GitHub '
                                   'Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), '
                                   'we only address code/doc bugs, performance issues, '
                                   'feature requests and build/installation issues on '
                                   'GitHub. tag:build_template</em>\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Ubuntu 19.0\r\n'
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device:\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'Source\r\n'
                                   '- TensorFlow version: 2.0\r\n'
                                   '- Python version: 3.7.4\r\n'
                                   '- Installed using virtualenv? pip? conda?: pip\r\n'
                                   '- Bazel version (if compiling from source): 1.1.0\r\n'
                                   '- GCC/Compiler version (if compiling from source): '
                                   '8.3.0\r\n'
                                   '- CUDA/cuDNN version: n/a\r\n'
                                   '- GPU model and memory: n/a\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Describe the problem**\r\n'
                                   '\r\n'
                                   '**Provide the exact sequence of commands / steps that '
                                   'you executed before running into the problem**\r\n'
                                   'After about 20+ minutes of watching the code build '
                                   'the build stopped abruptly\r\n'
                                   '\r\n'
                                   '**Any other info / logs**\r\n'
                                   'Here is a link to an enviorment where you can run my '
                                   'exact dev-env in the cloud\r\n'
                                   'https://gitpod.io/#https://github.com/JesterOrNot/tensorflow/tree/JesterOrNot/gitpod-setup\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   './tensorflow/python/lib/core/pybind11_proto.h:40:44: '
                                   "warning: 'pybind11::str "
                                   'pybind11::detail::object_api<Derived>::str() const '
                                   '[wi\r\n'
                                   "th Derived = pybind11::handle]' is deprecated: Use "
                                   'py::str(obj) instead [-Wdeprecated-declarations]\r\n'
                                   '       std::string(py_object.get_type().str()), " is '
                                   'not a valid proto."));\r\n'
                                   '                                            ^\r\n'
                                   'In file included from '
                                   'external/pybind11/include/pybind11/cast.h:13,\r\n'
                                   '                 from '
                                   'external/pybind11/include/pybind11/attr.h:13,\r\n'
                                   '                 from '
                                   'external/pybind11/include/pybind11/pybind11.h:49,\r\n'
                                   '                 from '
                                   'tensorflow/python/client/device_lib_wrapper.cc:18:\r\n'
                                   'external/pybind11/include/pybind11/pytypes.h:147:19: '
                                   'note: declared here\r\n'
                                   '     pybind11::str str() const;\r\n'
                                   '                   ^~~\r\n'
                                   'INFO: From Compiling '
                                   'tensorflow/stream_executor/stream_executor_pimpl.cc '
                                   '[for host]:\r\n'
                                   'tensorflow/stream_executor/stream_executor_pimpl.cc: '
                                   "In member function 'stream_executor::DeviceMemoryBase "
                                   'stream_executor::StreamE\r\n'
                                   'xecutor::Allocate(tensorflow::uint64, '
                                   "tensorflow::int64)':\r\n"
                                   'tensorflow/stream_executor/stream_executor_pimpl.cc:462:31: '
                                   'warning: comparison of integer expressions of '
                                   "different signedness: 'lo\r\n"
                                   "ng long unsigned int' and 'tensorflow::int64' {aka "
                                   "'long long int'} [-Wsign-compare]\r\n"
                                   '       mem_alloc_bytes_ + size > memory_limit_bytes_) '
                                   '{\r\n'
                                   '       '
                                   '~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~\r\n'
                                   'In file included from '
                                   './tensorflow/core/platform/default/logging.h:29,\r\n'
                                   '                 from '
                                   './tensorflow/core/platform/logging.h:27,\r\n'
                                   '                 from '
                                   './tensorflow/core/platform/status.h:24,\r\n'
                                   '                 from '
                                   './tensorflow/core/platform/errors.h:22,\r\n'
                                   '                 from '
                                   './tensorflow/core/lib/core/errors.h:19,\r\n'
                                   '                 from '
                                   './tensorflow/stream_executor/device_memory_allocator.h:23,\r\n'
                                   '                 from '
                                   './tensorflow/stream_executor/stream_executor_pimpl.h:28,\r\n'
                                   '                 from '
                                   'tensorflow/stream_executor/stream_executor_pimpl.cc:20:\r\n'
                                   './tensorflow/core/platform/default/logging.h: In '
                                   "instantiation of 'std::__cxx11::string* "
                                   'tensorflow::internal::Check_EQImpl(const T1&, const '
                                   'T2&, const char*) [with T1 = int; T2 = long long '
                                   'unsigned int; std::__cxx11::string = '
                                   "std::__cxx11::basic_string<char>]':\r\n"
                                   'tensorflow/stream_executor/stream_executor_pimpl.cc:700:3:   '
                                   'required from here\r\n'
                                   './tensorflow/core/platform/default/logging.h:386:25: '
                                   'warning: comparison of integer expressions of '
                                   "different signedness: 'const int' and 'const long "
                                   "long unsigned int' [-Wsign-compare]\r\n"
                                   '                         ==)  // Compilation error '
                                   'with CHECK_EQ(NULL, x)?\r\n'
                                   './tensorflow/core/platform/macros.h:88:49: note: in '
                                   "definition of macro 'TF_PREDICT_TRUE'\r\n"
                                   ' #define TF_PREDICT_TRUE(x) (__builtin_expect(!!(x), '
                                   '1))\r\n'
                                   '                                                 ^\r\n'
                                   './tensorflow/core/platform/default/logging.h:385:1: '
                                   'note: in expansion of macro '
                                   "'TF_DEFINE_CHECK_OP_IMPL'\r\n"
                                   ' TF_DEFINE_CHECK_OP_IMPL(Check_EQ,\r\n'
                                   ' ^~~~~~~~~~~~~~~~~~~~~~~\r\n'
                                   'INFO: From Compiling '
                                   'tensorflow/compiler/mlir/tensorflow/utils/tpu_rewrite_device_util.cc '
                                   '[for host]:\r\n'
                                   'tensorflow/compiler/mlir/tensorflow/utils/tpu_rewrite_device_util.cc: '
                                   "In function 'tensorflow::Status "
                                   'tensorflow::{anonymous}::GetT\r\n'
                                   'PUDevices(tensorflow::Devices, '
                                   'llvm::ArrayRef<tensorflow::DeviceNameUtils::ParsedName>, '
                                   'llvm::SmallVectorImpl<llvm::SmallVector<ten\r\n'
                                   "sorflow::DeviceNameUtils::ParsedName, 8> >*)':\r\n"
                                   'tensorflow/compiler/mlir/tensorflow/utils/tpu_rewrite_device_util.cc:129:27: '
                                   'warning: comparison of integer expressions of '
                                   'differen\r\n'
                                   "t signedness: 'int' and 'size_t' {aka 'long unsigned "
                                   "int'} [-Wsign-compare]\r\n"
                                   '     if (num_tpus_per_host != '
                                   'host_tpu_devices.size())\r\n'
                                   '         '
                                   '~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\r\n'
                                   'INFO: From Compiling '
                                   'tensorflow/core/kernels/quantization_utils.cc [for '
                                   'host]:\r\n'
                                   'In file included from '
                                   'external/gemmlowp/public/../internal/dispatch_gemm_shape.h:23,\r\n'
                                   '                 from '
                                   'external/gemmlowp/public/gemmlowp.h:19,\r\n'
                                   '                 from '
                                   './tensorflow/core/kernels/quantization_utils.h:37,\r\n'
                                   '                 from '
                                   'tensorflow/core/kernels/quantization_utils.cc:16:\r\n'
                                   'external/gemmlowp/public/../internal/multi_thread_gemm.h: '
                                   "In member function 'void "
                                   'gemmlowp::WorkersPool::LegacyExecuteAndDestroyTa\r\n'
                                   "sks(const std::vector<gemmlowp::Task*>&)':\r\n"
                                   'external/gemmlowp/public/../internal/multi_thread_gemm.h:405:23: '
                                   'warning: comparison of integer expressions of '
                                   'different signedness\r\n'
                                   ": 'int' and 'std::size_t' {aka 'long unsigned int'} "
                                   '[-Wsign-compare]\r\n'
                                   '     for (int i = 0; i < tasks_count - 1; i++) {\r\n'
                                   '                     ~~^~~~~~~~~~~~~~~~~\r\n'
                                   'In file included from '
                                   'tensorflow/core/kernels/quantization_utils.cc:16:\r\n'
                                   './tensorflow/core/kernels/quantization_utils.h: In '
                                   "function 'void "
                                   'tensorflow::RequantizeManyInNewRangeReference(const '
                                   'qint32*, tensorflow::int64, float, float, float, '
                                   "float, tensorflow::quint8*)':\r\n"
                                   './tensorflow/core/kernels/quantization_utils.h:271:32: '
                                   'warning: comparison of integer expressions of '
                                   "different signedness: 'size_t' {aka 'long unsigned "
                                   "int'} and 'tensorflow::int64' {aka 'long long int'} "
                                   '[-Wsign-compare]\r\n'
                                   '   for (size_t index = 0; index < count; ++index) '
                                   '{\r\n'
                                   '                          ~~~~~~^~~~~~~\r\n'
                                   '[6,434 / 12,032] 16 actions running\r\n'
                                   '    Compiling tensorflow/python/tfe_wrapper.cc [for '
                                   'host]; 77s local\r\n'
                                   '    Compiling tensorflow/core/kernels/rnn/lstm_ops.cc '
                                   '[for host]; 44s local\r\n'
                                   '    Compiling tensorflow/core/kernels/rnn/gru_ops.cc '
                                   '[for host]; 43s local\r\n'
                                   '    Compiling tensorflow/stream_executor/stream.cc '
                                   '[for host]; 41s local\r\n'
                                   '    Compiling '
                                   'tensorflow/core/kernels/split_lib_cpu.cc [for host]; '
                                   '28s local\r\n'
                                   '    Compiling .../core/kernels/serialize_sparse_op.cc '
                                   '[for host]; 24s local\r\n'
                                   '    '
                                   '//tensorflow/core/kernels:deserialize_sparse_string_op; '
                                   '22s local\r\n'
                                   '    Compiling .../core/kernels/sparse_reorder_op.cc '
                                   '[for host]; 22s local ...\r\n'
                                   '\r\n'
                                   'Server terminated abruptly (error code: 14, error '
                                   "message: 'Socket closed', log file: "
                                   "'/home/gitpod/.cache/bazel/_bazel_gitpod/2c92b5569ddded7b3a6bd5e139451b60/server/jvm.out'\r\n"
                                   '```',
                           'created_at': '2019-12-2'},
                          {'body': '**System information**\r\n'
                                   '* Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): yes\r\n'
                                   '* OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Ubuntu 18.04.3 LTS\r\n'
                                   '* TensorFlow installed from (source or binary): '
                                   'binary\r\n'
                                   '* TensorFlow version (use command below): '
                                   'v2.1.0-rc1-58-g9837ece 2.1.0-rc2 (python3 -c "import '
                                   'tensorflow as tf; print(tf.version.GIT_VERSION, '
                                   'tf.version.VERSION)")\r\n'
                                   '* Python version: Python 3.6.8\r\n'
                                   '* CUDA/cuDNN version: Driver Version: 440.33.01, CUDA '
                                   'Version: 10.2, cuDNN 7.6.2\r\n'
                                   '* GPU model and memory: Tesla V100-SXM2-16GB\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   "I'm using Bijectors as a flexible prior for a "
                                   'VAE. \r\n'
                                   '\r\n'
                                   'In tf2.1 autograph distributed mirrored mode \r\n'
                                   'https://github.com/olegmyrk/SPADE-Tensorflow/blob/85b5fd7943296561dc3d54557fec5346c2adea58/SPADE.py#L1152\r\n'
                                   'I am getting\r\n'
                                   '```\r\n'
                                   'google.protobuf.message.DecodeError: Error parsing '
                                   'message\r\n'
                                   '```\r\n'
                                   'when running with multiple GPUs (but not when running '
                                   'with single GPU):\r\n'
                                   '```\r\n'
                                   'bijectors = []\r\n'
                                   'for i in range(16):\r\n'
                                   '    bijectors.append(tfb.MaskedAutoregressiveFlow(\r\n'
                                   '      '
                                   'shift_and_log_scale_fn=tfb.masked_autoregressive_default_template(\r\n'
                                   '          code, hidden_layers=[1024, 1024], '
                                   'name=scope + "/maf_" + str(i))))\r\n'
                                   '\r\n'
                                   '    bijectors.append(tfb.BatchNormalization(\r\n'
                                   '        '
                                   'batchnorm_layer=tf.layers.BatchNormalization(\r\n'
                                   '                            name=scope + '
                                   "'/batch_norm_' + str(i)),\r\n"
                                   "        name=scope + '/batch_norm_bijector' + "
                                   'str(i)))\r\n'
                                   '\r\n'
                                   '    '
                                   "permutation=tf.get_variable('permutation_'+str(i), "
                                   'initializer=np.random.permutation(out_channel).astype("int32"), '
                                   'trainable=False)\r\n'
                                   '    bijectors.append(tfb.Permute(permutation))\r\n'
                                   '    \r\n'
                                   'flow_bijector = '
                                   'tfb.Chain(list(reversed(bijectors[:-1])))\r\n'
                                   '```\r\n'
                                   'https://github.com/olegmyrk/SPADE-Tensorflow/blob/85b5fd7943296561dc3d54557fec5346c2adea58/SPADE.py#L190\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   'Should not crash\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   'TF2.x code:\r\n'
                                   'https://github.com/olegmyrk/SPADE-Tensorflow/blob/85b5fd7943296561dc3d54557fec5346c2adea58/SPADE.py#L190\r\n'
                                   '\r\n'
                                   '**Other info / logs**\r\n'
                                   '```\r\n'
                                   'Traceback (most recent call last):\r\n'
                                   '  File "main.py", line 134, in <module>\r\n'
                                   '    main()\r\n'
                                   '  File "main.py", line 121, in main\r\n'
                                   '    gan.train()\r\n'
                                   '  File '
                                   '"/app/home/ubuntu/SPADE-Tensorflow.tf2/SPADE.py", '
                                   'line 1379, in train\r\n'
                                   '    train_loop()\r\n'
                                   '  File '
                                   '"/app/home/ubuntu/SPADE-Tensorflow.tf2/SPADE.py", '
                                   'line 1336, in train_loop\r\n'
                                   '    counter, result_inputs, result_losses_det, '
                                   'result_outputs_det, result_outputs_resample_det, '
                                   'result_outputs_random_det, '
                                   'result_outputs_random_gen_det = '
                                   'train_det_grad_both(global_step, self.train_main, '
                                   '*inputs)\r\n'
                                   '  File '
                                   '"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py", '
                                   'line 568, in __call__\r\n'
                                   '    result = self._call(*args, **kwds)\r\n'
                                   '  File '
                                   '"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py", '
                                   'line 615, in _call\r\n'
                                   '    self._initialize(args, kwds, '
                                   'add_initializers_to=initializers)\r\n'
                                   '  File '
                                   '"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py", '
                                   'line 497, in _initialize\r\n'
                                   '    *args, **kwds))\r\n'
                                   '  File '
                                   '"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", '
                                   'line 2389, in '
                                   '_get_concrete_function_internal_garbage_collected\r\n'
                                   '    graph_function, _, _ = '
                                   'self._maybe_define_function(args, kwargs)\r\n'
                                   '  File '
                                   '"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", '
                                   'line 2703, in _maybe_define_function\r\n'
                                   '    graph_function = '
                                   'self._create_graph_function(args, kwargs)\r\n'
                                   '  File '
                                   '"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", '
                                   'line 2599, in _create_graph_function\r\n'
                                   '    shared_func_graph=False)\r\n'
                                   '  File '
                                   '"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", '
                                   'line 1511, in __init__\r\n'
                                   '    func_graph, self._attrs, '
                                   'self._garbage_collector)\r\n'
                                   '  File '
                                   '"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", '
                                   'line 601, in __init__\r\n'
                                   '    self._func_graph.inputs, '
                                   'self._func_graph.outputs, attrs)\r\n'
                                   '  File '
                                   '"/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", '
                                   'line 466, in __init__\r\n'
                                   '    '
                                   'function_def.ParseFromString(compat.as_bytes(proto_data))\r\n'
                                   'google.protobuf.message.DecodeError: Error parsing '
                                   'message\r\n'
                                   '```\r\n'
                                   '[train.CelebAMask-HQ.tf21.4xgpu.maf.log](https://github.com/tensorflow/tensorflow/files/4001259/train.CelebAMask-HQ.tf21.4xgpu.maf.log)\r\n',
                           'created_at': '2019-12-2'},
                          {'body': '**System information**\r\n'
                                   '- OS Platform and Distribution: Windows10 x64\r\n'
                                   '- TensorFlow installed from: binary\r\n'
                                   '- TensorFlow version: 1.15.0\r\n'
                                   '- Python version: 3.7\r\n'
                                   '- Installed using: conda\r\n'
                                   '- Bazel version (if compiling from source): '
                                   '1.1/2.0\r\n'
                                   '- CUDA/cuDNN version: 10.0\r\n'
                                   '\r\n'
                                   'I was trying to inspect a model following the guide '
                                   '[here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#inspecting-graphs)\r\n'
                                   'When running the command\r\n'
                                   '```bash\r\n'
                                   'bazel build '
                                   'tensorflow/tools/graph_transforms:summarize_graph\r\n'
                                   '```\r\n'
                                   'it failed with these logs\r\n'
                                   '```\r\n'
                                   'INFO: Writing tracer profile to '
                                   "'C:/users/yy/_bazel_yy/zxtlmlwl/command.profile.gz'\r\n"
                                   'INFO: Options provided by the client:\r\n'
                                   "  Inherited 'common' options: --isatty=1 "
                                   '--terminal_columns=120\r\n'
                                   'INFO: Options provided by the client:\r\n'
                                   "  'build' options: "
                                   '--python_path=C:/Users/YY/Anaconda3/python.exe\r\n'
                                   "INFO: Reading rc options for 'build' from "
                                   'e:\\tensorflow\\tensorflow\\.bazelrc:\r\n'
                                   "  'build' options: --apple_platform_type=macos "
                                   '--define framework_shared_object=true --define '
                                   'open_source_build=true '
                                   '--java_toolchain=//third_party/toolchains/java:tf_java_toolchain '
                                   '--host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain '
                                   '--define=use_fast_cpp_protos=true '
                                   '--define=allow_oversize_protos=true '
                                   '--spawn_strategy=standalone -c opt --announce_rc '
                                   '--define=grpc_no_ares=true '
                                   '--noincompatible_remove_legacy_whole_archive '
                                   '--enable_platform_specific_config --config=v2\r\n'
                                   'INFO: Found applicable config definition build:v2 in '
                                   'file e:\\tensorflow\\tensorflow\\.bazelrc: '
                                   '--define=tf_api_version=2 '
                                   '--action_env=TF2_BEHAVIOR=1\r\n'
                                   'INFO: Found applicable config definition '
                                   'build:windows in file '
                                   'e:\\tensorflow\\tensorflow\\.bazelrc: --copt=/w '
                                   '--copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 '
                                   '--host_cxxopt=/std:c++14 --config=monolithic '
                                   '--copt=-DWIN32_LEAN_AND_MEAN '
                                   '--host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI '
                                   '--host_copt=-DNOGDI --linkopt=/DEBUG '
                                   '--host_linkopt=/DEBUG --linkopt=/OPT:REF '
                                   '--host_linkopt=/OPT:REF --linkopt=/OPT:ICF '
                                   '--host_linkopt=/OPT:ICF '
                                   '--experimental_strict_action_env=true '
                                   '--incompatible_windows_native_test_wrapper '
                                   '--verbose_failures '
                                   '--distinct_host_configuration=false\r\n'
                                   'INFO: Found applicable config definition '
                                   'build:monolithic in file '
                                   'e:\\tensorflow\\tensorflow\\.bazelrc: --define '
                                   'framework_shared_object=false\r\n'
                                   'INFO: Call stack for the definition of repository '
                                   "'com_google_protobuf' which is a tf_http_archive "
                                   '(rule definition at '
                                   'E:/tensorflow/tensorflow/third_party/repo.bzl:121:19):\r\n'
                                   ' - '
                                   'E:/tensorflow/tensorflow/tensorflow/workspace.bzl:457:5\r\n'
                                   ' - E:/tensorflow/tensorflow/WORKSPACE:19:1\r\n'
                                   "INFO: Repository 'com_google_protobuf' used the "
                                   'following cache hits instead of downloading the '
                                   'corresponding file.\r\n'
                                   ' * Hash '
                                   "'b9e92f9af8819bbbc514e2902aec860415b70209f31dfc8c4fa72515a5df9d59' "
                                   'for '
                                   'https://storage.googleapis.com/mirror.tensorflow.org/github.com/protocolbuffers/protobuf/archive/310ba5ee72661c081129eb878c1bbcec936b20f0.tar.gz\r\n'
                                   "If the definition of 'com_google_protobuf' was "
                                   'updated, verify that the hashes were also updated.\r\n'
                                   'ERROR: An error occurred during the fetch of '
                                   "repository 'com_google_protobuf':\r\n"
                                   '   Traceback (most recent call last):\r\n'
                                   '        File '
                                   '"E:/tensorflow/tensorflow/third_party/repo.bzl", line '
                                   '101\r\n'
                                   '                _apply_patch(ctx, <1 more '
                                   'arguments>)\r\n'
                                   '        File '
                                   '"E:/tensorflow/tensorflow/third_party/repo.bzl", line '
                                   '68, in _apply_patch\r\n'
                                   '                _execute_and_check_ret_code(ctx, <1 '
                                   'more arguments>)\r\n'
                                   '        File '
                                   '"E:/tensorflow/tensorflow/third_party/repo.bzl", line '
                                   '52, in _execute_and_check_ret_code\r\n'
                                   '                fail(<1 more arguments>)\r\n'
                                   'Non-zero return code(2) when executing '
                                   '\'C:\\Windows\\system32\\bash.exe -l -c "patch" "-p1" '
                                   '"-d" '
                                   '"C:/users/yy/_bazel_yy/zxtlmlwl/external/com_google_protobuf" '
                                   '"-i" '
                                   '"E:/tensorflow/tensorflow/third_party/protobuf/protobuf.patch"\':\r\n'
                                   'Stdout:\r\n'
                                   "Stderr: patch: **** Can't change to directory "
                                   'C:/users/yy/_bazel_yy/zxtlmlwl/external/com_google_protobuf '
                                   ': No such file or directory\r\n'
                                   'ERROR: Analysis of target '
                                   "'//tensorflow/tools/graph_transforms:summarize_graph' "
                                   'failed; build aborted: no such package '
                                   "'@com_google_protobuf//': Traceback (most recent call "
                                   'last):\r\n'
                                   '        File '
                                   '"E:/tensorflow/tensorflow/third_party/repo.bzl", line '
                                   '101\r\n'
                                   '                _apply_patch(ctx, <1 more '
                                   'arguments>)\r\n'
                                   '        File '
                                   '"E:/tensorflow/tensorflow/third_party/repo.bzl", line '
                                   '68, in _apply_patch\r\n'
                                   '                _execute_and_check_ret_code(ctx, <1 '
                                   'more arguments>)\r\n'
                                   '        File '
                                   '"E:/tensorflow/tensorflow/third_party/repo.bzl", line '
                                   '52, in _execute_and_check_ret_code\r\n'
                                   '                fail(<1 more arguments>)\r\n'
                                   'Non-zero return code(2) when executing '
                                   '\'C:\\Windows\\system32\\bash.exe -l -c "patch" "-p1" '
                                   '"-d" '
                                   '"C:/users/yy/_bazel_yy/zxtlmlwl/external/com_google_protobuf" '
                                   '"-i" '
                                   '"E:/tensorflow/tensorflow/third_party/protobuf/protobuf.patch"\':\r\n'
                                   'Stdout:\r\n'
                                   "Stderr: patch: **** Can't change to directory "
                                   'C:/users/yy/_bazel_yy/zxtlmlwl/external/com_google_protobuf '
                                   ': No such file or directory\r\n'
                                   'INFO: Elapsed time: 3.975s\r\n'
                                   'INFO: 0 processes.\r\n'
                                   'FAILED: Build did NOT complete successfully (0 '
                                   'packages loaded, 0 targets configured)\r\n'
                                   '    currently loading: tensorflow\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   "I've tried diferent versions of bazel, 0.20, 1.1.0, "
                                   'and 2.0.0and ```bazel clean```, the error is still '
                                   'there.\r\n'
                                   'What makes me confused is that the " Can\'t change to '
                                   'directory '
                                   'C:/users/yy/_bazel_yy/zxtlmlwl/external/com_google_protobuf '
                                   ': No such file or directory", which in fact I can '
                                   'find the dir at that path\r\n'
                                   '\r\n'
                                   "I've checked other similar issue, but none can fix "
                                   'this error\r\n',
                           'created_at': '2019-12-2'},
                          {'body': 'I can see many users over the last 2 weeks struggling '
                                   'with getting the build to work with Windows 10. I '
                                   'also see a few **recent commits** to improve the '
                                   'build in response to the above feedback.\r\n'
                                   '\r\n'
                                   'As [stated '
                                   'here](https://www.tensorflow.org/install/source_windows) '
                                   'that the Windows tensorflow 2.0 builds with following '
                                   'configurations are successful.\r\n'
                                   '\r\n'
                                   '![image](https://user-images.githubusercontent.com/59223977/71443261-34f74d00-270a-11ea-8cc5-ee2902f336b8.png)\r\n'
                                   '![image](https://user-images.githubusercontent.com/59223977/71443269-44769600-270a-11ea-8857-750f7f3598ee.png)\r\n'
                                   '\r\n'
                                   'Please **update** [the '
                                   'links](https://www.tensorflow.org/install/lang_c) '
                                   'here with the successful windows tensorflow 2.0 '
                                   'builds provided above \r\n'
                                   '\r\n'
                                   'For example: we need\r\n'
                                   'https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-2.0.0.zip\r\n'
                                   'https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-gpu-windows-x86_64-2.0.0.zip\r\n'
                                   '\r\n'
                                   '_Although these tentative builds are old_, but it '
                                   'will provide a starting point **to start TESTING the '
                                   'Tensorflow 2.0 features through bindings.**',
                           'created_at': '2019-12-2'},
                          {'body': '**System information**\r\n'
                                   '- TensorFlow version (you are using): 1.15 and '
                                   '>=2.0\r\n'
                                   '- Are you willing to contribute it (Yes/No): Yes\r\n'
                                   '\r\n'
                                   '**Describe the feature and the current '
                                   'behavior/state.**\r\n'
                                   'Add SO_REUSEPORT option when starting tensorflow '
                                   'training server. It will enable to scan ports to '
                                   'build TF_CONFIG env variable. It is necessary to use '
                                   'distributed tensorflow with resource managers that do '
                                   'not reserve ports (such as Yarn).\r\n'
                                   '\r\n'
                                   'It already has been discussed in ticket '
                                   'https://github.com/tensorflow/tensorflow/issues/21492. '
                                   'It is unclear why the option has been disabled in '
                                   'https://github.com/tensorflow/tensorflow/commit/8cf38e81e638db173238a8f95d6ea613c24d3d9f\r\n'
                                   '\r\n'
                                   '**Will this change the current api? How?**\r\n'
                                   'No\r\n'
                                   '\r\n'
                                   '**Who will benefit with this feature?**\r\n'
                                   '\r\n'
                                   'Projects like https://github.com/criteo/tf-yarn '
                                   '(tensorflow on yarn) will use it to implement the '
                                   'recommended way to create the cluster configuration. '
                                   '(from '
                                   'https://www.tensorflow.org/guide/distributed_training): '
                                   'The procedure will be: \r\n'
                                   '* Launch on all executors a process that will scan '
                                   'ports and reserve a free one\r\n'
                                   '* A master gathers ports numbers. \r\n'
                                   '* Master creates configuration and broadcasts '
                                   'TF_CONFIG variable to all executors\r\n'
                                   '* Launch tensorflow servers\r\n'
                                   '\r\n'
                                   '**Any Other info.**\r\n',
                           'created_at': '2019-12-2'},
                          {'body': '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow):Yes\r\n'
                                   '- OS Platform and Distribution (Android7.1 Snapdragon '
                                   '625):\r\n'
                                   '- Mobile device (HUAWEI Nova CAZ-AL 10) if the issue '
                                   'happens on mobile device:\r\n'
                                   '- TensorFlow installed from (source):\r\n'
                                   '- TensorFlow version '
                                   '(org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly):\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'I use **yolov3** model on android platform to do '
                                   'object detection. When I did object detection on CPU '
                                   'the results are right but when I add GPU module the '
                                   'results are totally different.\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '/**\r\n'
                                   ' * Wrapper for frozen detection models trained using '
                                   'the Tensorflow Object Detection API:\r\n'
                                   ' * '
                                   'github.com/tensorflow/models/tree/master/research/object_detection\r\n'
                                   ' */\r\n'
                                   'public class TFLitePanoObjectDetectionAPIModel '
                                   'implements Classifier {\r\n'
                                   '  private static final Logger LOGGER = new '
                                   'Logger();\r\n'
                                   '\r\n'
                                   '  private static final int NUM_of_classes = 19;\r\n'
                                   '  private static final int NUM_THREADS = 4;\r\n'
                                   '  private boolean isModelQuantized;\r\n'
                                   '  private int inputSize;\r\n'
                                   '  private Vector<String> labels = new '
                                   'Vector<String>();\r\n'
                                   '  private int[] intValues;\r\n'
                                   '  private float[][][][] output_1;\r\n'
                                   '  private float[][][][] output_2;\r\n'
                                   '  private float[][][][] output_3;\r\n'
                                   '  private ByteBuffer imgData;\r\n'
                                   '  private Interpreter tflite;\r\n'
                                   '  private MappedByteBuffer tfliteModel;\r\n'
                                   '  private final Interpreter.Options tfliteOptions = '
                                   'new Interpreter.Options();\r\n'
                                   '  private GpuDelegate gpuDelegate = null;\r\n'
                                   '  private NnApiDelegate nnapiDelegate = null;\r\n'
                                   '  private int gridNum;\r\n'
                                   '\r\n'
                                   '  private int BoxNum_each_gird=3;\r\n'
                                   '  private float[][][][] floatValues;\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '  private TFLitePanoObjectDetectionAPIModel() {}\r\n'
                                   '  private float scoreThreshold = 0.3f;\r\n'
                                   '  private int blockSize=32;\r\n'
                                   '\r\n'
                                   '  public static Classifier create(\r\n'
                                   '      final AssetManager assetManager,\r\n'
                                   '      final String modelFilename,\r\n'
                                   '      final String labelFilename,\r\n'
                                   '      final int inputSize,\r\n'
                                   '      final boolean isQuantized)\r\n'
                                   '      throws IOException {\r\n'
                                   '    final TFLitePanoObjectDetectionAPIModel d = new '
                                   'TFLitePanoObjectDetectionAPIModel();\r\n'
                                   '    try {\r\n'
                                   '\r\n'
                                   '      d.tfliteModel=loadModelFile(assetManager, '
                                   'modelFilename);\r\n'
                                   '      if (d.gpuDelegate == null)\r\n'
                                   '      {\r\n'
                                   '        d.gpuDelegate = new GpuDelegate();\r\n'
                                   '        '
                                   'd.tfliteOptions.addDelegate(d.gpuDelegate);\r\n'
                                   '      }\r\n'
                                   '      d.tflite = new '
                                   'Interpreter(d.tfliteModel,d.tfliteOptions);\r\n'
                                   '    } catch (Exception e) {\r\n'
                                   '      throw new RuntimeException(e);\r\n'
                                   '    }\r\n'
                                   '\r\n'
                                   '    d.isModelQuantized = isQuantized;\r\n'
                                   '    // Pre-allocate buffers.\r\n'
                                   '    int numBytesPerChannel;\r\n'
                                   '    if (isQuantized) {\r\n'
                                   '      numBytesPerChannel = 1; // Quantized\r\n'
                                   '    } else {\r\n'
                                   '      numBytesPerChannel = 4; // Floating point\r\n'
                                   '    }\r\n'
                                   '    d.imgData = ByteBuffer.allocateDirect(1 * '
                                   'd.inputSize * 2*d.inputSize * 3 * '
                                   'numBytesPerChannel);//\r\n'
                                   '    d.imgData.order(ByteOrder.nativeOrder());\r\n'
                                   '    d.intValues = new int[d.inputSize * '
                                   '2*d.inputSize];\r\n'
                                   '\r\n'
                                   '    d.gridNum=d.inputSize/32;\r\n'
                                   '    d.floatValues=new float[1][d.inputSize][2 * '
                                   'd.inputSize ][3];\r\n'
                                   '    d.output_1 = new float[1][][][];\r\n'
                                   '    d.output_2 = new float[1][][][];\r\n'
                                   '    d.output_3 = new float[1][][][];\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '    return d;\r\n'
                                   '  }\r\n'
                                   '  }\r\n'
                                   '\r\n'
                                   '  @Override\r\n'
                                   '  public List<Recognition> recognizeImage(final '
                                   'Bitmap bitmap) {\r\n'
                                   '\r\n'
                                   '    bitmap.getPixels(intValues, 0, bitmap.getWidth(), '
                                   '0, 0, bitmap.getWidth(), bitmap.getHeight());\r\n'
                                   '    imgData.rewind();\r\n'
                                   '\r\n'
                                   '    for (int i = 0; i < inputSize; ++i)\r\n'
                                   '    {\r\n'
                                   '      for (int j = 0; j < 2*inputSize; ++j)\r\n'
                                   '      {\r\n'
                                   '        int pixelValue = intValues[i * 2*inputSize + '
                                   'j];\r\n'
                                   '          // Float model\r\n'
                                   '          floatValues[0][i][j][0]=((pixelValue >> 16) '
                                   '& 0xFF)/255.0f ;\r\n'
                                   '          floatValues[0][i][j][1]=((pixelValue >> 8) '
                                   '& 0xFF)/255.0f ;\r\n'
                                   '          floatValues[0][i][j][2]=(pixelValue& 0xFF) '
                                   '/255.0f;\r\n'
                                   '      }\r\n'
                                   '    }\r\n'
                                   '\r\n'
                                   '     int '
                                   'channelNum=BoxNum_each_gird*(NUM_of_classes+5);\r\n'
                                   '\r\n'
                                   '    output_1 = new '
                                   'float[1][gridNum][2*gridNum][channelNum];\r\n'
                                   '    output_2 = new '
                                   'float[1][2*gridNum][4*gridNum][channelNum];\r\n'
                                   '    output_3 = new '
                                   'float[1][4*gridNum][8*gridNum][channelNum];\r\n'
                                   '\r\n'
                                   '    Object[] inputArray = {floatValues};\r\n'
                                   '    Map<Integer, Object> outputMap = new '
                                   'HashMap<>();\r\n'
                                   '    outputMap.put(0, output_1);\r\n'
                                   '    outputMap.put(1, output_2);\r\n'
                                   '    outputMap.put(2, output_3);\r\n'
                                   '    Trace.endSection();\r\n'
                                   '\r\n'
                                   '    // Run the inference call.\r\n'
                                   '    Trace.beginSection("run");\r\n'
                                   '    long startTime = SystemClock.uptimeMillis();\r\n'
                                   '    tflite.runForMultipleInputsOutputs(inputArray, '
                                   'outputMap);\r\n'
                                   '    long '
                                   'lastingTime=SystemClock.uptimeMillis()-startTime;\r\n'
                                   '\r\n'
                                   '    LOGGER.i("runForMultipleInputsOutputs time of '
                                   'each image: " + lastingTime + "ms");\r\n'
                                   '    Trace.endSection(); \r\n'
                                   '    }\r\n'
                                   '\r\n'
                                   '}`\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   '\r\n'
                                   'Provide a reproducible test case that is the bare '
                                   'minimum necessary to generate the problem.\r\n'
                                   '\r\n'
                                   '**Other info / logs**\r\n'
                                   'Include any logs or source code that would be helpful '
                                   'to diagnose the problem. If including tracebacks, '
                                   'please include the full traceback. Large logs and '
                                   'files should be attached.\r\n',
                           'created_at': '2019-12-2'},
                          {'body': 'Add support for the SparkFun Edge board in the '
                                   'Arduino library build. Allows individuals who are '
                                   'less comfortable with command line tools to get '
                                   'started with TFLu examples. \r\n'
                                   '\r\n'
                                   '**dependencies**\r\n'
                                   '[Update TFLu (micro) to use AmbiqSuite SDK Release '
                                   '2.2.0 for '
                                   'Apollo3](https://github.com/tensorflow/tensorflow/pull/35236)\r\n'
                                   '[Upgrade Edge Board Support Package in TFLu '
                                   '(micro)](https://github.com/tensorflow/tensorflow/pull/35290)',
                           'created_at': '2019-12-2'},
                          {'body': 'when saved the model as tf by api  '
                                   '**tf.keras.models.save_model(testmodel, '
                                   '"./1/",save_format=\'tf\')**\r\n'
                                   'then,I load it by '
                                   "tf.keras.models.load_model('1'),howeverI got the "
                                   'issue as title.\r\n'
                                   'It is worth mentioning that it succed if I saved as '
                                   '.h5\r\n'
                                   '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow):\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04):centos7.4\r\n'
                                   '- TensorFlow version (use command below):tensorflow '
                                   '2.0\r\n'
                                   '- Python version:3.7\r\n'
                                   '-NVIDIA-SMI 418.88\r\n'
                                   '-Driver Version: 418.88\r\n'
                                   '-CUDA Version: 10.1 \r\n'
                                   '- GPU model and memory:12\r\n'
                                   '\r\n',
                           'created_at': '2019-12-2'},
                          {'body': '### System information\r\n'
                                   '- **Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow)**: '
                                   'YES\r\n'
                                   '- **OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04)**: macOS 10.15.2 (19C57)\r\n'
                                   '- **TensorFlow installed from (source or binary)**: '
                                   'binary\r\n'
                                   '- **TensorFlow version (use command '
                                   'below)**:v2.0.0-rc2-26-g64c3d382ca 2.0.0\r\n'
                                   '- **Python version**:3.7.5 (default, Oct 25 2019, '
                                   '18:18:54) \\n[Clang 11.0.0 (clang-1100.0.33.8)]\r\n'
                                   '\r\n'
                                   '### Describe the problem\r\n'
                                   '\r\n'
                                   '`tf.data.Dataset` supports RaggedTensor and '
                                   'SparseTensor but `tf.data.Dataset.from_generator` is '
                                   'limited to Tensors only. Please support other types '
                                   'of Tensors. \r\n'
                                   '\r\n'
                                   '### Source code / logs\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   '    def data_get():\r\n'
                                   '        for i in range(5):\r\n'
                                   '            yield tf.ragged.constant([[i, i], '
                                   '[i]])\r\n'
                                   '\r\n'
                                   '    ds = tf.data.Dataset.from_generator(data_get, '
                                   'tf.int32)\r\n'
                                   '\r\n'
                                   '    for sample in ds:\r\n'
                                   '        print(sample)\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'produces:\r\n'
                                   '\r\n'
                                   'Traceback (most recent call last):\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   '  File '
                                   '"/Users/peak/IdeaProjects/TFmodels/venv-tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py", '
                                   'line 221, in __call__\r\n'
                                   '    ret = func(*args)\r\n'
                                   '\r\n'
                                   '  File '
                                   '"/Users/peak/IdeaProjects/TFmodels/venv-tf2/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py", '
                                   'line 606, in generator_py_func\r\n'
                                   '    "element was %s." % (dtype.name, ret))\r\n'
                                   '\r\n'
                                   'TypeError: `generator` yielded an element that could '
                                   'not be converted to the expected type. The expected '
                                   'type was int32, but the yielded element was '
                                   '<tf.RaggedTensor [[0, 0], [0]]>.\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '\r\n',
                           'created_at': '2019-12-2'},
                          {'body': '<em>Please make sure that this is a bug. As per our '
                                   '[GitHub '
                                   'Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), '
                                   'we only address code/doc bugs, performance issues, '
                                   'feature requests and build/installation issues on '
                                   'GitHub. tag:bug_template</em>\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): yes\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Windows 7\r\n'
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device:\r\n'
                                   '- TensorFlow installed from (source or binary): \r\n'
                                   '- TensorFlow version (use command below): 2.0.0\r\n'
                                   '- Python version: 3.7\r\n'
                                   '- Bazel version (if compiling from source):\r\n'
                                   '- GCC/Compiler version (if compiling from source):\r\n'
                                   '- CUDA/cuDNN version: 10.1\r\n'
                                   '- GPU model and memory: \r\n'
                                   '\r\n'
                                   'You can collect some of this information using our '
                                   'environment capture\r\n'
                                   '[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\n'
                                   'You can also obtain the TensorFlow version with: 1. '
                                   'TF 1.0: `python -c "import\r\n'
                                   'tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"` '
                                   '2. TF 2.0: `python -c\r\n'
                                   '"import tensorflow as tf; '
                                   'print(tf.version.GIT_VERSION, '
                                   'tf.version.VERSION)"`\r\n'
                                   '\r\n'
                                   'Hi,\r\n'
                                   '\r\n'
                                   "I tried to follow tf's doc to build up a model as "
                                   'follows:\r\n'
                                   'https://www.tensorflow.org/guide/keras/custom_layers_and_models\r\n'
                                   '\r\n'
                                   '`\r\n'
                                   '\t\t\t\t\t\r\n'
                                   '\tclass CBR(layers.Layer):\r\n'
                                   "\t\t'''\r\n"
                                   '\t\tConvolution + Batch normalisation + Relu\r\n'
                                   "\t\t'''\r\n"
                                   '\t\tdef __int__(self, filterNum, kSize, strSize, '
                                   "padMode, name='cbr', **kwargs):\r\n"
                                   '\t\t\tsuper(CBR, self).__init__(name=name, '
                                   '**kwargs)\r\n'
                                   '\t\t\tself.conv3D = layers.Conv3D(filters=filterNum, '
                                   'kernel_size=kSize, strides=strSize, padding=padMode, '
                                   "data_format='channels_first')\r\n"
                                   '\t\t\tself.BN = layers.BatchNormalization(axis=1)\r\n'
                                   '\t\tdef call(self, inputs):\r\n'
                                   '\t\t\tx = self.conv3D(inputs)\r\n'
                                   '\t\t\tx=self.BN(x)\r\n'
                                   '\t\t\treturn layers.Relu(x)\r\n'
                                   '\t\t\t\r\n'
                                   '\tclass SimpleUNet(tf.keras.Model, layers.Layer):\r\n'
                                   "\t\t'''\r\n"
                                   '\t\tSerialise basic units so as to build up a '
                                   'double-layered encoder-decoder U-Net\r\n'
                                   '\t\tInput:\r\n'
                                   '\t\t\tinDim: [mbSize, modaility/channel, tensor '
                                   'dimensions]\r\n'
                                   '\t\t\tclassNum: background included\r\n'
                                   '\t\t\tname: name for the net\r\n'
                                   '\t\t\tinputs: 5D tf tensor of [mbSize, '
                                   'modaility/channel, tensor dimensions]. Inputs must be '
                                   'organised into channel first\r\n'
                                   '\t\tReturns:\r\n'
                                   '\t\t\toutputs: 5D tf tensor of [mbSize, classNum, '
                                   'tensor dimensions]\r\n'
                                   "\t\t'''\r\n"
                                   '\t\tdef __init__(self, inDim, classNum, '
                                   "name='SimpleUNet', **kwargs):\r\n"
                                   '\t\t\tsuper(SimpleUNet, self).__init__(name=name, '
                                   '**kwargs)\r\n'
                                   '\t\t\tself.inDim = inDim\r\n'
                                   '\t\t\tself.classNum = classNum\r\n'
                                   '\t\t\tdimEnSt1End = np.array(inDim[1:])-2-2\r\n'
                                   '\t\t\tdimEnSt2Ed = dimEnSt1End/2-2-2\r\n'
                                   '\t\t\tdimBridgeEnd = (dimEnSt2Ed/2-2-2)*2\r\n'
                                   '\t\t\tdimDEStd1End = (dimBridgeEnd-2-2)*2\r\n'
                                   '\t\t\toutDim = dimDEStd1End-2-2-2\r\n'
                                   '\t\t\ttemp = ((dimEnSt2Ed - '
                                   "dimBridgeEnd)/2).astype('int32')\r\n"
                                   '\t\t\tcrop3d1 = tuple(np.tile(temp, (2, 1)).T)\r\n'
                                   '\t\t\ttemp = ((dimEnSt1End - '
                                   "dimDEStd1End)/2).astype('int32')\r\n"
                                   '\t\t\tcrop3d2 = tuple(np.tile(temp, (2, 1)).T)\r\n'
                                   '\t\t\t# list of basic units used in the model\r\n'
                                   "\t\t\tself.en_st1_cbr1 = CBR(32, 3, 1, 'valid')\r\n"
                                   "\t\t\tself.en_st1_cbr2 = CBR(64, 3, 1, 'valid')\r\n"
                                   '\t\t\tself.en_st2_mp = '
                                   'layers.MaxPooling3D(pool_size=(2, 2, 2), strides=(2, '
                                   "2, 2), padding='valid', "
                                   "data_format='channels_first')\r\n"
                                   "\t\t\tself.en_st2_cbr1 = CBR(64, 3, 1, 'valid')\r\n"
                                   "\t\t\tself.en_st2_cbr2 = CBR(128, 3, 1, 'valid')\r\n"
                                   '\t\t\tself.bridge_mp = '
                                   'layers.MaxPooling3D(pool_size=(2, 2, 2), strides=(2, '
                                   "2, 2), padding='valid', "
                                   "data_format='channels_first')\r\n"
                                   "\t\t\tself.bridge_cbr1 = CBR(128, 3, 1, 'valid')\r\n"
                                   '\t\t\tself.bridge_cbr2 = CBR(256, 3, 1, '
                                   "'valid')    \r\n"
                                   '\t\t\tself.bridge_tconv1 = '
                                   'layers.Conv3DTranspose(256, 2, strides=2, '
                                   "padding='valid', data_format='channels_first')\r\n"
                                   '\t\t\tself.de_3dcrop1 = layers.Cropping3D(crop3d1, '
                                   "data_format='channels_first')\r\n"
                                   "\t\t\tself.de_st1_cbr1 = CBR(256, 3, 1, 'valid')\r\n"
                                   '\t\t\tself.de_st1_cbr2 = CBR(128, 3, 1, '
                                   "'valid')    \r\n"
                                   '\t\t\tself.de_st1_tconv1 = '
                                   'layers.Conv3DTranspose(128, 2, strides=2, '
                                   "padding='valid', data_format='channels_first')\r\n"
                                   '\t\t\tself.de_3dcrop2 = layers.Cropping3D(crop3d2, '
                                   "data_format='channels_first')\r\n"
                                   "\t\t\tself.de_st2_cbr1 = CBR(64, 3, 1, 'valid')\r\n"
                                   "\t\t\tself.de_st2_cbr2 = CBR(64, 3, 1, 'valid') \r\n"
                                   '\t\t\tself.final_conv3D = '
                                   'layers.Conv3D(filters=self.classNum, kernel_size=3, '
                                   "strides=1, padding='valid', "
                                   "data_format='channels_first')\r\n"
                                   '\t\t\t\t\t\r\n'
                                   '\t\tdef call(self, inputs):\r\n'
                                   '\t\t\tx = self.en_st1_cbr1(inputs)\r\n'
                                   '\t\t\txEnSt1End = self.en_st1_cbr2(x)\r\n'
                                   '\t\t\tx= self.en_st2_mp(xEnSt1End)\r\n'
                                   '\t\t\tx= self.en_st2_cbr1(x)\r\n'
                                   '\t\t\txEnSt2Ed = self.en_st2_cbr2(x)\r\n'
                                   '\t\t\tx = self.bridge_mp(xEnSt2Ed)\r\n'
                                   '\t\t\tx = self.bridge_cbr1(x)\r\n'
                                   '\t\t\tx = self.bridge_cbr2(x)\r\n'
                                   '\t\t\txBridgeEnd = self.bridge_tconv1(x)\r\n'
                                   '\t\t\txCrop1 = self.de_3dcrop1(xEnSt2Ed)\r\n'
                                   '\t\t\tx = layers.Concatenate([xBridgeEnd, xCrop1], '
                                   'axis=1)\r\n'
                                   '\t\t\tx = self.de_st1_cbr1(x)\r\n'
                                   '\t\t\tx = self.de_st1_cbr2(x)\r\n'
                                   '\t\t\txDeSt1End = self.de_st1_tconv1(x)\r\n'
                                   '\t\t\txCrop2 = self.de_3dcrop2(xEnSt1End)\r\n'
                                   '\t\t\tx = layers.Concatenate([xDeSt1End, xCrop2], '
                                   'axis=1)\r\n'
                                   '\t\t\tx = self.de_st2_cbr1(x)\r\n'
                                   '\t\t\tx = self.de_st2_cbr2(x)\r\n'
                                   '\t\t\tx = self.final_conv3D(x)\r\n'
                                   '\t\t\toutputs = activations.softmax(x, axis=1)\r\n'
                                   '\t\t\t\r\n'
                                   '\t\t\treturn outputs\r\n'
                                   '\r\n'
                                   '`\r\n'
                                   '\r\n'
                                   'Then I initialised it, and tried to build it by '
                                   'calling SUNet.build\r\n'
                                   '`\r\n'
                                   '\tclassNum = 3 \r\n'
                                   '\tmbSize = 16 \r\n'
                                   '\tinDim = [4, 64, 64, 64] \r\n'
                                   '\tSUNet = SimpleUNet(inDim, classNum) \r\n'
                                   '\tSUNet.build(input_shape=inDim)\r\n'
                                   '`\r\n'
                                   "I strictly followed the example given in tf's doc, "
                                   'but an error was raised when building up it\r\n'
                                   'ValueError: name for name_scope must be a string.\r\n'
                                   'It occurred here when CBR is called for the first '
                                   'time:\r\n'
                                   '\r\n'
                                   '`\r\n'
                                   'def __int__(self, filterNum, kSize, strSize, padMode, '
                                   "name='cbr', **kwargs): \r\n"
                                   '\tsuper(CBR, self).__init__(name=name, **kwargs)\r\n'
                                   '`\r\n'
                                   '\r\n'
                                   'I cannot figure out any syntactic mistake. Could '
                                   'anyone give me a hand? Thanks a lot.\r\n'
                                   'Or, is the model cannot be built at this moment until '
                                   'it is actually used when being called in the '
                                   'training?',
                           'created_at': '2019-12-2'},
                          {'body': '**System information**\r\n'
                                   '- Have I written custom code: Yes\r\n'
                                   '- OS Platform and Distribution: '
                                   '4.4.0-18362-Microsoft\r\n'
                                   '- TensorFlow installed from: Anaconda default '
                                   'source\r\n'
                                   '- TensorFlow version: 1.15\r\n'
                                   '- Python version: 3.7.5\r\n'
                                   '- CUDA/cuDNN version: 10.0\r\n'
                                   '- GPU model and memory: GeForce RTX 2060\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   '\r\n'
                                   "I'm trying to implement a custom loss function based "
                                   "on a custom accuracy function that I'm already using "
                                   'to evaluate my model predictions on the test dataset. '
                                   "The conversion can't be 1:1 because I use numpy "
                                   '"greater" and "equal" functions that are not '
                                   'differentiable. I created thefore custom functions '
                                   'that approximate the latters but their behavior has '
                                   'some problems\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   '\r\n'
                                   'In particular I can test if everything is fine by '
                                   'comparing the results obtained by my original custom '
                                   'accuracy f. and the new loss f. given the same input '
                                   '(my input are tensorflow predictions, I just inglobe '
                                   'them inside K.constant to convert them in tensors). '
                                   'What I noticed is that this line of code\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'eps = sys.float_info.epsilon\r\n'
                                   'return 0.5*(y + 5 + K.sqrt(K.pow(y-5,2) + eps))\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'is problematic. In particular y is an array of '
                                   'float32 values in [1:10] range and the returned '
                                   "array, let's call it 'ret', should have "
                                   'ret[i]=max(5,y[i]) but sometimes the value of **5** '
                                   'becomes **4.9999995** instead. The next portion of my '
                                   'code is based on how many **5** are present and '
                                   "therefore I can't ignore this problem.\r\n"
                                   '\r\n'
                                   "The fact is that, let's say a problematic index is "
                                   "'w' so that ret[w]=4.9999995 instead of 5, if I use "
                                   'the same code with y now equal to only y[w] the '
                                   'returned array is correctly 5. This means that '
                                   'somehow if y is a batch of predictions and not just '
                                   "one something isn't working. This should not be the "
                                   'case because both K.sqrt and K.pow works element '
                                   'wise, it should not matter if y is an array of 1 or '
                                   'multiple values \r\n'
                                   '\r\n'
                                   'Out of almost 20k predictions, around 1k have this '
                                   'same problem and it is deterministic (always the same '
                                   'are problematic). I also tried to use:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'eps = sys.float_info.epsilon\r\n'
                                   'return 0.5*(y + 5 + np.sqrt(np.pow(y-5,2) + eps))\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'and the problem is gone thefore it is related to '
                                   'Keras backend.\r\n'
                                   '\r\n'
                                   'Last info, I tried to use also:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'eps = sys.float_info.epsilon\r\n'
                                   'return tf.math.ceil(0.5*(y + 5 + K.sqrt(K.pow(y-5,2) '
                                   '+ eps)))\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'but this completely ruins the returned value, '
                                   'sometimes real numbers such as 4.5 are rounded to 6 '
                                   'instead of 5\r\n'
                                   '\r\n'
                                   'If more informations are needed I can provide them',
                           'created_at': '2019-12-2'},
                          {'body': '**System information**\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Windows 10\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'installed TF binary 2.0 with Conda\r\n'
                                   '- TensorFlow version (or github SHA if from source): '
                                   'TF 2.0\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Command used to run the converter or code if youre '
                                   'using the Python API**\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'converter = '
                                   "tf.lite.TFLiteConverter.from_saved_model('model_mnist.hd5')\r\n"
                                   'converter.optimizations = '
                                   '[tf.lite.Optimize.DEFAULT]\r\n'
                                   'converter.target_spec.supported_ops = '
                                   '[tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n'
                                   'converter.inference_input_type = tf.uint8\r\n'
                                   'converter.inference_output_type = tf.uint8\r\n'
                                   '\r\n'
                                   'images = tf.cast(X_train, tf.float32)\r\n'
                                   'mnist_ds = '
                                   'tf.data.Dataset.from_tensor_slices((images)).batch(1)\r\n'
                                   'def representative_data_gen():\r\n'
                                   '    for input_value in mnist_ds.take(100):\r\n'
                                   '        yield[input_value]\r\n'
                                   'converter.representative_dataset = '
                                   'representative_data_gen\r\n'
                                   '\r\n'
                                   'tflite_quant_model = converter.convert()\r\n'
                                   "with open('model_mnist_quant_uint8.tflite', 'wb') as "
                                   'f:\r\n'
                                   '    f.write(tflite_quant_model)\r\n'
                                   '\r\n'
                                   '\r\n'
                                   'interpreter = '
                                   "tf.lite.Interpreter(model_path='model_mnist_quant_uint8.tflite')\r\n"
                                   'interpreter.allocate_tensors()\r\n'
                                   '\r\n'
                                   'img = X_train[0] * 255\r\n'
                                   "img = img.astype('uint8')\r\n"
                                   'print(interpreter.get_input_details())\r\n'
                                   "interpreter.set_tensor(interpreter.get_input_details()[0]['index'], "
                                   'np.expand_dims(img, axis=0))\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '**The output from the converter invocation**\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   "[{'name': 'flatten_input', 'index': 11, 'shape': "
                                   "array([ 1, 28, 28]), 'dtype': <class "
                                   "'numpy.float32'>, 'quantization': (0.0, 0)}]\r\n"
                                   '---------------------------------------------------------------------------\r\n'
                                   'ValueError                                Traceback '
                                   '(most recent call last)\r\n'
                                   '<ipython-input-12-5a2fa86c9de2> in <module>\r\n'
                                   "      5 img = img.astype('uint8')\r\n"
                                   '      6 print(interpreter.get_input_details())\r\n'
                                   '----> 7 '
                                   "interpreter.set_tensor(interpreter.get_input_details()[0]['index'], "
                                   'np.expand_dims(img, axis=0))\r\n'
                                   '\r\n'
                                   '~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\lite\\python\\interpreter.py '
                                   'in set_tensor(self, tensor_index, value)\r\n'
                                   '    344       ValueError: If the interpreter could '
                                   'not set the tensor.\r\n'
                                   '    345     """\r\n'
                                   '--> 346     self._interpreter.SetTensor(tensor_index, '
                                   'value)\r\n'
                                   '    347 \r\n'
                                   '    348   def resize_tensor_input(self, input_index, '
                                   'tensor_size):\r\n'
                                   '\r\n'
                                   '~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\lite\\python\\interpreter_wrapper\\tensorflow_wrap_interpreter_wrapper.py '
                                   'in SetTensor(self, i, value)\r\n'
                                   '    134 \r\n'
                                   '    135     def SetTensor(self, i, value):\r\n'
                                   '--> 136         return '
                                   '_tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_SetTensor(self, '
                                   'i, value)\r\n'
                                   '    137 \r\n'
                                   '    138     def GetTensor(self, i):\r\n'
                                   '\r\n'
                                   'ValueError: Cannot set tensor: Got tensor of type '
                                   'UINT8 but expected type FLOAT32 for input 11, name: '
                                   'flatten_input \r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '**Also, please include a link to the saved model or '
                                   'GraphDef**\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   '# Put link here or attach to the issue.\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '**Failure details**\r\n'
                                   'The conversion is successful, but the generated model '
                                   'is wrong. The input tensor dtype should be uint8, but '
                                   'is still float32.\r\n'
                                   '\r\n'
                                   'I tried the same thing with TF 1.15.0. In this case, '
                                   'every things works as expected. Here is the result '
                                   'with TF 1.15.0\r\n'
                                   '```\r\n'
                                   "[{'name': 'flatten_input', 'index': 11, 'shape': "
                                   "array([ 1, 28, 28], dtype=int32), 'dtype': <class "
                                   "'numpy.uint8'>, 'quantization': "
                                   '(0.003921568859368563, 0)}]\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Any other info / logs**\r\n'
                                   '\r\n'
                                   'Include any logs or source code that would be helpful '
                                   'to diagnose the problem. If including tracebacks, '
                                   'please include the full traceback. Large logs and '
                                   'files should be attached.\r\n',
                           'created_at': '2019-12-2'},
                          {'body': '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow):  Yes\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04):  Ubuntu 18.04\r\n'
                                   '- TensorFlow installed from (source or binary):  '
                                   'binary\r\n'
                                   '- TensorFlow version (use command below):  2.0.0\r\n'
                                   '- Python version:  3.6.8\r\n'
                                   '- CUDA/cuDNN version:  10.2 / 7.6.5.32-1+cuda10.2\r\n'
                                   '- GPU model and memory:  NVidia Titan RTX 24218 '
                                   'MiB\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   '\r\n'
                                   'When I attempt to slice a tensor inside a '
                                   'keras.util.Sequence from model.fit_generator with '
                                   'multiprocessing=True, TensorFlow hangs forever '
                                   'without reporting any error or using any CPU or GPU '
                                   'cycles.  It works as expected when '
                                   'multiprocessing=False.\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   '\r\n'
                                   'TensorFlow should correctly fit the model just as it '
                                   'does with multiprocessing=False\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   '\r\n'
                                   'In order to reproduce, substitute my_jpeg for some '
                                   'jpeg on your computer (hopefully with dimension '
                                   'greater than 224px).  Note that if you set '
                                   'use_multiprocessing=False in the example below, then '
                                   'this will correctly train the model.\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'from __future__ import absolute_import, division, '
                                   'print_function, unicode_literals\r\n'
                                   '\r\n'
                                   'import tensorflow as tf\r\n'
                                   'from tensorflow import keras\r\n'
                                   '\r\n'
                                   '# In order to reproduce, just use whatever random '
                                   'JPEG you have handy here.\r\n'
                                   '# It should be larger than my_crop in the x and y '
                                   'dimension.\r\n'
                                   'my_jpeg = "/home/ben/my_jpeg.jpg"\r\n'
                                   'my_crop = 224\r\n'
                                   '\r\n'
                                   '# Generates a single crop for TensorFlow.\r\n'
                                   'class DataGenerator(keras.utils.Sequence):\r\n'
                                   '  def __init__(\r\n'
                                   '      self,\r\n'
                                   '      image_location,\r\n'
                                   '      crop_size=224):\r\n'
                                   '    self._image_location = image_location\r\n'
                                   '    self._crop_size = crop_size\r\n'
                                   '\r\n'
                                   '  # Just one single batch will be returned, of just '
                                   'one single image.\r\n'
                                   '  def __len__(self):\r\n'
                                   '    return 1\r\n'
                                   '\r\n'
                                   '  # Generate one batch of data.\r\n'
                                   '  def __getitem__(self, index):\r\n'
                                   '    # Where the tensors will be stored.\r\n'
                                   '    X = []\r\n'
                                   '    y = [1]\r\n'
                                   '\r\n'
                                   '    # Read it.\r\n'
                                   '    image = tf.io.read_file(self._image_location)\r\n'
                                   '\r\n'
                                   '    # Load it.\r\n'
                                   '    image = tf.image.decode_jpeg(image, '
                                   'channels=3)\r\n'
                                   '\r\n'
                                   '    assert image.shape[2] == 3  # MUST be RGB.\r\n'
                                   '    height = image.shape[0]\r\n'
                                   '    width = image.shape[1]\r\n'
                                   '\r\n'
                                   '    # Just take a trivial crop of the image.\r\n'
                                   '    # This is the offending line operation which '
                                   'hangs forever.\r\n'
                                   '    image = image[0:self._crop_size, '
                                   '0:self._crop_size, :]\r\n'
                                   '\r\n'
                                   '    # This line is equivalent to above, and it also '
                                   'hangs with multiprocessing enabled.\r\n'
                                   '    # image = tf.slice(image, [0, 0, 0], '
                                   '[self._crop_size, self._crop_size, 3])\r\n'
                                   '\r\n'
                                   '    X.append(tf.dtypes.cast(image, tf.float32))\r\n'
                                   '\r\n'
                                   '    # Tensors are not generally assignable, but we '
                                   'can create them from a number of existing ones.\r\n'
                                   '    X = tf.stack(X)\r\n'
                                   '    y = tf.stack(y)\r\n'
                                   '\r\n'
                                   '    # Preprocess it.\r\n'
                                   '    X /= 255.0  # Normalize to [0, 1] range.\r\n'
                                   '\r\n'
                                   '    return X, y\r\n'
                                   '\r\n'
                                   'generator = DataGenerator(my_jpeg, my_crop)\r\n'
                                   '\r\n'
                                   'model = '
                                   'tf.keras.applications.ResNet50(input_shape=(my_crop, '
                                   'my_crop, 3))\r\n'
                                   '\r\n'
                                   "model.compile(loss='mse')\r\n"
                                   '\r\n'
                                   '# use_multiprocessing=False works.\r\n'
                                   '# use_multiprocessing=True hangs.\r\n'
                                   'model.fit_generator(generator, '
                                   'use_multiprocessing=True, workers=2)\r\n'
                                   '```\r\n'
                                   '\r\n',
                           'created_at': '2019-12-2'},
                          {'body': '@tensorflow/micro\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- Host OS Platform and Distribution (e.g., Linux '
                                   'Ubuntu 16.04): Ubuntu 18.04 ( Windows SL)\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'source\r\n'
                                   '- Tensorflow version (commit SHA if source):\r\n'
                                   '- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 '
                                   'etc.): target : efr32/efm32 (tried to compile with '
                                   'mbed) \r\n'
                                   '\r\n'
                                   '**Describe the problem**\r\n'
                                   "I'm trying to run one of the provided projects on "
                                   'efr/efm32 microcontroller, (i choose magic_wanda '
                                   "example because i have an accelero & it seem's good "
                                   'example to start with). \r\n'
                                   'I wanted just to generate a binary file first, then '
                                   'make changes to adapt code with external '
                                   'accelerometer, itried this command:  _make -f '
                                   'tensorflow/lite/micro/tools/make/Makefile TARGET=mbed '
                                   'TAGS="CMSIS efm32pg_stk3401" magic_wand_bin_ but '
                                   'errors appear.\r\n'
                                   'Should i do some big modifications on project to run '
                                   'it on efr32/efm32 micro ?\r\n'
                                   "Thank's for your answers\r\n"
                                   '\r\n'
                                   '**Please provide the exact sequence of commands/steps '
                                   'when you ran into the problem**\r\n'
                                   '\r\n'
                                   ' _make -f tensorflow/lite/micro/tools/make/Makefile '
                                   'TARGET=mbed TAGS="CMSIS efm32pg_stk3401" '
                                   'magic_wand_bin\r\n'
                                   '\r\n',
                           'created_at': '2019-12-2'},
                          {'body': 'This PR addresses minor spelling tweaks under '
                                   '`tensorflow/lite` directory.\r\n'
                                   'follow-on of #34958',
                           'created_at': '2019-12-1'},
                          {'body': 'My application only requires kTfLiteInt8 kernels.\r\n'
                                   'However, kTfLiteFloat32 and kTfLiteUInt8 kernels are '
                                   'also built into the application.\r\n'
                                   '\r\n'
                                   'It would save a considerable amount of code space if '
                                   'there was a way to disable building in the unused '
                                   'data types, e.g.:\r\n'
                                   '```\r\n'
                                   '  switch (input->type) {  // Already know in/out '
                                   'types are same.\r\n'
                                   '#ifndef TFLITE_FLOAT32_DISABLED\r\n'
                                   '    case kTfLiteFloat32:\r\n'
                                   '      return EvalFloat(context, node, params, &data, '
                                   'input, filter, bias,\r\n'
                                   '                       nullptr, nullptr, output);\r\n'
                                   '      break;\r\n'
                                   '#endif \r\n'
                                   '#infdef TFLITE_INT8_DISABLED\r\n'
                                   '    case kTfLiteInt8:\r\n'
                                   '      return EvalQuantizedPerChannel(context, node, '
                                   'params, &data, input,\r\n'
                                   '                                     filter, bias, '
                                   'output, nullptr);\r\n'
                                   '      break; \r\n'
                                   '#endif \r\n'
                                   '#ifndef TFLITE_UINT8_DISABLED\r\n'
                                   '    case kTfLiteUInt8:\r\n'
                                   '      return EvalQuantized(context, node, params, '
                                   '&data, input, filter, bias,\r\n'
                                   '                           nullptr, nullptr, '
                                   'output);\r\n'
                                   '      break;\r\n'
                                   '#endif\r\n'
                                   '    default:\r\n'
                                   '      context->ReportError(context, "Type %s (%d) not '
                                   'supported.",\r\n'
                                   '                           '
                                   'TfLiteTypeGetName(input->type), input->type);\r\n'
                                   '      return kTfLiteError\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'Or something more elegant ;) \r\n',
                           'created_at': '2019-12-1'},
                          {'body': '', 'created_at': '2019-12-1'},
                          {'body': '<em>Please make sure that this is a '
                                   'build/installation issue. As per our [GitHub '
                                   'Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), '
                                   'we only address code/doc bugs, performance issues, '
                                   'feature requests and build/installation issues on '
                                   'GitHub. tag:build_template</em>\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- OS Platform Windows 10 Pro\r\n'
                                   '- desktop computer:\r\n'
                                   '- TensorFlow installed from source\r\n'
                                   '- TensorFlow version: 2.0\r\n'
                                   '- Python version: 3.7\r\n'
                                   '- Installed using virtualenv? pip? conda?: installed '
                                   'via command line / git clone etc.\r\n'
                                   '- Bazel version (if compiling from source): 1.1.0\r\n'
                                   '- GCC/Compiler version (if compiling from source): '
                                   'Visual Studio 2017 Redistributables\r\n'
                                   '- CUDA/cuDNN version: --- (ROCm selected)\r\n'
                                   '- GPU model and memory:  AMD FX-8800P R7\r\n'
                                   '\r\n'
                                   'Build fails, see listing below.\r\n'
                                   '\r\n'
                                   'C:\\Users\\Bludorf\\tensorflow>python '
                                   './configure.py\r\n'
                                   'WARNING: Running Bazel server needs to be killed, '
                                   'because the startup options are different.\r\n'
                                   'WARNING: Waiting for server process to terminate '
                                   '(waited 5 seconds, waiting at most 60)\r\n'
                                   'WARNING: Waiting for server process to terminate '
                                   '(waited 10 seconds, waiting at most 60)\r\n'
                                   'WARNING: --batch mode is deprecated. Please instead '
                                   'explicitly shut down your Bazel server using the '
                                   'command "bazel shutdown".\r\n'
                                   'You have bazel 1.1.0 installed.\r\n'
                                   'Please specify the location of python. [Default is '
                                   'C:\\Users\\Bludorf\\AppData\\Local\\Programs\\Python\\Python37\\python.exe]: \r\n'
                                   '\r\n'
                                   '\r\n'
                                   'Found possible Python library paths:\r\n'
                                   '  '
                                   'C:\\Users\\Bludorf\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\r\n'
                                   'Please input the desired Python library path to use.  '
                                   'Default is '
                                   '[C:\\Users\\Bludorf\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages]\r\n'
                                   '\r\n'
                                   'Do you wish to build TensorFlow with XLA JIT support? '
                                   '[y/N]: y\r\n'
                                   'XLA JIT support will be enabled for TensorFlow.\r\n'
                                   '\r\n'
                                   'Do you wish to build TensorFlow with ROCm support? '
                                   '[y/N]: y\r\n'
                                   'ROCm support will be enabled for TensorFlow.\r\n'
                                   '\r\n'
                                   'Do you wish to build TensorFlow with CUDA support? '
                                   '[y/N]: N\r\n'
                                   'No CUDA support will be enabled for TensorFlow.\r\n'
                                   '\r\n'
                                   'Please specify optimization flags to use during '
                                   'compilation when bazel option "--config=opt" is '
                                   'specified [Default is /arch:AVX]:\r\n'
                                   '\r\n'
                                   '\r\n'
                                   'Would you like to override eigen strong inline for '
                                   'some C++ compilation to reduce the compilation time? '
                                   '[Y/n]: Y\r\n'
                                   'Eigen strong inline overridden.\r\n'
                                   '\r\n'
                                   'Preconfigured Bazel build configs. You can use any of '
                                   'the below by adding "--config=<>" to your build '
                                   'command. See .bazelrc for more details.\r\n'
                                   '        --config=mkl            # Build with MKL '
                                   'support.\r\n'
                                   '        --config=monolithic     # Config for mostly '
                                   'static monolithic build.\r\n'
                                   '        --config=ngraph         # Build with Intel '
                                   'nGraph support.\r\n'
                                   '        --config=numa           # Build with NUMA '
                                   'support.\r\n'
                                   '        --config=dynamic_kernels        # '
                                   '(Experimental) Build kernels into separate shared '
                                   'objects.\r\n'
                                   '        --config=v2             # Build TensorFlow '
                                   '2.x instead of 1.x.\r\n'
                                   'Preconfigured Bazel build configs to DISABLE default '
                                   'on features:\r\n'
                                   '        --config=noaws          # Disable AWS S3 '
                                   'filesystem support.\r\n'
                                   '        --config=nogcp          # Disable GCP '
                                   'support.\r\n'
                                   '        --config=nohdfs         # Disable HDFS '
                                   'support.\r\n'
                                   '        --config=nonccl         # Disable NVIDIA NCCL '
                                   'support.\r\n'
                                   '\r\n'
                                   'C:\\Users\\Bludorf\\tensorflow>bazel build '
                                   '--config=v2 '
                                   '//tensorflow/tools/pip_package:build_pip_package\r\n'
                                   'Starting local Bazel server and connecting to '
                                   'it...\r\n'
                                   'WARNING: The following configs were expanded more '
                                   'than once: [v2]. For repeatable flags, repeats are '
                                   'counted twice and may lead to unexpected behavior.\r\n'
                                   'INFO: Writing tracer profile to '
                                   "'C:/users/bludorf/_bazel_bludorf/jkbqqwso/command.profile.gz'\r\n"
                                   'INFO: Options provided by the client:\r\n'
                                   "  Inherited 'common' options: --isatty=1 "
                                   '--terminal_columns=120\r\n'
                                   'INFO: Options provided by the client:\r\n'
                                   "  'build' options: "
                                   '--python_path=C:/Users/Bludorf/AppData/Local/Programs/Python/Python37/python.exe\r\n'
                                   "INFO: Reading rc options for 'build' from "
                                   'c:\\users\\bludorf\\tensorflow\\.bazelrc:\r\n'
                                   "  'build' options: --apple_platform_type=macos "
                                   '--define framework_shared_object=true --define '
                                   'open_source_build=true '
                                   '--java_toolchain=//third_party/toolchains/java:tf_java_toolchain '
                                   '--host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain '
                                   '--define=use_fast_cpp_protos=true '
                                   '--define=allow_oversize_protos=true '
                                   '--spawn_strategy=standalone -c opt --announce_rc '
                                   '--define=grpc_no_ares=true '
                                   '--noincompatible_remove_legacy_whole_archive '
                                   '--enable_platform_specific_config --config=v2\r\n'
                                   "INFO: Reading rc options for 'build' from "
                                   'c:\\users\\bludorf\\tensorflow\\.tf_configure.bazelrc:\r\n'
                                   "  'build' options: --action_env "
                                   'PYTHON_BIN_PATH=C:/Users/Bludorf/AppData/Local/Programs/Python/Python37/python.exe '
                                   '--action_env '
                                   'PYTHON_LIB_PATH=C:/Users/Bludorf/AppData/Local/Programs/Python/Python37/lib/site-packages '
                                   '--python_path=C:/Users/Bludorf/AppData/Local/Programs/Python/Python37/python.exe '
                                   '--config=xla --config=rocm '
                                   '--define=override_eigen_strong_inline=true '
                                   '--action_env TF_CONFIGURE_IOS=0\r\n'
                                   'INFO: Found applicable config definition build:v2 in '
                                   'file c:\\users\\bludorf\\tensorflow\\.bazelrc: '
                                   '--define=tf_api_version=2 '
                                   '--action_env=TF2_BEHAVIOR=1\r\n'
                                   'INFO: Found applicable config definition build:xla in '
                                   'file c:\\users\\bludorf\\tensorflow\\.bazelrc: '
                                   '--action_env=TF_ENABLE_XLA=1 '
                                   '--define=with_xla_support=true\r\n'
                                   'INFO: Found applicable config definition build:xla in '
                                   'file '
                                   'c:\\users\\bludorf\\tensorflow\\.tf_configure.bazelrc: '
                                   '--define with_xla_support=true\r\n'
                                   'INFO: Found applicable config definition build:rocm '
                                   'in file c:\\users\\bludorf\\tensorflow\\.bazelrc: '
                                   '--crosstool_top=@local_config_rocm//crosstool:toolchain '
                                   '--define=using_rocm=true '
                                   '--define=using_rocm_hipcc=true --action_env '
                                   'TF_NEED_ROCM=1\r\n'
                                   'INFO: Found applicable config definition build:v2 in '
                                   'file c:\\users\\bludorf\\tensorflow\\.bazelrc: '
                                   '--define=tf_api_version=2 '
                                   '--action_env=TF2_BEHAVIOR=1\r\n'
                                   'INFO: Found applicable config definition '
                                   'build:windows in file '
                                   'c:\\users\\bludorf\\tensorflow\\.bazelrc: --copt=/w '
                                   '--cxxopt=/std:c++14 --host_cxxopt=/std:c++14 '
                                   '--config=monolithic --copt=-DWIN32_LEAN_AND_MEAN '
                                   '--host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI '
                                   '--host_copt=-DNOGDI --linkopt=/DEBUG '
                                   '--host_linkopt=/DEBUG --linkopt=/OPT:REF '
                                   '--host_linkopt=/OPT:REF --linkopt=/OPT:ICF '
                                   '--host_linkopt=/OPT:ICF '
                                   '--experimental_strict_action_env=true '
                                   '--incompatible_windows_native_test_wrapper '
                                   '--verbose_failures '
                                   '--distinct_host_configuration=false\r\n'
                                   'INFO: Found applicable config definition '
                                   'build:monolithic in file '
                                   'c:\\users\\bludorf\\tensorflow\\.bazelrc: --define '
                                   'framework_shared_object=false\r\n'
                                   'INFO: Call stack for the definition of repository '
                                   "'io_bazel_rules_docker' which is a git_repository "
                                   '(rule definition at '
                                   'C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18):\r\n'
                                   ' - '
                                   'C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_toolchains/repositories/repositories.bzl:37:9\r\n'
                                   ' - C:/users/bludorf/tensorflow/WORKSPACE:37:1\r\n'
                                   'ERROR: An error occurred during the fetch of '
                                   "repository 'io_bazel_rules_docker':\r\n"
                                   '   Traceback (most recent call last):\r\n'
                                   '        File '
                                   '"C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_tools/tools/build_defs/repo/git.bzl", '
                                   'line 177\r\n'
                                   '                _clone_or_update(ctx)\r\n'
                                   '        File '
                                   '"C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_tools/tools/build_defs/repo/git.bzl", '
                                   'line 36, in _clone_or_update\r\n'
                                   '                git_repo(ctx, directory)\r\n'
                                   '        File '
                                   '"C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_tools/tools/build_defs/repo/git_worker.bzl", '
                                   'line 91, in git_repo\r\n'
                                   '                _update(ctx, git_repo)\r\n'
                                   '        File '
                                   '"C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_tools/tools/build_defs/repo/git_worker.bzl", '
                                   'line 101, in _update\r\n'
                                   '                init(ctx, git_repo)\r\n'
                                   '        File '
                                   '"C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_tools/tools/build_defs/repo/git_worker.bzl", '
                                   'line 115, in init\r\n'
                                   '                _error(ctx.name, cl, st.stderr)\r\n'
                                   '        File '
                                   '"C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_tools/tools/build_defs/repo/git_worker.bzl", '
                                   'line 181, in _error\r\n'
                                   '                fail(<1 more arguments>)\r\n'
                                   "error running 'git init "
                                   "C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/io_bazel_rules_docker' "
                                   'while working with @io_bazel_rules_docker:\r\n'
                                   'java.io.IOException: ERROR: '
                                   'src/main/native/windows/process.cc(199): '
                                   'CreateProcessW("git" init '
                                   'C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/io_bazel_rules_docker): '
                                   'Das System kann die angegebene Datei nicht finden.\r\n'
                                   ' (error: 2)\r\n'
                                   'ERROR: no such package '
                                   "'@io_bazel_rules_docker//repositories': Traceback "
                                   '(most recent call last):\r\n'
                                   '        File '
                                   '"C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_tools/tools/build_defs/repo/git.bzl", '
                                   'line 177\r\n'
                                   '                _clone_or_update(ctx)\r\n'
                                   '        File '
                                   '"C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_tools/tools/build_defs/repo/git.bzl", '
                                   'line 36, in _clone_or_update\r\n'
                                   '                git_repo(ctx, directory)\r\n'
                                   '        File '
                                   '"C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_tools/tools/build_defs/repo/git_worker.bzl", '
                                   'line 91, in git_repo\r\n'
                                   '                _update(ctx, git_repo)\r\n'
                                   '        File '
                                   '"C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_tools/tools/build_defs/repo/git_worker.bzl", '
                                   'line 101, in _update\r\n'
                                   '                init(ctx, git_repo)\r\n'
                                   '        File '
                                   '"C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_tools/tools/build_defs/repo/git_worker.bzl", '
                                   'line 115, in init\r\n'
                                   '                _error(ctx.name, cl, st.stderr)\r\n'
                                   '        File '
                                   '"C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_tools/tools/build_defs/repo/git_worker.bzl", '
                                   'line 181, in _error\r\n'
                                   '                fail(<1 more arguments>)\r\n'
                                   "error running 'git init "
                                   "C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/io_bazel_rules_docker' "
                                   'while working with @io_bazel_rules_docker:\r\n'
                                   'java.io.IOException: ERROR: '
                                   'src/main/native/windows/process.cc(199): '
                                   'CreateProcessW("git" init '
                                   'C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/io_bazel_rules_docker): '
                                   'Das System kann die angegebene Datei nicht finden.\r\n'
                                   ' (error: 2)\r\n'
                                   'ERROR: no such package '
                                   "'@io_bazel_rules_docker//repositories': Traceback "
                                   '(most recent call last):\r\n'
                                   '        File '
                                   '"C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_tools/tools/build_defs/repo/git.bzl", '
                                   'line 177\r\n'
                                   '                _clone_or_update(ctx)\r\n'
                                   '        File '
                                   '"C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_tools/tools/build_defs/repo/git.bzl", '
                                   'line 36, in _clone_or_update\r\n'
                                   '                git_repo(ctx, directory)\r\n'
                                   '        File '
                                   '"C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_tools/tools/build_defs/repo/git_worker.bzl", '
                                   'line 91, in git_repo\r\n'
                                   '                _update(ctx, git_repo)\r\n'
                                   '        File '
                                   '"C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_tools/tools/build_defs/repo/git_worker.bzl", '
                                   'line 101, in _update\r\n'
                                   '                init(ctx, git_repo)\r\n'
                                   '        File '
                                   '"C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_tools/tools/build_defs/repo/git_worker.bzl", '
                                   'line 115, in init\r\n'
                                   '                _error(ctx.name, cl, st.stderr)\r\n'
                                   '        File '
                                   '"C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/bazel_tools/tools/build_defs/repo/git_worker.bzl", '
                                   'line 181, in _error\r\n'
                                   '                fail(<1 more arguments>)\r\n'
                                   "error running 'git init "
                                   "C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/io_bazel_rules_docker' "
                                   'while working with @io_bazel_rules_docker:\r\n'
                                   'java.io.IOException: ERROR: '
                                   'src/main/native/windows/process.cc(199): '
                                   'CreateProcessW("git" init '
                                   'C:/users/bludorf/_bazel_bludorf/jkbqqwso/external/io_bazel_rules_docker): '
                                   'Das System kann die angegebene Datei nicht finden.\r\n'
                                   ' (error: 2)\r\n'
                                   'INFO: Elapsed time: 7.563s\r\n'
                                   'INFO: 0 processes.\r\n'
                                   'FAILED: Build did NOT complete successfully (0 '
                                   'packages loaded)\r\n'
                                   '\r\n',
                           'created_at': '2019-12-1'},
                          {'body': 'Incompatible flag '
                                   '--incompatible_restrict_string_escapes will break '
                                   'TensorFlow once Bazel 1.2.1 is released.\n'
                                   '\n'
                                   'Please see the following CI builds for more '
                                   'information:\n'
                                   '\n'
                                   '* [:darwin: (OpenJDK 8)](<a '
                                   'href="https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/342#042f4c72-2a23-4d7b-9d3b-d78619ea3fc7" '
                                   'target="_blank">:darwin: (OpenJDK 8)</a>)\n'
                                   '* [:windows: (OpenJDK 8)](<a '
                                   'href="https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/342#65246ccf-c676-40de-b693-3e1408052faa" '
                                   'target="_blank">:windows: (OpenJDK 8)</a>)\n'
                                   '* [:ubuntu: 18.04 (OpenJDK 11)](<a '
                                   'href="https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/342#42574ec2-097a-4fa6-9c82-5de0093a2ed1" '
                                   'target="_blank">:ubuntu: 18.04 (OpenJDK 11)</a>)\n'
                                   '\n'
                                   'Questions? Please file an issue in '
                                   'https://github.com/bazelbuild/continuous-integration\n'
                                   '\n'
                                   '**Important**: Please do NOT modify the issue title '
                                   'since that might break our tools.\n',
                           'created_at': '2019-12-1'},
                          {'body': 'Incompatible flag '
                                   '--incompatible_load_cc_rules_from_bzl will break '
                                   'TensorFlow once Bazel 1.2.1 is released.\n'
                                   '\n'
                                   'Please see the following CI builds for more '
                                   'information:\n'
                                   '\n'
                                   '* [:darwin: (OpenJDK 8)](<a '
                                   'href="https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/342#042f4c72-2a23-4d7b-9d3b-d78619ea3fc7" '
                                   'target="_blank">:darwin: (OpenJDK 8)</a>)\n'
                                   '* [:windows: (OpenJDK 8)](<a '
                                   'href="https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/342#65246ccf-c676-40de-b693-3e1408052faa" '
                                   'target="_blank">:windows: (OpenJDK 8)</a>)\n'
                                   '* [:ubuntu: 18.04 (OpenJDK 11)](<a '
                                   'href="https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/342#42574ec2-097a-4fa6-9c82-5de0093a2ed1" '
                                   'target="_blank">:ubuntu: 18.04 (OpenJDK 11)</a>)\n'
                                   '\n'
                                   'Questions? Please file an issue in '
                                   'https://github.com/bazelbuild/continuous-integration\n'
                                   '\n'
                                   '**Important**: Please do NOT modify the issue title '
                                   'since that might break our tools.\n',
                           'created_at': '2019-12-1'},
                          {'body': 'Incompatible flag '
                                   '--incompatible_no_implicit_file_export will break '
                                   'TensorFlow once Bazel 1.2.1 is released.\n'
                                   '\n'
                                   'Please see the following CI builds for more '
                                   'information:\n'
                                   '\n'
                                   '* [:darwin: (OpenJDK 8)](<a '
                                   'href="https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/342#042f4c72-2a23-4d7b-9d3b-d78619ea3fc7" '
                                   'target="_blank">:darwin: (OpenJDK 8)</a>)\n'
                                   '* [:windows: (OpenJDK 8)](<a '
                                   'href="https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/342#65246ccf-c676-40de-b693-3e1408052faa" '
                                   'target="_blank">:windows: (OpenJDK 8)</a>)\n'
                                   '* [:ubuntu: 18.04 (OpenJDK 11)](<a '
                                   'href="https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/342#42574ec2-097a-4fa6-9c82-5de0093a2ed1" '
                                   'target="_blank">:ubuntu: 18.04 (OpenJDK 11)</a>)\n'
                                   '\n'
                                   'Questions? Please file an issue in '
                                   'https://github.com/bazelbuild/continuous-integration\n'
                                   '\n'
                                   '**Important**: Please do NOT modify the issue title '
                                   'since that might break our tools.\n',
                           'created_at': '2019-12-1'},
                          {'body': 'Incompatible flag --incompatible_disallow_empty_glob '
                                   'will break TensorFlow once Bazel 1.2.1 is released.\n'
                                   '\n'
                                   'Please see the following CI builds for more '
                                   'information:\n'
                                   '\n'
                                   '* [:darwin: (OpenJDK 8)](<a '
                                   'href="https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/342#042f4c72-2a23-4d7b-9d3b-d78619ea3fc7" '
                                   'target="_blank">:darwin: (OpenJDK 8)</a>)\n'
                                   '* [:windows: (OpenJDK 8)](<a '
                                   'href="https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/342#65246ccf-c676-40de-b693-3e1408052faa" '
                                   'target="_blank">:windows: (OpenJDK 8)</a>)\n'
                                   '* [:ubuntu: 18.04 (OpenJDK 11)](<a '
                                   'href="https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/342#42574ec2-097a-4fa6-9c82-5de0093a2ed1" '
                                   'target="_blank">:ubuntu: 18.04 (OpenJDK 11)</a>)\n'
                                   '\n'
                                   'Questions? Please file an issue in '
                                   'https://github.com/bazelbuild/continuous-integration\n'
                                   '\n'
                                   '**Important**: Please do NOT modify the issue title '
                                   'since that might break our tools.\n',
                           'created_at': '2019-12-1'},
                          {'body': '<em>Please make sure that this is a feature request. '
                                   'As per our [GitHub '
                                   'Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), '
                                   'we only address code/doc bugs, performance issues, '
                                   'feature requests and build/installation issues on '
                                   'GitHub. tag:feature_template</em>\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- TensorFlow version (you are using): 2.0.0\r\n'
                                   '- Are you willing to contribute it (Yes/No): Yes\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Describe the feature and the current '
                                   'behavior/state.**\r\n'
                                   'Currently, whenever user loads keras models using '
                                   'HDF5, user gets no confirmation that models were '
                                   'loaded successfully '
                                   '([\\[1\\]](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#load_weights), '
                                   '[\\[2\\]](https://www.tensorflow.org/api_docs/python/tf/keras/Model?version=stable#load_weights) '
                                   'return nothing). This confirmation could be useful '
                                   'for verifying that weights are properly loaded. In '
                                   'case of transfer learning, users typically only want '
                                   'to load specific weights from the HDF5file. This can '
                                   'be currently achieved by using '
                                   "`load_weights(by_name=True)`, however, users don't "
                                   'get any confirmation about which layers were actually '
                                   'loaded.\r\n'
                                   '\r\n'
                                   'Also, in case there are no matching layers in between '
                                   'the original model and source model, the '
                                   '`model.load_weights(by_name=True)` fails without '
                                   'raising any exception so there is no way to actually '
                                   'debug what went wrong with the model loading. (Note '
                                   "here that I'm talking about name mismatch not weight "
                                   'mismatch) This significantly affects the ability to '
                                   'write unit tests for models since the tester code '
                                   'cannot actually verify what layers were loaded from '
                                   'HDF5 file.\r\n'
                                   '\r\n'
                                   '**Will this change the current api? How?**\r\n'
                                   'Yes, this changes the current API for '
                                   '[\\[1\\]](https://www.tensorflow.org/api_docs/python/tf/keras/Model?version=stable#load_weights) '
                                   'and '
                                   '[\\[2\\]](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#load_weights) '
                                   'by adding a return type to them. Specifically, we '
                                   'will be returning a particular data structure when '
                                   'loading HDF5 files '
                                   '[here](https://github.com/tensorflow/tensorflow/blob/c49396cf71dacc32195033507b3bbd985b12c255/tensorflow/python/keras/engine/network.py#L1131). '
                                   'My current idea is to return the list of layers that '
                                   "were loaded from HDF5 although I'm open to discussion "
                                   'about the return type.\r\n'
                                   '\r\n'
                                   '**Who will benefit with this feature?**\r\n'
                                   'Users who are loading their weights from h5py files '
                                   'and want to verify/check what layers were loaded from '
                                   'HDF5. \r\n'
                                   '\r\n'
                                   '**Any Other info.**\r\n'
                                   'N/A\r\n'
                                   '\r\n'
                                   '\r\n'
                                   'Let me know if any more clarification/information is '
                                   "needed. I'm willing to contribute by working on this "
                                   'issue.',
                           'created_at': '2019-12-1'},
                          {'body': 'I am also facing a similar issue.\r\n'
                                   'The demo API gives error at tflite.load_delegate.\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'pi@bpi-iot-ros-ai:~/coral/tflite/python/examples/classification$ '
                                   'python3 classify_image.py --model '
                                   'models/mobilenet_v2_1.0_224_inat_bird_quant_edgetpu.tflite '
                                   '--labels models/inat_bird_labels.txt --input '
                                   'images/parrot.jpg\r\n'
                                   'E :248] HIB Error. hib_error_status = '
                                   '0000000000000001, hib_first_error_status = '
                                   '0000000000000001\r\n'
                                   'E :248] HIB Error. hib_error_status = '
                                   '0000000000000001, hib_first_error_status = '
                                   '0000000000000001\r\n'
                                   'INFO: Initialized TensorFlow Lite runtime.\r\n'
                                   '----INFERENCE TIME----\r\n'
                                   'Note: The first inference on Edge TPU is slow because '
                                   'it includes loading the model into Edge TPU '
                                   'memory.\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '\r\n'
                                   'pi@bpi-iot-ros-ai:~$ uname -a\r\n'
                                   'Linux bpi-iot-ros-ai 5.4.0-bpi-r64 #1 SMP PREEMPT Mon '
                                   'Dec 16 16:00:08 IST 2019 aarch64 aarch64 aarch64 '
                                   'GNU/Linux\r\n'
                                   'pi@bpi-iot-ros-ai:~$ lscpu\r\n'
                                   'Architecture:          aarch64\r\n'
                                   'Byte Order:            Little Endian\r\n'
                                   'CPU(s):                2\r\n'
                                   'On-line CPU(s) list:   0,1\r\n'
                                   'Thread(s) per core:    1\r\n'
                                   'Core(s) per socket:    2\r\n'
                                   'Socket(s):             1\r\n'
                                   'CPU max MHz:           1350.0000\r\n'
                                   'CPU min MHz:           30.0000\r\n'
                                   'pi@bpi-iot-ros-ai:~$ ls -l '
                                   '/usr/lib/aarch64-linux-gnu/libedge*\r\n'
                                   'lrwxrwxrwx 1 root root     17 Sep 17 04:27 '
                                   '/usr/lib/aarch64-linux-gnu/libedgetpu.so.1 -> '
                                   'libedgetpu.so.1.0\r\n'
                                   '-rwxrwxrwx 1 root root 792376 Sep 17 04:27 '
                                   '/usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0\r\n'
                                   'pi@bpi-iot-ros-ai:~$ lspci\r\n'
                                   '00:00.0 PCI bridge: MEDIATEK Corp. Device 3258\r\n'
                                   '01:00.0 System peripheral: Device 1ac1:089a\r\n'
                                   'pi@bpi-iot-ros-ai:~$ ls /dev/apex_0 \r\n'
                                   '/dev/apex_0\r\n'
                                   'pi@bpi-iot-ros-ai:~$ sudo sh -c "echo '
                                   '\'SUBSYSTEM==\\"apex\\", MODE=\\"0660\\", '
                                   'GROUP=\\"apex\\"\' >> '
                                   '/etc/udev/rules.d/65-apex.rules"\r\n'
                                   'pi@bpi-iot-ros-ai:~$ sudo groupadd apex\r\n'
                                   "groupadd: group 'apex' already exists\r\n"
                                   'pi@bpi-iot-ros-ai:~$ sudo adduser $USER apex\r\n'
                                   "The user `pi' is already a member of `apex'.\r\n"
                                   '```\r\n',
                           'created_at': '2019-12-1'},
                          {'body': '<em>Please make sure that this is a bug. As per our '
                                   '[GitHub '
                                   'Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), '
                                   'we only address code/doc bugs, performance issues, '
                                   'feature requests and build/installation issues on '
                                   'GitHub. tag:bug_template</em>\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): '
                                   'https://github.com/cogaplex-bts/bts\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): ubuntu 1604\r\n'
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device:\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'pip\r\n'
                                   '- TensorFlow version (use command below):1.13.2\r\n'
                                   '- Python version: 3.7\r\n'
                                   '- Bazel version (if compiling from source):\r\n'
                                   '- GCC/Compiler version (if compiling from source): '
                                   'pip \r\n'
                                   '- CUDA/cuDNN version: 10.0 \r\n'
                                   '- GPU model and memory: 1060, 6G\r\n'
                                   '\r\n'
                                   'You can collect some of this information using our '
                                   'environment capture\r\n'
                                   '[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\n'
                                   'You can also obtain the TensorFlow version with: 1. '
                                   'TF 1.0: `python -c "import\r\n'
                                   'tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"` '
                                   '2. TF 2.0: `python -c\r\n'
                                   '"import tensorflow as tf; '
                                   'print(tf.version.GIT_VERSION, '
                                   'tf.version.VERSION)"`\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'in a process, use full path , twice load:\r\n'
                                   'tf.load_op_library(os.path.join(dname, '
                                   "'build/libcompute_depth.so'))\r\n"
                                   'the second time, OP_LIST is empty, \r\n'
                                   'but with relative path, twice  tf.load_op_library not '
                                   'empty\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   'use full path, twice  tf.load_op_library, OP_LIST '
                                   'should not empty\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   'Provide a reproducible test case that is the bare '
                                   'minimum necessary to generate the problem.\r\n'
                                   'I compile https://github.com/cogaplex-bts/bts, met '
                                   'this problem. But I think this is a general problem, '
                                   'reproduce: just in a python file, load the library '
                                   'twice, with full path and relative path   \r\n'
                                   '**Other info / logs**\r\n'
                                   'Include any logs or source code that would be helpful '
                                   'to diagnose the problem. If including tracebacks, '
                                   'please include the full traceback. Large logs and '
                                   'files should be attached.\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   "compute_depth_grad_module dict: {'__name__': "
                                   "'a11935c229913616b7b14d8da52f01ac', '__doc__': "
                                   "'Python wrappers around TensorFlow ops.\\n\\nThis "
                                   "file is MACHINE GENERATED! Do not edit.\\n', ...  , "
                                   "'LIB_HANDLE': <Swig Object of type 'TF_Library *' at "
                                   "0x7ff4ad011f60>, 'OP_LIST': op {\r\n"
                                   '  name: "ComputeDepth"\r\n'
                                   '  input_arg {\r\n'
                                   '    name: "input"\r\n'
                                   '    type: DT_FLOAT\r\n'
                                   '  }\r\n'
                                   '  input_arg {\r\n'
                                   '    name: "focal"\r\n'
                                   '    type: DT_FLOAT\r\n'
                                   '  }\r\n'
                                   '  output_arg {\r\n'
                                   '    name: "depth"\r\n'
                                   '    type: DT_FLOAT\r\n'
                                   '  }\r\n'
                                   '  attr {\r\n'
                                   '    name: "upratio"\r\n'
                                   '    type: "int"\r\n'
                                   '  }\r\n'
                                   '}\r\n'
                                   'op {\r\n'
                                   '  name: "ComputeDepthGrad"\r\n'
                                   '  input_arg {\r\n'
                                   '    name: "depth_grad"\r\n'
                                   '    type: DT_FLOAT\r\n'
                                   '  }\r\n'
                                   '  input_arg {\r\n'
                                   '    name: "input"\r\n'
                                   '    type: DT_FLOAT\r\n'
                                   '  }\r\n'
                                   '  input_arg {\r\n'
                                   '    name: "focal"\r\n'
                                   '    type: DT_FLOAT\r\n'
                                   '  }\r\n'
                                   '  output_arg {\r\n'
                                   '    name: "grad_input"\r\n'
                                   '    type: DT_FLOAT\r\n'
                                   '  }\r\n'
                                   '  output_arg {\r\n'
                                   '    name: "grad_focal"\r\n'
                                   '    type: DT_FLOAT\r\n'
                                   '  }\r\n'
                                   '}\r\n'
                                   '}\r\n'
                                   "{'__name__': 'a11935c229913616b7b14d8da52f01ac', "
                                   "'__doc__': 'Python wrappers around TensorFlow "
                                   'ops.\\n\\nThis file is MACHINE GENERATED! Do not '
                                   "edit.\\n', '__package__': None,  ... , 'LIB_HANDLE': "
                                   "<Swig Object of type 'TF_Library *' at "
                                   "0x7ff4ad011f60>, 'OP_LIST': op {\r\n"
                                   '  name: "ComputeDepth"\r\n'
                                   '  input_arg {\r\n'
                                   '    name: "input"\r\n'
                                   '    type: DT_FLOAT\r\n'
                                   '  }\r\n'
                                   '  input_arg {\r\n'
                                   '    name: "focal"\r\n'
                                   '    type: DT_FLOAT\r\n'
                                   '  }\r\n'
                                   '  output_arg {\r\n'
                                   '    name: "depth"\r\n'
                                   '    type: DT_FLOAT\r\n'
                                   '  }\r\n'
                                   '  attr {\r\n'
                                   '    name: "upratio"\r\n'
                                   '    type: "int"\r\n'
                                   '  }\r\n'
                                   '}\r\n'
                                   'op {\r\n'
                                   '  name: "ComputeDepthGrad"\r\n'
                                   '  input_arg {\r\n'
                                   '    name: "depth_grad"\r\n'
                                   '    type: DT_FLOAT\r\n'
                                   '  }\r\n'
                                   '  input_arg {\r\n'
                                   '    name: "input"\r\n'
                                   '    type: DT_FLOAT\r\n'
                                   '  }\r\n'
                                   '  input_arg {\r\n'
                                   '    name: "focal"\r\n'
                                   '    type: DT_FLOAT\r\n'
                                   '  }\r\n'
                                   '  output_arg {\r\n'
                                   '    name: "grad_input"\r\n'
                                   '    type: DT_FLOAT\r\n'
                                   '  }\r\n'
                                   '  output_arg {\r\n'
                                   '    name: "grad_focal"\r\n'
                                   '    type: DT_FLOAT\r\n'
                                   '  }\r\n'
                                   '}\r\n'
                                   '}\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'but with full name, second will print:\r\n'
                                   '```\r\n'
                                   "compute_depth_grad_module dict: {'__name__': "
                                   "'670cc8cfec5b6d3b8635f39bd583d769', '__doc__': "
                                   "'Python wrappers around TensorFlow ops.\\n\\nThis "
                                   "file is MACHINE GENERATED! Do not edit.\\n', "
                                   "'__package__': None, ... , 'LIB_HANDLE': <Swig Object "
                                   "of type 'TF_Library *' at 0x7f6b2a8f3e70>, 'OP_LIST': "
                                   '}\r\n'
                                   '```\r\n',
                           'created_at': '2019-12-1'},
                          {'body': 'Object detection SSD trained and tested to produce '
                                   'expected results in PC. \r\n'
                                   'http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz\r\n'
                                   'https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/ssd_inception_v2_pets.config\r\n'
                                   '\r\n'
                                   'Model works well and produces accurate results on '
                                   'PC. \r\n'
                                   'After converting to tflite and loading in mobile, the '
                                   'camera view shows incorrect detection (several '
                                   'detection of same class and in fixed place even when '
                                   'moving the camera).',
                           'created_at': '2019-12-1'},
                          {'body': 'This PR is trying to resolve the issue in #35179\r\n'
                                   'where boringssl was not the latest version. The old '
                                   'version\r\n'
                                   '7f63442 was released one and half year ago so it is '
                                   'time to update.\r\n'
                                   '\r\n'
                                   'This PR updates boringssl to the latest 80ca9f9.\r\n'
                                   '\r\n'
                                   'This PR fixes #35179.\r\n'
                                   '\r\n'
                                   'Signed-off-by: Yong Tang '
                                   '<yong.tang.github@outlook.com>',
                           'created_at': '2019-12-1'},
                          {'body': 'Add TfLite micro ExpandDims reference kernel and '
                                   'tests (int8, uint8, float32)\r\n'
                                   '\r\n'
                                   'Signed-off-by: SiCongLi <sicong.li@arm.com>',
                           'created_at': '2019-12-1'},
                          {'body': 'Dear all,\r\n'
                                   ' I have a point about DropoutWrapper and its use with '
                                   'Recurrent Neural Networks.\r\n'
                                   '\r\n'
                                   'Due to the possibility that the dropout can be '
                                   'applied to the state or the output (state_keep_prob '
                                   'and output_keep_prob), I found that, during the '
                                   'recurrent process, the state propagated through the '
                                   'time can take values not bounded in the interval [-1, '
                                   '1]. This is probably due to the way in which the '
                                   'dropout is implemented (at training time with a '
                                   'scaling instead of testing time with expectation). '
                                   'Since the dropout is applied after the activation '
                                   '(i.e. tanh), the feature values will range between '
                                   '-inf and +inf. This point is a bit strange for me '
                                   'since the current implementation can induce exploding '
                                   'gradient issues in the GRU/LSTM process while such '
                                   'cells were introduced to deal with vanishing as well '
                                   'as exploding gradients.\r\n'
                                   '\r\n'
                                   'Please, could you supply me some feedback about my '
                                   'issue since, practically, it can impact people that '
                                   'commonly employ such Wrapper that induces behaviours '
                                   'that are divergent w.r.t. the theoretical behaviour '
                                   'of RNN (GRU/LSTM).\r\n'
                                   '\r\n'
                                   'All the best\r\n',
                           'created_at': '2019-12-1'},
                          {'body': '**System information**\r\n'
                                   '- OS Platform: Windows10\r\n'
                                   '- TensorFlow installed from:source\r\n'
                                   '- TensorFlow version:1.13.0\r\n'
                                   '- Python version: NO\r\n'
                                   '- Bazel version (if compiling from source):0.19\r\n'
                                   '- GCC/Compiler version: msvc14\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Describe the problem**\r\n'
                                   'I want to build tensorflow from the source using the '
                                   'below command \r\n'
                                   '`bazel build -c opt  --config=mkl --config=monolithic '
                                   '--linkopt="/FORCE:MULTIPLE" '
                                   '--define=no_tensorflow_py_deps=true '
                                   '//tensorflow:libtensorflow_cc.so '
                                   '//tensorflow:install_headers   '
                                   '//tensorflow/tools/lib_package:libtensorflow '
                                   '--verbose_failures`\r\n'
                                   '\r\n'
                                   'However after the dll file generated, some symbol is '
                                   'not inside of the dll, I will paste some of this '
                                   'error in here(As far as I know this problem is '
                                   'accured because number of symbol is limited in '
                                   "windows, So all functions in tensorflow source can't "
                                   'be exported( I _check the exported function using '
                                   "dumpbin.exe /EXPORT and it's weird because only 3000 "
                                   'symbols is exported )_\r\n'
                                   '`tfwrapper.obj : error LNK2001: unresolved external '
                                   'symbol "class tensorflow::Output __cdecl '
                                   'tensorflow::ops::Const(class tensorflow::Scope const '
                                   '&,struct tensorflow::Input::Initializer const &)" '
                                   '(?Const@ops@tensorflow@@YA?AVOutput@2@AEBVScope@2@AEBUInitializer@Input@2@@Z)`\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '`tfwrapper.obj : error LNK2001: unresolved external '
                                   'symbol "public: __cdecl '
                                   'tensorflow::ops::DecodePng::DecodePng(class '
                                   'tensorflow::Scope const &,class '
                                   'tensorflow::Input,struct '
                                   'tensorflow::ops::DecodePng::Attrs const &)" '
                                   '(??0DecodePng@ops@tensorflow@@QEAA@AEBVScope@2@VInput@2@AEBUAttrs@012@@Z)`\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '`tfwrapper.obj : error LNK2001: unresolved external '
                                   'symbol "public: __cdecl '
                                   'tensorflow::ops::Placeholder::Placeholder(class '
                                   'tensorflow::Scope const &,enum tensorflow::DataType)" '
                                   '(??0Placeholder@ops@tensorflow@@QEAA@AEBVScope@2@W4DataType@2@@Z)`\r\n'
                                   '\r\n'
                                   'and for solving this issue I work on two idea\r\n'
                                   ' **first one** is using `def_file_filter.py.tpl`, as '
                                   'may you know in this file I have to add missed symbol '
                                   'to it like below(I just paste some of them in here) '
                                   'and reconfigure & recompile the source(I guess). But '
                                   "this solution can't export any of this missing symbol "
                                   'for me\r\n'
                                   '\r\n'
                                   '     # Header for the def file.\r\n'
                                   '     def_fp.write("LIBRARY " + args.target + '
                                   '"\\n")\r\n'
                                   '    def_fp.write("EXPORTS\\n")\r\n'
                                   '    def_fp.write("\\t '
                                   '??1OpDef@tensorflow@@UEAA@XZ\\n")\r\n'
                                   '\tdef_fp.write("\\t '
                                   '??0DecodePng@ops@tensorflow@@QEAA@AEBVScope@2@VInput@2@AEBUAttrs@012@@Z\\n")\r\n'
                                   '\tdef_fp.write("\\t '
                                   '??6tensorflow@@YAAEAV?$basic_ostream@DU?$char_traits@D@std@@@std@@AEAV12@AEBVStatus@0@@Z\\n")`\r\n'
                                   '\r\n'
                                   '\r\n'
                                   "So, I can't solve my problem using this method. So I "
                                   'use another Idea that I got this Idea from `ashley '
                                   'tharp` (you can see her great work in this[ '
                                   'link](https://github.com/robosina/stuff/tree/master/ai/tensorflow/build_tensorflow_1.14_source_for_Windows)) '
                                   'and this workaround solve 8 of this problems. Main '
                                   'idea of her is to add `TF_EXPORT` macro to the '
                                   'function names to force symbol to include in the dll '
                                   'file. but my problem is raised in the DecodePng file, '
                                   'there is a function in tensorflow source '
                                   '->`tensorflow/core/kernels/decode_image_op.cc` the '
                                   'function signature is \r\n'
                                   '     \r\n'
                                   '     void DecodePng(OpKernelContext* context, '
                                   'StringPiece input)\r\n'
                                   " I can't find any other. But in examples of the "
                                   'tensorflow we will see this way to read png files\r\n'
                                   '\r\n'
                                   '    image_reader = '
                                   'DecodePng(root.WithOpName("png_reader"), '
                                   'file_reader,\r\n'
                                   '                             '
                                   'DecodePng::Channels(wanted_channels));\r\n'
                                   "this two function is not same and I couldn't find "
                                   'this function in the tensorflow source code so I '
                                   "can't add `TF_EXPORT` macro to it, but how it is "
                                   'possible to use a function that is not present in '
                                   'source code?? So I look in the bazel genereated files '
                                   'and this function is in there.(it is in '
                                   '`bazel-source/bazel-out/x64_windows-opt/genfiles/tensorflow/cc/ops/image_ops.h`)\r\n'
                                   '\r\n'
                                   '     DecodePng(const ::tensorflow::Scope& scope, '
                                   '::tensorflow::Input contents);\r\n'
                                   '     DecodePng(const ::tensorflow::Scope& scope, '
                                   '::tensorflow::Input contents, const\r\n'
                                   '          DecodePng::Attrs& attrs);\r\n'
                                   '\r\n'
                                   " I don't know exactly how bazel created it and how to "
                                   'add `TF_EXPORT` macro to it(because this files is '
                                   "machine generated files and you can't add TF_EXPORT "
                                   'to it, because it will be overwritten in compile '
                                   'time)',
                           'created_at': '2019-12-1'},
                          {'body': '### **System information**\r\n'
                                   '- OS Platform and Distribution: Linux Ubuntu 16.04\r\n'
                                   '- Mobile device: LG G7\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'Source\r\n'
                                   '- TensorFlow version: r2.0\r\n'
                                   '- Python version: 3.5\r\n'
                                   '- Bazel version: 0.24.1\r\n'
                                   '- Android NDK version: r17c\r\n'
                                   '- GCC/Compiler version (if compiling from source): '
                                   'GCC 4.8\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '### **Describe the problem**\r\n'
                                   'Built Tensorflow lite from source, but the inference '
                                   'is about 3 times slower than original.\r\n'
                                   "(What I mean by 'original' is the prebuilt "
                                   'tensorflow-lite downloaded from Maven repository.)\r\n'
                                   'For example, the model which originally costs 20 ms '
                                   'on GPU takes 50 ms.\r\n'
                                   'I tried different versions of Tensorflow and Android '
                                   'NDK but resulted all same.\r\n'
                                   '\r\n'
                                   "Below is the process I've done to build tensorflow "
                                   'lite libraries.\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**1. Download Tensorflow source code from github**\r\n'
                                   '```shell\r\n'
                                   '$ git clone '
                                   'https://github.com/tensorflow/tensorflow.git\r\n'
                                   '$ git checkout r2.0\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '**2. Download Android NDK and install standalone '
                                   'toolchains**\r\n'
                                   'Download NDK r17c from '
                                   '[here](https://developer.android.com/ndk/downloads/older_releases.html).\r\n'
                                   'Extract files and move to Android Sdk directory.\r\n'
                                   '```shell\r\n'
                                   '$ cd Android/Sdk/android-ndk-r17c\r\n'
                                   '$ python build/tools/make_standalone_toolchain.py '
                                   '--arch arm64 --api 21\r\n'
                                   '$ export ANDROID_NDK=/path/to/ndk\r\n'
                                   '$ export ANDROID_NDK_HOME=$ANDROID_NDK\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '**3. Download and install Bazel**\r\n'
                                   'Download installer script from '
                                   '[here](https://github.com/bazelbuild/bazel/releases/0.24.1).\r\n'
                                   '```shell\r\n'
                                   '$ cd /path/to/download\r\n'
                                   '$ chmod +x bazel-0.24.1-installer-linux-x86_64.sh\r\n'
                                   '$ ./bazel-0.24.1-installer-linux-x86_64.sh --user\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '**4. Build tensorflow-lite.aar and '
                                   'tensorflow-lite-gpu.aar**\r\n'
                                   '```shell\r\n'
                                   '$ cd tensorflow\r\n'
                                   '$ ./configure\r\n'
                                   "$ bazel build --cxxopt='--std=c++11' -c opt "
                                   '--fat_apk_cpu=arm64-v8a,armeabi-v7a '
                                   'tensorflow/lite/java:tensorflow-lite\r\n'
                                   "$ bazel build --cxxopt='--std=c++11' -c opt "
                                   '--fat_apk_cpu=arm64-v8a,armeabi-v7a '
                                   'tensorflow/lite/java:tensorflow-lite-gpu\r\n'
                                   '```\r\n'
                                   "On `./configure`, set all 'n' for support question "
                                   'and leave others on default.\r\n'
                                   '\r\n'
                                   '| Configuration | Value |\r\n'
                                   '| --- | --- |\r\n'
                                   '| XLA JIT support | No |\r\n'
                                   '| OpenCL SYCL support | No |\r\n'
                                   '| ROCm support | No |\r\n'
                                   '| CUDA support | No |\r\n'
                                   '| Fresh released clang | No |\r\n'
                                   '| MPI support | No |\r\n'
                                   '| Bazel comilation option | Default |\r\n'
                                   '| Android ./WORKSPACE configuration | Yes |\r\n'
                                   '| Android NDK API level | 22 |\r\n'
                                   '| Android SDK path | Default |\r\n'
                                   '| Android SDK API level | Default (29) |\r\n'
                                   '| Android build tools version | Default (29.0.2) |\r\n'
                                   '\r\n'
                                   '**5. Import libraries to Android project**\r\n'
                                   'Copy the generated `.aar` files into Android project, '
                                   'and change `build.gradle` file:\r\n'
                                   '\r\n'
                                   '```gradle\r\n'
                                   'dependencies {\r\n'
                                   '    ...\r\n'
                                   '    implementation '
                                   "files('libs/tensorflow-lite.aar')\r\n"
                                   '    implementation '
                                   "files('libs/tensorflow-lite-gpu.aar')\r\n"
                                   '\r\n'
                                   '    // implementation '
                                   "'org.tensorflow:tensorflow-lite:2.0.0'\r\n"
                                   '    // implementation '
                                   "'org.tensorflow:tensorflow-lite-gpu:2.0.0'\r\n"
                                   '}\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '\r\n'
                                   'Any suggestion or help will be appreciated.\r\n'
                                   'Thanks in advance.',
                           'created_at': '2019-12-1'},
                          {'body': "I'd like to understand the performance issue I faced "
                                   ':\r\n'
                                   'Why TF2.0+TRT6 (keras) slower than TF1+keras about 4 '
                                   'times ?\r\n'
                                   '\r\n'
                                   'GPU K80\r\n'
                                   '\r\n'
                                   'before : TF1 + keras (as separate package)\r\n'
                                   'after: TF2 + TRT6 integrated with integrated keras\r\n'
                                   '\r\n'
                                   "on the same example TF2 is 4 times slower, when I'm "
                                   'waiting acceleration of training/predition in new '
                                   'version with TRT integration.\r\n'
                                   '\r\n',
                           'created_at': '2019-12-1'},
                          {'body': '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): Yes\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Ubuntu 18.04.3 LTS (in docker container)\r\n'
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device: NA\r\n'
                                   '- TensorFlow installed from (source or binary): pip '
                                   'wheel\r\n'
                                   '- TensorFlow version (use command below): 2.0.0\r\n'
                                   '- Python version: 3.6.8 \r\n'
                                   '- Bazel version (if compiling from source): NA\r\n'
                                   '- GCC/Compiler version (if compiling from source): '
                                   'NA\r\n'
                                   '- CUDA/cuDNN version: NA\r\n'
                                   '- GPU model and memory: NA\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'The training is down due to low layer system call '
                                   '(corrupted size vs. prev_size). the process is '
                                   'immediately corrupted without much log to trace.\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   'the estimator (BoostedTreesRegressor) should be '
                                   'trained in normal.\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   '```\r\n'
                                   'import os\r\n'
                                   'import uuid\r\n'
                                   'import json\r\n'
                                   'from io import StringIO\r\n'
                                   '\r\n'
                                   'import pandas as pd\r\n'
                                   'import tensorflow as tf\r\n'
                                   'from sklearn.model_selection import '
                                   'train_test_split\r\n'
                                   'from tensorflow.estimator import '
                                   'BoostedTreesRegressor\r\n'
                                   '\r\n'
                                   'def split_data(df: pd.DataFrame) -> (pd.DataFrame, '
                                   'pd.DataFrame, pd.DataFrame, pd.DataFrame):\r\n'
                                   '    """Split data into train and test sets\r\n'
                                   '\r\n'
                                   '    Args:\r\n'
                                   '        df (DataFrame): pandas dataframe\r\n'
                                   '\r\n'
                                   '    Returns:\r\n'
                                   '        X_train, X_test, y_train, y_test\r\n'
                                   '    """\r\n'
                                   '    feature_cols = [c for c in df.columns if '
                                   "c.startswith('FEATURE')]\r\n"
                                   '    label_col = [c for c in df.columns if '
                                   "c.startswith('LABEL')]\r\n"
                                   '\r\n'
                                   '    return train_test_split(df[feature_cols], '
                                   'df[label_col], test_size=.2, random_state=42)\r\n'
                                   '\r\n'
                                   '\r\n'
                                   'def make_input_fn(X, y, n_epochs=None, '
                                   'shuffle=True):\r\n'
                                   '    def input_fn():\r\n'
                                   '        dataset = '
                                   'tf.data.Dataset.from_tensor_slices((dict(X), y))\r\n'
                                   '        if shuffle:\r\n'
                                   '            dataset = dataset.shuffle(len(y))\r\n'
                                   '        dataset = dataset.repeat(n_epochs)\r\n'
                                   '        dataset = dataset.batch(len(y))\r\n'
                                   '        return dataset\r\n'
                                   '    return input_fn\r\n'
                                   '\r\n'
                                   '\r\n'
                                   'def make_serving_receiver_fn(df: pd.DataFrame):\r\n'
                                   '    feature_col_names = [c for c in df.columns if '
                                   "c.startswith('FEATURE')]\r\n"
                                   '    feature_cols = '
                                   '[tf.feature_column.numeric_column(fc) for fc in '
                                   'feature_col_names]\r\n'
                                   '    feature_spec = '
                                   'tf.feature_column.make_parse_example_spec(feature_cols)\r\n'
                                   '    return '
                                   'tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\r\n'
                                   '\r\n'
                                   '\r\n'
                                   'def train_model(df: pd.DataFrame, **params) -> '
                                   '(BoostedTreesRegressor, dict, dict):\r\n'
                                   '    """Train Boost Tree\r\n'
                                   '\r\n'
                                   '    Args:\r\n'
                                   '        df (DataFrame): pandas dataframe\r\n'
                                   '        params (**dict): parameters for training\r\n'
                                   '\r\n'
                                   '    Returns:\r\n'
                                   '        BoostTreesRegressor, saved model dir, a dict '
                                   'containing the evaluation metrics\r\n'
                                   '    """\r\n'
                                   '    feature_col_names = [c for c in df.columns if '
                                   "c.startswith('FEATURE')]\r\n"
                                   '    label_col_name = [c for c in df.columns if '
                                   "c.startswith('LABEL')]\r\n"
                                   '    feature_cols = '
                                   '[tf.feature_column.numeric_column(fc_name) for '
                                   'fc_name in feature_col_names]\r\n'
                                   '    default_params = {\r\n'
                                   "        'feature_columns': feature_cols,\r\n"
                                   "        'n_batches_per_layer': 1,\r\n"
                                   "        'model_dir': os.path.join('../output', "
                                   'str(uuid.uuid4())),\r\n'
                                   '    }\r\n'
                                   '    default_params.update(params)\r\n'
                                   '    regressor = '
                                   'BoostedTreesRegressor(**default_params)\r\n'
                                   '    X_train, X_valid, y_train, y_valid = '
                                   'train_test_split(df[feature_col_names], '
                                   'df[label_col_name], test_size=0.2, '
                                   'random_state=42)\r\n'
                                   '    train_input_fn = make_input_fn(X_train, '
                                   'y_train)\r\n'
                                   '    evaluate_input_fn = make_input_fn(X_valid, '
                                   'y_valid, n_epochs=1)\r\n'
                                   '    regressor.train(input_fn=train_input_fn)\r\n'
                                   '    summary = '
                                   'regressor.evaluate(input_fn=evaluate_input_fn)\r\n'
                                   '    receiver_fn = make_serving_receiver_fn(df)\r\n'
                                   '    export_dir = '
                                   'regressor.export_saved_model(regressor.model_dir, '
                                   'receiver_fn)\r\n'
                                   '\r\n'
                                   '    summary = {k: float(v) for k, v in '
                                   'summary.items()}\r\n'
                                   '\r\n'
                                   '    return regressor, export_dir, summary\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '**Other info / logs**\r\n'
                                   'No problem under environment __OSX 10.14.5__ with '
                                   '__pyenv virtualenv 3.7.0 (default, Nov 22 2019, '
                                   '12:39:30) \\n[Clang 11.0.0 (clang-1100.0.33.12)]__\r\n'
                                   '\r\n'
                                   'No problem when use google colab runtime (__Ubuntu '
                                   '18.04.3 LTS Python 3.6.9 compiled by GCC 8.3.0__). '
                                   'See __[notebook '
                                   'shared](https://colab.research.google.com/drive/1aAjJCWOBd7R0Hb6w4d7UCSnkfk4c-xyE)__\r\n'
                                   '\r\n'
                                   'Same problem in Kaggle runtime (__Debian GNU/Linux 9 '
                                   'Python 3.6.6 Anaconda GCC 7.3.0__) using tensorflow '
                                   '2.0.0.\r\n'
                                   '\r\n'
                                   'Full error log in docker using official image '
                                   '__tensorflow/tensorflow:2.0.0-py3__:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'WARNING: Logging before flag parsing goes to '
                                   'stderr.\r\n'
                                   'I1216 13:01:22.775628 140590360139584 '
                                   'estimator.py:1800] Using default config.\r\n'
                                   'I1216 13:01:22.778364 140590360139584 '
                                   "estimator.py:212] Using config: {'_model_dir': "
                                   "'/app/WINDMIL_PoC_Data_FE/service/estimator/saved_model/8f979f53-4821-4def-bc6e-9692d868e2ea', "
                                   "'_tf_random_seed': None, '_save_summary_steps': 100, "
                                   "'_save_checkpoints_steps': None, "
                                   "'_save_checkpoints_secs': 600, '_session_config': "
                                   'allow_soft_placement: true\r\n'
                                   'graph_options {\r\n'
                                   '  rewrite_options {\r\n'
                                   '    meta_optimizer_iterations: ONE\r\n'
                                   '  }\r\n'
                                   '}\r\n'
                                   ", '_keep_checkpoint_max': 5, "
                                   "'_keep_checkpoint_every_n_hours': 10000, "
                                   "'_log_step_count_steps': 100, '_train_distribute': "
                                   "None, '_device_fn': None, '_protocol': None, "
                                   "'_eval_distribute': None, '_experimental_distribute': "
                                   "None, '_experimental_max_worker_delay_secs': None, "
                                   "'_session_creation_timeout_secs': 7200, '_service': "
                                   "None, '_cluster_spec': "
                                   '<tensorflow.python.training.server_lib.ClusterSpec '
                                   "object at 0x7fdd837c5d30>, '_task_type': 'worker', "
                                   "'_task_id': 0, '_global_id_in_cluster': 0, '_master': "
                                   "'', '_evaluation_master': '', '_is_chief': True, "
                                   "'_num_ps_replicas': 0, '_num_worker_replicas': 1}\r\n"
                                   'W1216 13:01:22.809657 140590360139584 '
                                   'deprecation.py:506] From '
                                   '/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: '
                                   'calling BaseResourceVariable.__init__ (from '
                                   'tensorflow.python.ops.resource_variable_ops) with '
                                   'constraint is deprecated and will be removed in a '
                                   'future version.\r\n'
                                   'Instructions for updating:\r\n'
                                   'If using Keras pass *_constraint arguments to '
                                   'layers.\r\n'
                                   'W1216 13:01:22.811977 140590360139584 '
                                   'deprecation.py:323] From '
                                   '/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: '
                                   'Variable.initialized_value (from '
                                   'tensorflow.python.ops.variables) is deprecated and '
                                   'will be removed in a future version.\r\n'
                                   'Instructions for updating:\r\n'
                                   'Use Variable.read_value. Variables in 2.X are '
                                   'initialized automatically both in eager and graph '
                                   '(inside tf.defun) contexts.\r\n'
                                   'I1216 13:01:22.888739 140590360139584 '
                                   'estimator.py:1147] Calling model_fn.\r\n'
                                   'W1216 13:01:22.968535 140590360139584 '
                                   'deprecation.py:323] From '
                                   '/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/head.py:437: '
                                   'to_float (from tensorflow.python.ops.math_ops) is '
                                   'deprecated and will be removed in a future '
                                   'version.\r\n'
                                   'Instructions for updating:\r\n'
                                   'Use `tf.cast` instead.\r\n'
                                   'I1216 13:01:23.278414 140590360139584 '
                                   'estimator.py:1149] Done calling model_fn.\r\n'
                                   'I1216 13:01:23.278981 140590360139584 '
                                   'basic_session_run_hooks.py:541] Create '
                                   'CheckpointSaverHook.\r\n'
                                   'W1216 13:01:23.327183 140590360139584 '
                                   'meta_graph.py:448] Issue encountered when serializing '
                                   'resources.\r\n'
                                   "Type is unsupported, or the types of the items don't "
                                   'match field type in CollectionDef. Note this is a '
                                   'warning and probably safe to ignore.\r\n'
                                   "'_Resource' object has no attribute 'name'\r\n"
                                   'I1216 13:01:23.468171 140590360139584 '
                                   'monitored_session.py:240] Graph was finalized.\r\n'
                                   '2019-12-16 13:01:23.468761: I '
                                   'tensorflow/core/platform/cpu_feature_guard.cc:142] '
                                   'Your CPU supports instructions that this TensorFlow '
                                   'binary was not compiled to use: AVX2 FMA\r\n'
                                   '2019-12-16 13:01:23.475253: I '
                                   'tensorflow/core/platform/profile_utils/cpu_utils.cc:94] '
                                   'CPU Frequency: 2904000000 Hz\r\n'
                                   '2019-12-16 13:01:23.476582: I '
                                   'tensorflow/compiler/xla/service/service.cc:168] XLA '
                                   'service 0x4ed0210 executing computations on platform '
                                   'Host. Devices:\r\n'
                                   '2019-12-16 13:01:23.476657: I '
                                   'tensorflow/compiler/xla/service/service.cc:175]   '
                                   'StreamExecutor device (0): Host, Default Version\r\n'
                                   'I1216 13:01:23.541273 140590360139584 '
                                   'session_manager.py:500] Running local_init_op.\r\n'
                                   'I1216 13:01:23.561274 140590360139584 '
                                   'session_manager.py:502] Done running '
                                   'local_init_op.\r\n'
                                   'W1216 13:01:23.960061 140590360139584 '
                                   'meta_graph.py:448] Issue encountered when serializing '
                                   'resources.\r\n'
                                   "Type is unsupported, or the types of the items don't "
                                   'match field type in CollectionDef. Note this is a '
                                   'warning and probably safe to ignore.\r\n'
                                   "'_Resource' object has no attribute 'name'\r\n"
                                   'I1216 13:01:24.019694 140590360139584 '
                                   'basic_session_run_hooks.py:606] Saving checkpoints '
                                   'for 0 into '
                                   '/app/WINDMIL_PoC_Data_FE/service/estimator/saved_model/8f979f53-4821-4def-bc6e-9692d868e2ea/model.ckpt.\r\n'
                                   'W1216 13:01:24.100714 140590360139584 '
                                   'meta_graph.py:448] Issue encountered when serializing '
                                   'resources.\r\n'
                                   "Type is unsupported, or the types of the items don't "
                                   'match field type in CollectionDef. Note this is a '
                                   'warning and probably safe to ignore.\r\n'
                                   "'_Resource' object has no attribute 'name'\r\n"
                                   'I1216 13:01:24.385114 140590360139584 '
                                   'basic_session_run_hooks.py:262] loss = 0.017109463, '
                                   'step = 0\r\n'
                                   'W1216 13:01:24.594182 140590360139584 '
                                   'basic_session_run_hooks.py:724] It seems that global '
                                   'step (tf.train.get_global_step) has not been '
                                   'increased. Current value (could be stable): 0 vs '
                                   'previous value: 0. You could increase the global step '
                                   'by passing tf.train.get_global_step() to '
                                   'Optimizer.apply_gradients or Optimizer.minimize.\r\n'
                                   'corrupted size vs. prev_size\r\n'
                                   'Aborted\r\n'
                                   '```\r\n',
                           'created_at': '2019-12-1'},
                          {'body': '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): Yes\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): '
                                   'Linux-4.14.106+-x86_64-with-debian-buster-sid\r\n'
                                   '- TensorFlow installed from (source or binary): pip '
                                   'install\r\n'
                                   '- TensorFlow version (use command below): 2.0.0\r\n'
                                   '- Python version: 3.6.6\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'I am trying to train a model using:\r\n'
                                   '* TF 2.0 Keras functional API\r\n'
                                   '* Feature columns and `DenseFeatures` as the input '
                                   'layer\r\n'
                                   '* tf.data.Dataset API as the `x` parameter in '
                                   'model.fit()\r\n'
                                   '\r\n'
                                   "This raises a ValueError, and I'm not sure why "
                                   "because this doesn't work even with (what I think is) "
                                   'a minimal example. I suspect that this might be due '
                                   'to TF trying to match the feature columns to the '
                                   'inputs by name, but the name of the Input tensor '
                                   'contains a suffix e.g. `age:0`, but I may very well '
                                   'be mistaken.\r\n'
                                   '\r\n'
                                   'Might be related to: '
                                   'https://github.com/tensorflow/tensorflow/issues/30143\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   'I expect to be able to train a model using the Keras '
                                   'functional API using data from the Dataset API, with '
                                   'feature_columns being fed into Input layers.\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   'The following test case does not represent my use '
                                   'case, but it does reproduce the problem. Despite what '
                                   'the simplistic example suggests, I explicitly require '
                                   'both feature_columns and the functional API so '
                                   'suggesting that I use other TF libraries would not be '
                                   'an option, unless I can replicate the same '
                                   'functionality with minimal effort.\r\n'
                                   '\r\n'
                                   '```python\r\n'
                                   'import tensorflow as tf\r\n'
                                   'import numpy as np\r\n'
                                   'from tensorflow.keras.layers import DenseFeatures, '
                                   'Dense, Input\r\n'
                                   '\r\n'
                                   'def make_model(features):\r\n'
                                   '    feature_columns = '
                                   '[tf.feature_column.numeric_column(key) for key in '
                                   'features]\r\n'
                                   '    nn_input = {key: Input(name=key, shape=(), '
                                   'dtype=tf.float32) for key in features}\r\n'
                                   '\r\n'
                                   '    feat = '
                                   'DenseFeatures(feature_columns)(nn_input)\r\n'
                                   '    dense = Dense(16)(feat)\r\n'
                                   '    output = Dense(1)(dense)\r\n'
                                   '    model = tf.keras.Model(inputs=nn_input, '
                                   'outputs=output)\r\n'
                                   '    model.compile(\r\n'
                                   '        '
                                   'optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\r\n'
                                   '        '
                                   'loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\r\n'
                                   '        metrics=[tf.keras.metrics.AUC()],\r\n'
                                   '    )\r\n'
                                   '    return model\r\n'
                                   '\r\n'
                                   'features = ["age", "income"]\r\n'
                                   'label = "is_male"\r\n'
                                   '\r\n'
                                   'input_dataset = '
                                   'tf.data.Dataset.from_tensor_slices(\r\n'
                                   '    {key: np.ones((1000, 1), dtype=np.float) for key '
                                   'in features}\r\n'
                                   ')\r\n'
                                   'target_dataset = '
                                   'tf.data.Dataset.from_tensor_slices(\r\n'
                                   '    {label: np.ones((1000, 1), dtype=np.int)}\r\n'
                                   ')\r\n'
                                   'complete_dataset = '
                                   'tf.data.Dataset.zip((input_dataset, '
                                   'target_dataset)).shuffle(10000)\r\n'
                                   '\r\n'
                                   'model = make_model(features)\r\n'
                                   'model.summary()\r\n'
                                   'model.fit(complete_dataset)\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'This code references the issue created by @durandg12. '
                                   'Thank you.\r\n'
                                   '\r\n'
                                   '**Stack trace**\r\n'
                                   '```bash\r\n'
                                   '---------------------------------------------------------------------------\r\n'
                                   'KeyError                                  Traceback '
                                   '(most recent call last)\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py '
                                   'in standardize_input_data(data, names, shapes, '
                                   'check_batch_axis, exception_prefix)\r\n'
                                   '    498           if data[x].__class__.__name__ == '
                                   "'DataFrame' else data[x]\r\n"
                                   '--> 499           for x in names\r\n'
                                   '    500       ]\r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py '
                                   'in <listcomp>(.0)\r\n'
                                   '    498           if data[x].__class__.__name__ == '
                                   "'DataFrame' else data[x]\r\n"
                                   '--> 499           for x in names\r\n'
                                   '    500       ]\r\n'
                                   '\r\n'
                                   "KeyError: 'dense_1'\r\n"
                                   '\r\n'
                                   'During handling of the above exception, another '
                                   'exception occurred:\r\n'
                                   '\r\n'
                                   'ValueError                                Traceback '
                                   '(most recent call last)\r\n'
                                   '<ipython-input-1-0081a84113eb> in <module>\r\n'
                                   '     27 model = make_model(features)\r\n'
                                   '     28 model.summary()\r\n'
                                   '---> 29 model.fit(complete_dataset)\r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py '
                                   'in fit(self, x, y, batch_size, epochs, verbose, '
                                   'callbacks, validation_split, validation_data, '
                                   'shuffle, class_weight, sample_weight, initial_epoch, '
                                   'steps_per_epoch, validation_steps, validation_freq, '
                                   'max_queue_size, workers, use_multiprocessing, '
                                   '**kwargs)\r\n'
                                   '    726         max_queue_size=max_queue_size,\r\n'
                                   '    727         workers=workers,\r\n'
                                   '--> 728         '
                                   'use_multiprocessing=use_multiprocessing)\r\n'
                                   '    729 \r\n'
                                   '    730   def evaluate(self,\r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py '
                                   'in fit(self, model, x, y, batch_size, epochs, '
                                   'verbose, callbacks, validation_split, '
                                   'validation_data, shuffle, class_weight, '
                                   'sample_weight, initial_epoch, steps_per_epoch, '
                                   'validation_steps, validation_freq, **kwargs)\r\n'
                                   '    322                 mode=ModeKeys.TRAIN,\r\n'
                                   '    323                 '
                                   'training_context=training_context,\r\n'
                                   '--> 324                 total_epochs=epochs)\r\n'
                                   '    325             cbks.make_logs(model, epoch_logs, '
                                   'training_result, ModeKeys.TRAIN)\r\n'
                                   '    326 \r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py '
                                   'in run_one_epoch(model, iterator, execution_function, '
                                   'dataset_size, batch_size, strategy, steps_per_epoch, '
                                   'num_samples, mode, training_context, total_epochs)\r\n'
                                   '    121         step=step, mode=mode, '
                                   'size=current_batch_size) as batch_logs:\r\n'
                                   '    122       try:\r\n'
                                   '--> 123         batch_outs = '
                                   'execution_function(iterator)\r\n'
                                   '    124       except (StopIteration, '
                                   'errors.OutOfRangeError):\r\n'
                                   '    125         # TODO(kaftan): File bug about tf '
                                   'function and errors.OutOfRangeError?\r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py '
                                   'in execution_function(input_fn)\r\n'
                                   '     84     # `numpy` translates Tensors to values in '
                                   'Eager mode.\r\n'
                                   '     85     return '
                                   'nest.map_structure(_non_none_constant_value,\r\n'
                                   '---> 86                               '
                                   'distributed_function(input_fn))\r\n'
                                   '     87 \r\n'
                                   '     88   return execution_function\r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py '
                                   'in __call__(self, *args, **kwds)\r\n'
                                   '    455 \r\n'
                                   '    456     tracing_count = '
                                   'self._get_tracing_count()\r\n'
                                   '--> 457     result = self._call(*args, **kwds)\r\n'
                                   '    458     if tracing_count == '
                                   'self._get_tracing_count():\r\n'
                                   '    459       '
                                   'self._call_counter.called_without_tracing()\r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py '
                                   'in _call(self, *args, **kwds)\r\n'
                                   '    501       # This is the first call of __call__, '
                                   'so we have to initialize.\r\n'
                                   '    502       initializer_map = '
                                   'object_identity.ObjectIdentityDictionary()\r\n'
                                   '--> 503       self._initialize(args, kwds, '
                                   'add_initializers_to=initializer_map)\r\n'
                                   '    504     finally:\r\n'
                                   '    505       # At this point we know that the '
                                   'initialization is complete (or less\r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py '
                                   'in _initialize(self, args, kwds, '
                                   'add_initializers_to)\r\n'
                                   '    406     self._concrete_stateful_fn = (\r\n'
                                   '    407         '
                                   'self._stateful_fn._get_concrete_function_internal_garbage_collected(  '
                                   '# pylint: disable=protected-access\r\n'
                                   '--> 408             *args, **kwds))\r\n'
                                   '    409 \r\n'
                                   '    410     def invalid_creator_scope(*unused_args, '
                                   '**unused_kwds):\r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py '
                                   'in '
                                   '_get_concrete_function_internal_garbage_collected(self, '
                                   '*args, **kwargs)\r\n'
                                   '   1846     if self.input_signature:\r\n'
                                   '   1847       args, kwargs = None, None\r\n'
                                   '-> 1848     graph_function, _, _ = '
                                   'self._maybe_define_function(args, kwargs)\r\n'
                                   '   1849     return graph_function\r\n'
                                   '   1850 \r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py '
                                   'in _maybe_define_function(self, args, kwargs)\r\n'
                                   '   2148         graph_function = '
                                   'self._function_cache.primary.get(cache_key, None)\r\n'
                                   '   2149         if graph_function is None:\r\n'
                                   '-> 2150           graph_function = '
                                   'self._create_graph_function(args, kwargs)\r\n'
                                   '   2151           '
                                   'self._function_cache.primary[cache_key] = '
                                   'graph_function\r\n'
                                   '   2152         return graph_function, args, '
                                   'kwargs\r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py '
                                   'in _create_graph_function(self, args, kwargs, '
                                   'override_flat_arg_shapes)\r\n'
                                   '   2039             arg_names=arg_names,\r\n'
                                   '   2040             '
                                   'override_flat_arg_shapes=override_flat_arg_shapes,\r\n'
                                   '-> 2041             '
                                   'capture_by_value=self._capture_by_value),\r\n'
                                   '   2042         self._function_attributes,\r\n'
                                   '   2043         # Tell the ConcreteFunction to clean '
                                   'up its graph once it goes out of\r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py '
                                   'in func_graph_from_py_func(name, python_func, args, '
                                   'kwargs, signature, func_graph, autograph, '
                                   'autograph_options, add_control_dependencies, '
                                   'arg_names, op_return_value, collections, '
                                   'capture_by_value, override_flat_arg_shapes)\r\n'
                                   '    913                                           '
                                   'converted_func)\r\n'
                                   '    914 \r\n'
                                   '--> 915       func_outputs = python_func(*func_args, '
                                   '**func_kwargs)\r\n'
                                   '    916 \r\n'
                                   '    917       # invariant: `func_outputs` contains '
                                   'only Tensors, CompositeTensors,\r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py '
                                   'in wrapped_fn(*args, **kwds)\r\n'
                                   '    356         # __wrapped__ allows AutoGraph to '
                                   'swap in a converted function. We give\r\n'
                                   '    357         # the function a weak reference to '
                                   'itself to avoid a reference cycle.\r\n'
                                   '--> 358         return '
                                   'weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n'
                                   '    359     weak_wrapped_fn = '
                                   'weakref.ref(wrapped_fn)\r\n'
                                   '    360 \r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py '
                                   'in distributed_function(input_iterator)\r\n'
                                   '     71     strategy = '
                                   'distribution_strategy_context.get_strategy()\r\n'
                                   '     72     outputs = '
                                   'strategy.experimental_run_v2(\r\n'
                                   '---> 73         per_replica_function, args=(model, x, '
                                   'y, sample_weights))\r\n'
                                   '     74     # Out of PerReplica outputs reduce or '
                                   'pick values to return.\r\n'
                                   '     75     all_outputs = '
                                   'dist_utils.unwrap_output_dict(\r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py '
                                   'in experimental_run_v2(self, fn, args, kwargs)\r\n'
                                   '    758       fn = autograph.tf_convert(fn, '
                                   'ag_ctx.control_status_ctx(),\r\n'
                                   '    759                                 '
                                   'convert_by_default=False)\r\n'
                                   '--> 760       return '
                                   'self._extended.call_for_each_replica(fn, args=args, '
                                   'kwargs=kwargs)\r\n'
                                   '    761 \r\n'
                                   '    762   def reduce(self, reduce_op, value, '
                                   'axis):\r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py '
                                   'in call_for_each_replica(self, fn, args, kwargs)\r\n'
                                   '   1785       kwargs = {}\r\n'
                                   '   1786     with '
                                   'self._container_strategy().scope():\r\n'
                                   '-> 1787       return self._call_for_each_replica(fn, '
                                   'args, kwargs)\r\n'
                                   '   1788 \r\n'
                                   '   1789   def _call_for_each_replica(self, fn, args, '
                                   'kwargs):\r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py '
                                   'in _call_for_each_replica(self, fn, args, kwargs)\r\n'
                                   '   2130         self._container_strategy(),\r\n'
                                   '   2131         '
                                   'replica_id_in_sync_group=constant_op.constant(0, '
                                   'dtypes.int32)):\r\n'
                                   '-> 2132       return fn(*args, **kwargs)\r\n'
                                   '   2133 \r\n'
                                   '   2134   def _reduce_to(self, reduce_op, value, '
                                   'destinations):\r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py '
                                   'in wrapper(*args, **kwargs)\r\n'
                                   '    290   def wrapper(*args, **kwargs):\r\n'
                                   '    291     with '
                                   'ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\r\n'
                                   '--> 292       return func(*args, **kwargs)\r\n'
                                   '    293 \r\n'
                                   '    294   if inspect.isfunction(func) or '
                                   'inspect.ismethod(func):\r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py '
                                   'in train_on_batch(model, x, y, sample_weight, '
                                   'class_weight, reset_metrics)\r\n'
                                   '    251   x, y, sample_weights = '
                                   'model._standardize_user_data(\r\n'
                                   '    252       x, y, sample_weight=sample_weight, '
                                   'class_weight=class_weight,\r\n'
                                   '--> 253       extract_tensors_from_dataset=True)\r\n'
                                   '    254   batch_size = '
                                   'array_ops.shape(nest.flatten(x, '
                                   'expand_composites=True)[0])[0]\r\n'
                                   '    255   # If `model._distribution_strategy` is '
                                   'True, then we are in a replica context\r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py '
                                   'in _standardize_user_data(self, x, y, sample_weight, '
                                   'class_weight, batch_size, check_steps, steps_name, '
                                   'steps, validation_split, shuffle, '
                                   'extract_tensors_from_dataset)\r\n'
                                   '   2517           shapes=None,\r\n'
                                   "   2518           check_batch_axis=False,  # Don't "
                                   'enforce the batch size.\r\n'
                                   "-> 2519           exception_prefix='target')\r\n"
                                   '   2520 \r\n'
                                   '   2521       # Generate sample-wise weight values '
                                   'given the `sample_weight` and\r\n'
                                   '\r\n'
                                   '/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py '
                                   'in standardize_input_data(data, names, shapes, '
                                   'check_batch_axis, exception_prefix)\r\n'
                                   '    501     except KeyError as e:\r\n'
                                   "    502       raise ValueError('No data provided for "
                                   '"\' + e.args[0] + \'". Need data \'\r\n'
                                   "--> 503                        'for each key in: ' + "
                                   'str(names))\r\n'
                                   '    504   elif isinstance(data, (list, tuple)):\r\n'
                                   '    505     if isinstance(data[0], (list, tuple)):\r\n'
                                   '\r\n'
                                   'ValueError: No data provided for "dense_1". Need data '
                                   "for each key in: ['dense_1']\r\n"
                                   '```\r\n',
                           'created_at': '2019-12-1'},
                          {'body': '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): No\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Windows 10\r\n'
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device: NA\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'Binary (pip)\r\n'
                                   '- TensorFlow version (use command below): '
                                   'v2.0.0-rc2-26-g64c3d382ca 2.0.0\r\n'
                                   '- Python version: Python 3.6.8\r\n'
                                   '- Bazel version (if compiling from source): NA\r\n'
                                   '- GCC/Compiler version (if compiling from source): '
                                   'NA\r\n'
                                   '- CUDA/cuDNN version: CUDA 10.0.130_411.31; cuDNN '
                                   '10.0 v7.6.5.32\r\n'
                                   '- GPU model and memory: NVIDIA Quadro P2000, 4 GB\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'When the model is saved in the default tf format, '
                                   'warnings are logged when trying to serve the '
                                   'model.\r\n'
                                   '\r\n'
                                   'Examplary warning logs:\r\n'
                                   '```\r\n'
                                   'WARNING:tensorflow:5 out of the last 5 calls to '
                                   '<function '
                                   'recreate_function.<locals>.restored_function_body at '
                                   '0x000001ED79058730> triggered tf.function retracing. '
                                   'Tracing is expensive and the excessive number of '
                                   'tracings is likely due to passing python objects '
                                   'instead of tensors. Also, tf.function has '
                                   'experimental_relax_shapes=True option that relaxes '
                                   'argument shapes that can avoid unnecessary retracing. '
                                   'Please refer to '
                                   'https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args '
                                   'and '
                                   'https://www.tensorflow.org/api_docs/python/tf/function '
                                   'for more details.\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'When the model is saved in the hdf5 format, the '
                                   'warnings do not occur.\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   'The save formats should be equivalent and behave in '
                                   'the same way.\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   'Execute the following scripts to create and serve '
                                   'model\r\n'
                                   "1. Run the first script with `format_ext = ''` which "
                                   'saves the model in tf format, **restart the Python '
                                   'console**, serve the model with the second script '
                                   'which creates the aforementioned warnings.\r\n'
                                   '1. When running the scripts with `format_ext = '
                                   "'.h5'`, the model is saved in hdf5 format and no "
                                   'warnings appear.\r\n'
                                   '\r\n'
                                   'Model creation:\r\n'
                                   '```python\r\n'
                                   'import os\r\n'
                                   '\r\n'
                                   'import tensorflow as tf\r\n'
                                   '\r\n'
                                   "format_ext = ''  # '.h5' or empty for tf format\r\n"
                                   "model_path = os.path.join('out', "
                                   "'mnist-classifier{}'.format(format_ext))\r\n"
                                   '\r\n'
                                   'gpus = '
                                   "tf.config.experimental.list_physical_devices('GPU')\r\n"
                                   '\r\n'
                                   'tf.config.experimental.set_virtual_device_configuration(\r\n'
                                   '    gpus[0],\r\n'
                                   '    '
                                   '[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512),\r\n'
                                   '     '
                                   'tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512),\r\n'
                                   '     '
                                   'tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512)]\r\n'
                                   ')\r\n'
                                   '\r\n'
                                   'strategy = tf.distribute.MirroredStrategy()\r\n'
                                   'with strategy.scope():\r\n'
                                   '    inputs = tf.keras.Input(shape=(784,), '
                                   "name='digits')\r\n"
                                   "    x = tf.keras.layers.Dense(64, activation='relu', "
                                   "name='dense_1')(inputs)\r\n"
                                   "    x = tf.keras.layers.Dense(64, activation='relu', "
                                   "name='dense_2')(x)\r\n"
                                   '    outputs = tf.keras.layers.Dense(10, '
                                   "activation='softmax', name='predictions')(x)\r\n"
                                   '\r\n'
                                   '    model = tf.keras.Model(inputs=inputs, '
                                   'outputs=outputs)\r\n'
                                   '\r\n'
                                   '    '
                                   'model.compile(optimizer=tf.keras.optimizers.RMSprop(),  '
                                   '# Optimizer\r\n'
                                   '                  # Loss function to minimize\r\n'
                                   '                  '
                                   'loss=tf.keras.losses.SparseCategoricalCrossentropy(),\r\n'
                                   '                  # List of metrics to monitor\r\n'
                                   '                  '
                                   'metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\r\n'
                                   '\r\n'
                                   'model.save(model_path)\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'Model serving:\r\n'
                                   '```python\r\n'
                                   'import os\r\n'
                                   '\r\n'
                                   'import tensorflow as tf\r\n'
                                   '\r\n'
                                   "format_ext = ''  # '.h5' or empty for tf format\r\n"
                                   "model_path = os.path.join('out', "
                                   "'mnist-classifier{}'.format(format_ext))\r\n"
                                   '\r\n'
                                   'gpus = '
                                   "tf.config.experimental.list_physical_devices('GPU')\r\n"
                                   '\r\n'
                                   'tf.config.experimental.set_virtual_device_configuration(\r\n'
                                   '    gpus[0],\r\n'
                                   '    '
                                   '[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512),\r\n'
                                   '     '
                                   'tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512),\r\n'
                                   '     '
                                   'tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512)]\r\n'
                                   ')\r\n'
                                   '\r\n'
                                   '(_, _), (x_test, _) = '
                                   'tf.keras.datasets.mnist.load_data()\r\n'
                                   "x_test = x_test.reshape(10000, 784).astype('float32') "
                                   '/ 255\r\n'
                                   '\r\n'
                                   'strategy = tf.distribute.MirroredStrategy()\r\n'
                                   'with strategy.scope():\r\n'
                                   '    loaded_model = '
                                   'tf.keras.models.load_model(model_path)\r\n'
                                   '    predictions = loaded_model.predict(x_test, '
                                   'batch_size=64)\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '**Other info / logs**\r\n'
                                   'The warnings occur only if more than two vGPUs are '
                                   'used.',
                           'created_at': '2019-12-1'},
                          {'body': '- TensorFlow version (you are using): 2.0\r\n'
                                   '- Are you willing to contribute it (Yes/No): Yes\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'tf.keras.backend.floatx = tf.float64\r\n'
                                   'f64 = tf.Variable([0,0.2,0.5,0.7,1], '
                                   'dtype=tf.float64)\r\n'
                                   'tf.where(f64 > 0.5, 1., 0. )\r\n'
                                   '\r\n'
                                   '<tf.Tensor: id=16, shape=(5,), dtype=float32, '
                                   'numpy=array([0., 0., 0., 1., 1.], dtype=float32)>\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'alternatives for tf.float64 models lead to difficult '
                                   'to read code\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'tf.where(f64 > 0.5, tf.constant(1., '
                                   'dtype=tf.float64), tf.constant(0., dtype=tf.float64) '
                                   ')\r\n'
                                   'tf.cast(tf.where(f64 > 0.5, 1., 0. ), '
                                   'dtype=tf.float64)\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   "assuming that tf.where can't respect the float type "
                                   'of the input variable nor the floatx setting, as '
                                   'those change the api, better would be:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'tf.where(f64 > 0.5, 1., 0. , dtype=tf.float64)\r\n'
                                   '```\r\n'
                                   '\r\n',
                           'created_at': '2019-12-1'},
                          {'body': '<em>Please make sure that this is a '
                                   'build/installation issue. As per our [GitHub '
                                   'Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), '
                                   'we only address code/doc bugs, performance issues, '
                                   'feature requests and build/installation issues on '
                                   'GitHub. tag:build_template</em>\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- OS Platform and Distribution: Ubuntu 18.04.3 LTS\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'source\r\n'
                                   '- TensorFlow version: v2.1.0-rc1\r\n'
                                   '\r\n'
                                   " I'm building using the docker image for a raspberry "
                                   'pi 3 build.\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Describe the problem**\r\n'
                                   '\r\n'
                                   "I'm able to correctly build "
                                   '`tensorflow-2.1.0rc1-cp35-none-linux_armv7l.whl` '
                                   'using:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'CI_DOCKER_EXTRA_PARAMS="-e CI_BUILD_PYTHON=python3 -e '
                                   'CROSSTOOL_PYTHON_INCLUDE_PATH=/usr/include/python3.4"     '
                                   'tensorflow/tools/ci_build/ci_build.sh PI-PYTHON3     '
                                   'tensorflow/tools/ci_build/pi/build_raspberry_pi.sh \r\n'
                                   '```\r\n'
                                   "I'm trying to do the same but with the python 3.7 "
                                   'docker images `PI-PYTHON37` '
                                   '(`tensorflow/tools/ci_build/Dockerfile.pi-python37`) '
                                   'but it fails with:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'ERROR: '
                                   '/workspace/tensorflow/lite/python/interpreter_wrapper/BUILD:8:1: '
                                   'C++ compilation of rule '
                                   "'//tensorflow/lite/python/interpreter_wrapper:numpy' "
                                   'failed (Exit 1)\r\n'
                                   "cc1plus: warning: command line option '-std=gnu11' is "
                                   'valid for C/ObjC but not for C++\r\n'
                                   'In file included from '
                                   'bazel-out/armeabi-py2-opt/bin/external/local_config_python/python_include/Python.h:8:0,\r\n'
                                   '                 from '
                                   './tensorflow/lite/python/interpreter_wrapper/numpy.h:49,\r\n'
                                   '                 from '
                                   'tensorflow/lite/python/interpreter_wrapper/numpy.cc:17:\r\n'
                                   'bazel-out/armeabi-py2-opt/bin/external/local_config_python/python_include/pyconfig.h:13:55: '
                                   'fatal error: '
                                   'arm-linux-gnueabihf/python3.5m/pyconfig.h: No such '
                                   'file or directory\r\n'
                                   ' #  include '
                                   '<arm-linux-gnueabihf/python3.5m/pyconfig.h>\r\n'
                                   '                                                       '
                                   '^\r\n'
                                   'compilation terminated.\r\n'
                                   'INFO: Elapsed time: 339.221s, Critical Path: '
                                   '36.02s\r\n'
                                   'INFO: 6204 processes: 6204 local.\r\n'
                                   'FAILED: Build did NOT complete successfully\r\n'
                                   'FAILED: Build did NOT complete successfully\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '**Provide the exact sequence of commands / steps that '
                                   'you executed before running into the problem**\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'cd tensorflow\r\n'
                                   'git checkout v2.1.0-rc1\r\n'
                                   'CI_DOCKER_EXTRA_PARAMS="-e CI_BUILD_PYTHON=python3 -e '
                                   'CROSSTOOL_PYTHON_INCLUDE_PATH=/usr/include/python3.4"     '
                                   'tensorflow/tools/ci_build/ci_build.sh PI-PYTHON37     '
                                   'tensorflow/tools/ci_build/pi/build_raspberry_pi.sh\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '**Any other info / logs**\r\n'
                                   'Include any logs or source code that would be helpful '
                                   'to diagnose the problem. If including tracebacks, '
                                   'please include the full traceback. Large logs and '
                                   'files should be attached.\r\n',
                           'created_at': '2019-12-1'},
                          {'body': '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): Yes\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Linux Ubuntu 16.04 in Docker\r\n'
                                   '- TensorFlow installed from (source or binary): pip '
                                   'install\r\n'
                                   '- TensorFlow version (use command below): '
                                   'v2.0.0-rc2-26-g64c3d38\r\n'
                                   '- Python version: 3.5\r\n'
                                   '- CUDA/cuDNN version: 10.0 / 7\r\n'
                                   '- GPU model and memory: GTX 1080Ti / 11175MiB\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   '\r\n'
                                   'Hi authors and developers,\r\n'
                                   '\r\n'
                                   'I am developing our project in tf=2.0.0 and '
                                   'eager_mode is disable.\r\n'
                                   '\r\n'
                                   'The main reason is tf=1.x will not be maintained but '
                                   'third party libraries have not been ready for tf=2.0 '
                                   'yet.\r\n'
                                   '\r\n'
                                   'This issues is a separate issues from '
                                   '[#35050](https://github.com/tensorflow/tensorflow/issues/35050#issuecomment-565395512)\r\n'
                                   '\r\n'
                                   'This potential issue is somethine wrong if users do '
                                   'custom training with level API which includes '
                                   '`tf.keras.layers.BatchNormalization()` in tf=2.0 and '
                                   'eager model is disable.\r\n'
                                   '\r\n'
                                   'I summary the testcaset as the following:\r\n'
                                   '\r\n'
                                   '```python\r\n'
                                   '#%%\r\n'
                                   'import tensorflow as tf\r\n'
                                   'tf.compat.v1.disable_eager_execution()\r\n'
                                   '#tf.compat.v1.disable_v2_behavior()\r\n'
                                   '\r\n'
                                   'import numpy as np\r\n'
                                   '\r\n'
                                   'batch_size = 100\r\n'
                                   '\r\n'
                                   'def download_data():\r\n'
                                   '\r\n'
                                   '    # get raw data\r\n'
                                   '    (trainX, trainY), (testX, testY) = '
                                   'tf.keras.datasets.cifar10.load_data()\r\n'
                                   '    trainX = trainX.astype(np.float32)\r\n'
                                   '    testX  = testX.astype(np.float32)\r\n'
                                   '\r\n'
                                   '    # ont-hot\r\n'
                                   '    trainY = tf.keras.utils.to_categorical(trainY, '
                                   '10)\r\n'
                                   '    testY  = tf.keras.utils.to_categorical(testY , '
                                   '10)\r\n'
                                   '\r\n'
                                   '    # get validation sets\r\n'
                                   '    training_size = 45000\r\n'
                                   '    validX = trainX[training_size:,:]\r\n'
                                   '    validY = trainY[training_size:,:]\r\n'
                                   '\r\n'
                                   '    trainX = trainX[:training_size,:]\r\n'
                                   '    trainY = trainY[:training_size,:]\r\n'
                                   '\r\n'
                                   '    return trainX, trainY, validX, validY, testX, '
                                   'testY\r\n'
                                   '\r\n'
                                   'def data_pipeline(dataX, dataY):\r\n'
                                   '\r\n'
                                   '        dataset = tf.data.Dataset.from_tensor_slices( '
                                   '(dataX, dataY) )\r\n'
                                   '        dataset = dataset.shuffle(batch_size * 8)\r\n'
                                   '        dataset = dataset.repeat()\r\n'
                                   '        dataset = dataset.batch(batch_size)\r\n'
                                   '        dataset = '
                                   'dataset.prefetch(tf.data.experimental.AUTOTUNE)\r\n'
                                   '        return dataset\r\n'
                                   '\r\n'
                                   'class custom_model():\r\n'
                                   '    def __init__(self):\r\n'
                                   '\r\n'
                                   '        def Acc():\r\n'
                                   '            acc = '
                                   'tf.keras.metrics.categorical_accuracy(label_ref, '
                                   'clf_out)\r\n'
                                   '            return tf.math.reduce_mean(acc)\r\n'
                                   '\r\n'
                                   '        def c_loss():\r\n'
                                   '            loss = '
                                   'tf.keras.losses.categorical_crossentropy(label_ref, '
                                   'clf_out)\r\n'
                                   '            loss = tf.math.reduce_mean(loss)\r\n'
                                   '            return loss\r\n'
                                   '\r\n'
                                   '        # create model\r\n'
                                   '        clf_input = '
                                   'tf.keras.layers.Input(shape=(32,32,3), '
                                   'name="model/input")\r\n'
                                   '        model = '
                                   'tf.keras.applications.resnet_v2.ResNet50V2(include_top=True, '
                                   "weights=None, input_tensor=clf_input, pooling='max', "
                                   'classes=10)\r\n'
                                   '        #model = '
                                   'tf.keras.applications.vgg16.VGG16(include_top=True, '
                                   "weights=None, input_tensor=clf_input, pooling='max', "
                                   'classes=10)\r\n'
                                   '        '
                                   "model.compile(loss='categorical_crossentropy', "
                                   "optimizer='SGD', metrics=['accuracy'])\r\n"
                                   '\r\n'
                                   '        label_ref = tf.keras.layers.Input(shape=(10,) '
                                   ", name='label_ref')\r\n"
                                   '        clf_out = model(clf_input)\r\n'
                                   '\r\n'
                                   '        # using tf.keras.optimizers.Nadam would get '
                                   'error\r\n'
                                   '        #optimizer = '
                                   'tf.keras.optimizers.Nadam(lr=0.0005)\r\n'
                                   '        optimizer = '
                                   'tf.compat.v1.train.AdamOptimizer(learning_rate=0.01)\r\n'
                                   '        self.train_op = optimizer.minimize(c_loss(), '
                                   'var_list=[model.trainable_variables])\r\n'
                                   '\r\n'
                                   '        self.clf_model = model\r\n'
                                   '        self.clf_input = clf_input\r\n'
                                   '        self.label_ref = label_ref\r\n'
                                   '        self.op_acc = Acc()\r\n'
                                   '        self.c_loss = c_loss()\r\n'
                                   '\r\n'
                                   "if __name__ == '__main__':\r\n"
                                   '\r\n'
                                   '    # set GPU\r\n'
                                   '    import os\r\n'
                                   '    if os.environ.get("CUDA_VISIBLE_DEVICES") is '
                                   'None:\r\n'
                                   '        os.environ["CUDA_VISIBLE_DEVICES"] = "0"\r\n'
                                   '\r\n'
                                   '    # reset tf session\r\n'
                                   '    tf.compat.v1.keras.backend.clear_session()\r\n'
                                   '    gpu_options = '
                                   'tf.compat.v1.GPUOptions(allow_growth=True)\r\n'
                                   '    sess = '
                                   'tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\r\n'
                                   '    tf.compat.v1.keras.backend.set_session(sess) \r\n'
                                   '\r\n'
                                   '    # prepare data\r\n'
                                   '    trainX, trainY, validX, validY, testX, testY = '
                                   'download_data()\r\n'
                                   '    train_gen = data_pipeline(trainX, trainY)\r\n'
                                   '    valid_gen = data_pipeline(validX, validY)\r\n'
                                   '    test_gen = data_pipeline(testX, testY)\r\n'
                                   '\r\n'
                                   '    # build targeted model\r\n'
                                   '    model = '
                                   'tf.keras.applications.resnet_v2.ResNet50V2(include_top=True, '
                                   "weights=None, input_shape=(32,32,3), pooling='max', "
                                   'classes=10)\r\n'
                                   '    #model = '
                                   'tf.keras.applications.vgg16.VGG16(include_top=True, '
                                   'weights=None, input_shape=(32,32,3), pooling=None, '
                                   'classes=10)\r\n'
                                   "    model.compile(loss='categorical_crossentropy', "
                                   "optimizer='SGD', metrics=['accuracy'])\r\n"
                                   '\r\n'
                                   '    # fit and evalutate\r\n'
                                   '    model.fit(train_gen,\r\n'
                                   '            steps_per_epoch = trainY.shape[0] // '
                                   'batch_size,\r\n'
                                   '            validation_data = valid_gen,\r\n'
                                   '            validation_steps= validY.shape[0] // '
                                   'batch_size,\r\n'
                                   '            epochs=5,\r\n'
                                   '            verbose=2)\r\n'
                                   '    model.evaluate(testX, testY, verbose=2, '
                                   'batch_size=batch_size)\r\n'
                                   '\r\n'
                                   '    # create a new model\r\n'
                                   "    print('Make sure that we create a new model.')\r\n"
                                   '    model = custom_model()\r\n'
                                   '    '
                                   'sess.run(tf.compat.v1.global_variables_initializer())\r\n'
                                   '    model.clf_model.evaluate(testX, testY, verbose=2, '
                                   'batch_size=batch_size)\r\n'
                                   '\r\n'
                                   '    # train model\r\n'
                                   '    num_epoch = 5\r\n'
                                   '    total_len = trainY.shape[0] // batch_size\r\n'
                                   '    tf_iter = '
                                   'tf.compat.v1.data.make_initializable_iterator(train_gen)\r\n'
                                   '    tf_next = tf_iter.get_next()\r\n'
                                   '    sess.run(tf_iter.initializer)\r\n'
                                   '    for epoch in range(num_epoch):\r\n'
                                   '        c_loss, acc = 0.0, 0.0\r\n'
                                   '        for ii in range(total_len):\r\n'
                                   '            X, Y = sess.run(tf_next)\r\n'
                                   '            [b_c_loss, b_acc, _] = '
                                   'sess.run([model.c_loss, model.op_acc, '
                                   'model.train_op],\r\n'
                                   '                                                '
                                   'feed_dict={ model.clf_input: X,\r\n'
                                   '                                                            '
                                   'model.label_ref: Y,\r\n'
                                   '                                                            '
                                   'tf.keras.backend.learning_phase(): 1})\r\n'
                                   '            c_loss = c_loss + b_c_loss\r\n'
                                   '            acc = acc + b_acc\r\n'
                                   '        \r\n'
                                   '        c_loss = c_loss / total_len\r\n'
                                   '        acc = acc / total_len\r\n'
                                   "        print('[Training]Epoch: {:d}/{:d} - loss: "
                                   "{:.3f} - acc: {:.3f}'.format(epoch+1, num_epoch, "
                                   'c_loss, acc) )\r\n'
                                   '\r\n'
                                   "    print('Show loss and accuracy with keras API')\r\n"
                                   '    model.clf_model.evaluate(trainX, trainY, '
                                   'verbose=2, batch_size=batch_size)\r\n'
                                   '    model.clf_model.evaluate(validX, validY, '
                                   'verbose=2, batch_size=batch_size)\r\n'
                                   '    model.clf_model.evaluate(testX, testY, verbose=2, '
                                   'batch_size=batch_size)\r\n'
                                   '\r\n'
                                   "    print('Show loss and accuracy with low level "
                                   "API')\r\n"
                                   '    # evaluate\r\n'
                                   '    num_epoch = 1\r\n'
                                   '    total_len = validY.shape[0] // batch_size\r\n'
                                   '    tf_iter = '
                                   'tf.compat.v1.data.make_initializable_iterator(valid_gen)\r\n'
                                   '    tf_next = tf_iter.get_next()\r\n'
                                   '    sess.run(tf_iter.initializer)\r\n'
                                   '    for epoch in range(num_epoch):\r\n'
                                   '        c_loss_t, acc_t, c_loss_f, acc_f = 0.0, 0.0, '
                                   '0.0, 0.0\r\n'
                                   '        for ii in range(total_len):\r\n'
                                   '            X, Y = sess.run(tf_next)\r\n'
                                   '            [b_c_loss, b_acc] = '
                                   'sess.run([model.c_loss, model.op_acc],\r\n'
                                   '                                        feed_dict={ '
                                   'model.clf_input: X,\r\n'
                                   '                                                    '
                                   'model.label_ref: Y,\r\n'
                                   '                                                    '
                                   'tf.keras.backend.learning_phase(): 1})\r\n'
                                   '            c_loss_t = c_loss_t + b_c_loss\r\n'
                                   '            acc_t = acc_t + b_acc\r\n'
                                   '\r\n'
                                   '            [b_c_loss, b_acc] = '
                                   'sess.run([model.c_loss, model.op_acc],\r\n'
                                   '                                        feed_dict={ '
                                   'model.clf_input: X,\r\n'
                                   '                                                    '
                                   'model.label_ref: Y,\r\n'
                                   '                                                    '
                                   'tf.keras.backend.learning_phase(): 0})\r\n'
                                   '            c_loss_f = c_loss_f + b_c_loss\r\n'
                                   '            acc_f = acc_f + b_acc\r\n'
                                   '\r\n'
                                   '        c_loss_t = c_loss_t / total_len\r\n'
                                   '        c_loss_f = c_loss_f / total_len\r\n'
                                   '        acc_t = acc_t / total_len\r\n'
                                   '        acc_f = acc_f / total_len\r\n'
                                   "        print('[Validation][learning_phase=1] Epoch: "
                                   '{:d}/{:d} - loss: {:.3f} - acc: '
                                   "{:.3f}'.format(epoch+1, num_epoch, c_loss_t, acc_t) "
                                   ')\r\n'
                                   "        print('[Validation][learning_phase=0] Epoch: "
                                   '{:d}/{:d} - loss: {:.3f} - acc: '
                                   "{:.3f}'.format(epoch+1, num_epoch, c_loss_f, acc_f) "
                                   ')\r\n'
                                   '\r\n'
                                   '    # evaluate\r\n'
                                   '    num_epoch = 1\r\n'
                                   '    total_len = testY.shape[0] // batch_size\r\n'
                                   '    tf_iter = '
                                   'tf.compat.v1.data.make_initializable_iterator(test_gen)\r\n'
                                   '    tf_next = tf_iter.get_next()\r\n'
                                   '    sess.run(tf_iter.initializer)\r\n'
                                   '    for epoch in range(num_epoch):\r\n'
                                   '        c_loss_t, acc_t, c_loss_f, acc_f = 0.0, 0.0, '
                                   '0.0, 0.0\r\n'
                                   '        for ii in range(total_len):\r\n'
                                   '            X, Y = sess.run(tf_next)\r\n'
                                   '            [b_c_loss, b_acc] = '
                                   'sess.run([model.c_loss, model.op_acc],\r\n'
                                   '                                        feed_dict={ '
                                   'model.clf_input: X,\r\n'
                                   '                                                    '
                                   'model.label_ref: Y,\r\n'
                                   '                                                    '
                                   'tf.keras.backend.learning_phase(): 1})\r\n'
                                   '            c_loss_t = c_loss_t + b_c_loss\r\n'
                                   '            acc_t = acc_t + b_acc\r\n'
                                   '\r\n'
                                   '            [b_c_loss, b_acc] = '
                                   'sess.run([model.c_loss, model.op_acc],\r\n'
                                   '                                        feed_dict={ '
                                   'model.clf_input: X,\r\n'
                                   '                                                    '
                                   'model.label_ref: Y,\r\n'
                                   '                                                    '
                                   'tf.keras.backend.learning_phase(): 0})\r\n'
                                   '            c_loss_f = c_loss_f + b_c_loss\r\n'
                                   '            acc_f = acc_f + b_acc\r\n'
                                   '\r\n'
                                   '        c_loss_t = c_loss_t / total_len\r\n'
                                   '        c_loss_f = c_loss_f / total_len\r\n'
                                   '        acc_t = acc_t / total_len\r\n'
                                   '        acc_f = acc_f / total_len\r\n'
                                   "        print('[Testing][learning_phase=1] Epoch: "
                                   '{:d}/{:d} - loss: {:.3f} - acc: '
                                   "{:.3f}'.format(epoch+1, num_epoch, c_loss_t, acc_t) "
                                   ')\r\n'
                                   "        print('[Testing][learning_phase=0] Epoch: "
                                   '{:d}/{:d} - loss: {:.3f} - acc: '
                                   "{:.3f}'.format(epoch+1, num_epoch, c_loss_f, acc_f) "
                                   ')\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'The first part of testing case is training model with '
                                   'high leval API and the result is as expected.\r\n'
                                   '```\r\n'
                                   '450/450 - 39s - loss: 1.9658 - accuracy: 0.2993 - '
                                   'val_loss: 1.7215 - val_accuracy: 0.3738\r\n'
                                   'Epoch 2/5\r\n'
                                   '450/450 - 28s - loss: 1.5722 - accuracy: 0.4334 - '
                                   'val_loss: 1.5897 - val_accuracy: 0.4152\r\n'
                                   'Epoch 3/5\r\n'
                                   '450/450 - 27s - loss: 1.3876 - accuracy: 0.4993 - '
                                   'val_loss: 1.4867 - val_accuracy: 0.4770\r\n'
                                   'Epoch 4/5\r\n'
                                   '450/450 - 28s - loss: 1.2564 - accuracy: 0.5477 - '
                                   'val_loss: 1.3498 - val_accuracy: 0.5060\r\n'
                                   'Epoch 5/5\r\n'
                                   '450/450 - 27s - loss: 1.1488 - accuracy: 0.5888 - '
                                   'val_loss: 1.3380 - val_accuracy: 0.5232\r\n'
                                   '10000/10000 - 3s - loss: 1.3523 - accuracy: 0.5289\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'I got a strange loss and the ourput can be seen the '
                                   'following:\r\n'
                                   '```\r\n'
                                   'Make sure that we create a new model.\r\n'
                                   '10000/10000 - 3s - loss: 10.2004 - accuracy: '
                                   '0.1048\r\n'
                                   '[Training]Epoch: 1/5 - loss: 2.288 - acc: 0.268\r\n'
                                   '[Training]Epoch: 2/5 - loss: 1.513 - acc: 0.448\r\n'
                                   '[Training]Epoch: 3/5 - loss: 1.285 - acc: 0.537\r\n'
                                   '[Training]Epoch: 4/5 - loss: 1.426 - acc: 0.487\r\n'
                                   '[Training]Epoch: 5/5 - loss: 1.306 - acc: 0.535\r\n'
                                   'Show loss and accuracy with keras API\r\n'
                                   '45000/45000 - 9s - loss: nan - accuracy: 0.1002\r\n'
                                   '5000/5000 - 1s - loss: nan - accuracy: 0.0986\r\n'
                                   '10000/10000 - 2s - loss: nan - accuracy: 0.1000\r\n'
                                   'Show loss and accuracy with low level API\r\n'
                                   '[Validation][learning_phase=1] Epoch: 1/1 - loss: '
                                   '1.163 - acc: 0.585\r\n'
                                   '[Validation][learning_phase=0] Epoch: 1/1 - loss: nan '
                                   '- acc: 0.099\r\n'
                                   '[Testing][learning_phase=1] Epoch: 1/1 - loss: 1.179 '
                                   '- acc: 0.587\r\n'
                                   '[Testing][learning_phase=0] Epoch: 1/1 - loss: nan - '
                                   'acc: 0.100\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'Obviously, after training custom model with low level '
                                   'API, the result would be wrong when setting '
                                   '`tf.keras.backend.learning_phase(): 0`\r\n'
                                   '\r\n'
                                   'Also, the result from keras API is wrong too.\r\n'
                                   '\r\n'
                                   '`tf.keras.backend.learning_phase(): 0` may affect the '
                                   'behavior of `tf.keras.layers.BatchNormalization()` '
                                   "but I'm not sure whether this is root cause.\r\n"
                                   '\r\n'
                                   'I have tried a small custom model without '
                                   '`tf.keras.layers.BatchNormalization()` for MNIST '
                                   'dataset and the result is normal.\r\n'
                                   '\r\n'
                                   'The testcase for MNIST as shown in the following:\r\n'
                                   '\r\n'
                                   '```python\r\n'
                                   'import tensorflow as tf\r\n'
                                   'tf.compat.v1.disable_eager_execution()\r\n'
                                   '#tf.compat.v1.disable_v2_behavior()\r\n'
                                   '\r\n'
                                   'import numpy as np\r\n'
                                   '\r\n'
                                   'batch_size = 100\r\n'
                                   '\r\n'
                                   'def download_data():\r\n'
                                   '\r\n'
                                   '    # get raw data\r\n'
                                   '    (trainX, trainY), (testX, testY) = '
                                   'tf.keras.datasets.mnist.load_data()\r\n'
                                   '    trainX = trainX.astype(np.float32)\r\n'
                                   '    testX  = testX.astype(np.float32)\r\n'
                                   '\r\n'
                                   '    # ont-hot\r\n'
                                   '    trainY = tf.keras.utils.to_categorical(trainY, '
                                   '10)\r\n'
                                   '    testY  = tf.keras.utils.to_categorical(testY , '
                                   '10)\r\n'
                                   '\r\n'
                                   '    # get validation sets\r\n'
                                   '    training_size = 55000\r\n'
                                   '    validX = trainX[training_size:,:]\r\n'
                                   '    validY = trainY[training_size:,:]\r\n'
                                   '\r\n'
                                   '    trainX = trainX[:training_size,:]\r\n'
                                   '    trainY = trainY[:training_size,:]\r\n'
                                   '\r\n'
                                   '    # expand dimesion\r\n'
                                   '    trainX = np.expand_dims(trainX, axis=3)\r\n'
                                   '    validX = np.expand_dims(validX, axis=3)\r\n'
                                   '    testX  = np.expand_dims(testX , axis=3)\r\n'
                                   '\r\n'
                                   '    return trainX, trainY, validX, validY, testX, '
                                   'testY\r\n'
                                   '\r\n'
                                   'def data_pipeline(dataX, dataY):\r\n'
                                   '\r\n'
                                   '        dataset = tf.data.Dataset.from_tensor_slices( '
                                   '(dataX, dataY) )\r\n'
                                   '        dataset = dataset.shuffle(batch_size * 8)\r\n'
                                   '        dataset = dataset.repeat()\r\n'
                                   '        dataset = dataset.batch(batch_size)\r\n'
                                   '        dataset = '
                                   'dataset.prefetch(tf.data.experimental.AUTOTUNE)\r\n'
                                   '        return dataset\r\n'
                                   '\r\n'
                                   'class custom_model():\r\n'
                                   '    def __init__(self):\r\n'
                                   '\r\n'
                                   '        def Acc():\r\n'
                                   '            acc = '
                                   'tf.keras.metrics.categorical_accuracy(label_ref, '
                                   'clf_out)\r\n'
                                   '            return tf.math.reduce_mean(acc)\r\n'
                                   '\r\n'
                                   '        def c_loss():\r\n'
                                   '            loss = '
                                   'tf.keras.losses.categorical_crossentropy(label_ref, '
                                   'clf_out)\r\n'
                                   '            loss = tf.math.reduce_mean(loss)\r\n'
                                   '            return loss\r\n'
                                   '\r\n'
                                   '        # declare variables\r\n'
                                   '        self.init_op = '
                                   'tf.compat.v1.keras.initializers.he_normal()\r\n'
                                   '        model_layers = [ tf.keras.layers.Conv2D(16, '
                                   '(3, 3), padding="same", activation="relu", '
                                   'kernel_initializer=self.init_op, name="clf/c1"),\r\n'
                                   '                         tf.keras.layers.Conv2D(32, '
                                   '(3, 3), padding="same", activation="relu", '
                                   'kernel_initializer=self.init_op, name="clf/c2"),\r\n'
                                   '                         '
                                   'tf.keras.layers.MaxPooling2D(pool_size=(2, 2), '
                                   'name="clf/p1"),\r\n'
                                   '                         tf.keras.layers.Conv2D(32, '
                                   '(3, 3), padding="same", activation="relu", '
                                   'kernel_initializer=self.init_op, name="clf/c3"),\r\n'
                                   '                         tf.keras.layers.Conv2D(64, '
                                   '(3, 3), padding="same", activation="relu", '
                                   'kernel_initializer=self.init_op, name="clf/c4"),\r\n'
                                   '                         '
                                   'tf.keras.layers.MaxPooling2D(pool_size=(2, 2), '
                                   'name="clf/p2"),\r\n'
                                   '                         '
                                   'tf.keras.layers.Flatten(name="clf/f1"),\r\n'
                                   '                         tf.keras.layers.Dense(256, '
                                   'activation="relu", kernel_initializer=self.init_op, '
                                   'name="clf/d1"),\r\n'
                                   '                         tf.keras.layers.Dense(10 , '
                                   'activation=None  , kernel_initializer=self.init_op, '
                                   'name="clf/d2"),\r\n'
                                   '                         '
                                   "tf.keras.layers.Activation('softmax', "
                                   'name="clf/a1")\r\n'
                                   '                        ]\r\n'
                                   '\r\n'
                                   '        # clf_model\r\n'
                                   '        clf_input = '
                                   'tf.keras.layers.Input(shape=(28,28,1 ), '
                                   'name="model/input")\r\n'
                                   '        clf_out   = clf_input\r\n'
                                   '        for ii in model_layers:\r\n'
                                   '            clf_out = ii(clf_out)\r\n'
                                   '        clf_model = '
                                   'tf.keras.models.Model(inputs=clf_input, '
                                   "outputs=clf_out, name='clf_model')\r\n"
                                   '        '
                                   "clf_model.compile(loss='categorical_crossentropy', "
                                   "optimizer='Nadam', metrics=['accuracy'])\r\n"
                                   '\r\n'
                                   '\r\n'
                                   '        label_ref = tf.keras.layers.Input(shape=(10,) '
                                   ", name='label_ref')\r\n"
                                   '        clf_out = clf_model(clf_input)\r\n'
                                   '\r\n'
                                   '        # using tf.keras.optimizers.Nadam would get '
                                   'error\r\n'
                                   '        #optimizer = '
                                   'tf.keras.optimizers.Nadam(lr=0.0005)\r\n'
                                   '        optimizer = '
                                   'tf.compat.v1.train.AdamOptimizer(learning_rate=0.01)\r\n'
                                   '        self.train_op = optimizer.minimize(c_loss(), '
                                   'var_list=[clf_model.trainable_variables])\r\n'
                                   '\r\n'
                                   '        self.clf_model = clf_model\r\n'
                                   '        self.clf_input = clf_input\r\n'
                                   '        self.label_ref = label_ref\r\n'
                                   '        self.op_acc = Acc()\r\n'
                                   '        self.c_loss = c_loss()\r\n'
                                   '\r\n'
                                   "if __name__ == '__main__':\r\n"
                                   '\r\n'
                                   '    # set GPU\r\n'
                                   '    import os\r\n'
                                   '    if os.environ.get("CUDA_VISIBLE_DEVICES") is '
                                   'None:\r\n'
                                   '        os.environ["CUDA_VISIBLE_DEVICES"] = "0"\r\n'
                                   '\r\n'
                                   '    # reset tf session\r\n'
                                   '    tf.compat.v1.keras.backend.clear_session()\r\n'
                                   '    gpu_options = '
                                   'tf.compat.v1.GPUOptions(allow_growth=True)\r\n'
                                   '    sess = '
                                   'tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\r\n'
                                   '    tf.compat.v1.keras.backend.set_session(sess) \r\n'
                                   '\r\n'
                                   '    # prepare data\r\n'
                                   '    trainX, trainY, validX, validY, testX, testY = '
                                   'download_data()\r\n'
                                   '    train_gen = data_pipeline(trainX, trainY)\r\n'
                                   '    valid_gen = data_pipeline(validX, validY)\r\n'
                                   '    test_gen = data_pipeline(testX, testY)\r\n'
                                   '\r\n'
                                   '    # create a new model\r\n'
                                   "    print('Make sure that we create a new model.')\r\n"
                                   '    model = custom_model()\r\n'
                                   '    '
                                   'sess.run(tf.compat.v1.global_variables_initializer())\r\n'
                                   '    model.clf_model.evaluate(testX, testY, verbose=2, '
                                   'batch_size=batch_size)\r\n'
                                   '\r\n'
                                   '    # train model\r\n'
                                   '    num_epoch = 5\r\n'
                                   '    total_len = trainY.shape[0] // batch_size\r\n'
                                   '    tf_iter = '
                                   'tf.compat.v1.data.make_initializable_iterator(train_gen)\r\n'
                                   '    tf_next = tf_iter.get_next()\r\n'
                                   '    sess.run(tf_iter.initializer)\r\n'
                                   '    for epoch in range(num_epoch):\r\n'
                                   '        c_loss, acc = 0.0, 0.0\r\n'
                                   '        for ii in range(total_len):\r\n'
                                   '            X, Y = sess.run(tf_next)\r\n'
                                   '            [b_c_loss, b_acc, _] = '
                                   'sess.run([model.c_loss, model.op_acc, '
                                   'model.train_op],\r\n'
                                   '                                                '
                                   'feed_dict={ model.clf_input: X,\r\n'
                                   '                                                            '
                                   'model.label_ref: Y,\r\n'
                                   '                                                            '
                                   'tf.keras.backend.learning_phase(): 1})\r\n'
                                   '            c_loss = c_loss + b_c_loss\r\n'
                                   '            acc = acc + b_acc\r\n'
                                   '        \r\n'
                                   '        c_loss = c_loss / total_len\r\n'
                                   '        acc = acc / total_len\r\n'
                                   "        print('[Training]Epoch: {:d}/{:d} - loss: "
                                   "{:.3f} - acc: {:.3f}'.format(epoch+1, num_epoch, "
                                   'c_loss, acc) )\r\n'
                                   '\r\n'
                                   "    print('Show loss and accuracy with keras API')\r\n"
                                   '    model.clf_model.evaluate(trainX, trainY, '
                                   'verbose=2, batch_size=batch_size)\r\n'
                                   '    model.clf_model.evaluate(validX, validY, '
                                   'verbose=2, batch_size=batch_size)\r\n'
                                   '    model.clf_model.evaluate(testX, testY, verbose=2, '
                                   'batch_size=batch_size)\r\n'
                                   '\r\n'
                                   "    print('Show loss and accuracy with low level "
                                   "API')\r\n"
                                   '    # evaluate\r\n'
                                   '    num_epoch = 1\r\n'
                                   '    total_len = validY.shape[0] // batch_size\r\n'
                                   '    tf_iter = '
                                   'tf.compat.v1.data.make_initializable_iterator(valid_gen)\r\n'
                                   '    tf_next = tf_iter.get_next()\r\n'
                                   '    sess.run(tf_iter.initializer)\r\n'
                                   '    for epoch in range(num_epoch):\r\n'
                                   '        c_loss_t, acc_t, c_loss_f, acc_f = 0.0, 0.0, '
                                   '0.0, 0.0\r\n'
                                   '        for ii in range(total_len):\r\n'
                                   '            X, Y = sess.run(tf_next)\r\n'
                                   '            [b_c_loss, b_acc] = '
                                   'sess.run([model.c_loss, model.op_acc],\r\n'
                                   '                                        feed_dict={ '
                                   'model.clf_input: X,\r\n'
                                   '                                                    '
                                   'model.label_ref: Y,\r\n'
                                   '                                                    '
                                   'tf.keras.backend.learning_phase(): 1})\r\n'
                                   '            c_loss_t = c_loss_t + b_c_loss\r\n'
                                   '            acc_t = acc_t + b_acc\r\n'
                                   '\r\n'
                                   '            [b_c_loss, b_acc] = '
                                   'sess.run([model.c_loss, model.op_acc],\r\n'
                                   '                                        feed_dict={ '
                                   'model.clf_input: X,\r\n'
                                   '                                                    '
                                   'model.label_ref: Y,\r\n'
                                   '                                                    '
                                   'tf.keras.backend.learning_phase(): 0})\r\n'
                                   '            c_loss_f = c_loss_f + b_c_loss\r\n'
                                   '            acc_f = acc_f + b_acc\r\n'
                                   '\r\n'
                                   '        c_loss_t = c_loss_t / total_len\r\n'
                                   '        c_loss_f = c_loss_f / total_len\r\n'
                                   '        acc_t = acc_t / total_len\r\n'
                                   '        acc_f = acc_f / total_len\r\n'
                                   "        print('[Validation][learning_phase=1] Epoch: "
                                   '{:d}/{:d} - loss: {:.3f} - acc: '
                                   "{:.3f}'.format(epoch+1, num_epoch, c_loss_t, acc_t) "
                                   ')\r\n'
                                   "        print('[Validation][learning_phase=0] Epoch: "
                                   '{:d}/{:d} - loss: {:.3f} - acc: '
                                   "{:.3f}'.format(epoch+1, num_epoch, c_loss_f, acc_f) "
                                   ')\r\n'
                                   '\r\n'
                                   '    # evaluate\r\n'
                                   '    num_epoch = 1\r\n'
                                   '    total_len = testY.shape[0] // batch_size\r\n'
                                   '    tf_iter = '
                                   'tf.compat.v1.data.make_initializable_iterator(test_gen)\r\n'
                                   '    tf_next = tf_iter.get_next()\r\n'
                                   '    sess.run(tf_iter.initializer)\r\n'
                                   '    for epoch in range(num_epoch):\r\n'
                                   '        c_loss_t, acc_t, c_loss_f, acc_f = 0.0, 0.0, '
                                   '0.0, 0.0\r\n'
                                   '        for ii in range(total_len):\r\n'
                                   '            X, Y = sess.run(tf_next)\r\n'
                                   '            [b_c_loss, b_acc] = '
                                   'sess.run([model.c_loss, model.op_acc],\r\n'
                                   '                                        feed_dict={ '
                                   'model.clf_input: X,\r\n'
                                   '                                                    '
                                   'model.label_ref: Y,\r\n'
                                   '                                                    '
                                   'tf.keras.backend.learning_phase(): 1})\r\n'
                                   '            c_loss_t = c_loss_t + b_c_loss\r\n'
                                   '            acc_t = acc_t + b_acc\r\n'
                                   '\r\n'
                                   '            [b_c_loss, b_acc] = '
                                   'sess.run([model.c_loss, model.op_acc],\r\n'
                                   '                                        feed_dict={ '
                                   'model.clf_input: X,\r\n'
                                   '                                                    '
                                   'model.label_ref: Y,\r\n'
                                   '                                                    '
                                   'tf.keras.backend.learning_phase(): 0})\r\n'
                                   '            c_loss_f = c_loss_f + b_c_loss\r\n'
                                   '            acc_f = acc_f + b_acc\r\n'
                                   '\r\n'
                                   '        c_loss_t = c_loss_t / total_len\r\n'
                                   '        c_loss_f = c_loss_f / total_len\r\n'
                                   '        acc_t = acc_t / total_len\r\n'
                                   '        acc_f = acc_f / total_len\r\n'
                                   "        print('[Testing][learning_phase=1] Epoch: "
                                   '{:d}/{:d} - loss: {:.3f} - acc: '
                                   "{:.3f}'.format(epoch+1, num_epoch, c_loss_t, acc_t) "
                                   ')\r\n'
                                   "        print('[Testing][learning_phase=0] Epoch: "
                                   '{:d}/{:d} - loss: {:.3f} - acc: '
                                   "{:.3f}'.format(epoch+1, num_epoch, c_loss_f, acc_f) "
                                   ')\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'Definitely, we got a very normal output:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'Make sure that we create a new model.\r\n'
                                   '10000/10000 - 1s - loss: 398.0696 - acc: 0.1151\r\n'
                                   '[Training]Epoch: 1/5 - loss: 11.997 - acc: 0.558\r\n'
                                   '[Training]Epoch: 2/5 - loss: 0.474 - acc: 0.849\r\n'
                                   '[Training]Epoch: 3/5 - loss: 0.282 - acc: 0.914\r\n'
                                   '[Training]Epoch: 4/5 - loss: 0.213 - acc: 0.935\r\n'
                                   '[Training]Epoch: 5/5 - loss: 0.181 - acc: 0.945\r\n'
                                   'Show loss and accuracy with keras API\r\n'
                                   '55000/55000 - 1s - loss: 0.1555 - acc: 0.9535\r\n'
                                   '5000/5000 - 0s - loss: 0.1501 - acc: 0.9584\r\n'
                                   '10000/10000 - 0s - loss: 0.1687 - acc: 0.9539\r\n'
                                   'Show loss and accuracy with low level API\r\n'
                                   '[Validation][learning_phase=1] Epoch: 1/1 - loss: '
                                   '0.150 - acc: 0.958\r\n'
                                   '[Validation][learning_phase=0] Epoch: 1/1 - loss: '
                                   '0.150 - acc: 0.958\r\n'
                                   '[Testing][learning_phase=1] Epoch: 1/1 - loss: 0.169 '
                                   '- acc: 0.954\r\n'
                                   '[Testing][learning_phase=0] Epoch: 1/1 - loss: 0.169 '
                                   '- acc: 0.954\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   '\r\n'
                                   'It should work properly.\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   '\r\n'
                                   'Please see the section of **Describe the current '
                                   'behavior**\r\n'
                                   '\r\n'
                                   '**Other info / logs**\r\n'
                                   '\r\n'
                                   'skip ...',
                           'created_at': '2019-12-1'},
                          {'body': '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): N/A\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Ubuntu 16.04.6\r\n'
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device:\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'binary\r\n'
                                   '- TensorFlow version (use command below): '
                                   'v2.0.0-rc2-26-g64c3d38 2.0.0\r\n'
                                   '- Python version: 3.7.3\r\n'
                                   '- Bazel version (if compiling from source): N/A\r\n'
                                   '- GCC/Compiler version (if compiling from source): '
                                   'N/A\r\n'
                                   '- CUDA/cuDNN version: V10.0.130\r\n'
                                   '- GPU model and memory: Tesla V100-SXM2\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'In the Adam paper, we subtract the following quantity '
                                   'from our current gradient [0]:\r\n'
                                   '\\alpha * \\hat{m_t} / (\\sqrt{v_t / (1-\\beta^t_2)}  '
                                   '+ \\epsilon)\r\n'
                                   '\r\n'
                                   '<img width="475" alt="Screen Shot 2019-12-13 at 2 32 '
                                   '58 PM" '
                                   'src="https://user-images.githubusercontent.com/54961543/70836600-7f490780-1db5-11ea-9669-27c50fe48cae.png">\r\n'
                                   '\r\n'
                                   'The Tensorflow implementation subtracts a subtly '
                                   'different quantity ([1]):\r\n'
                                   '\\alpha * \\hat{m_t} * \\sqrt{1-\\beta^T_2} / '
                                   '(\\sqrt{v_t} + \\epsilon)\r\n'
                                   '\r\n'
                                   '<img width="438" alt="Screen Shot 2019-12-13 at 2 34 '
                                   '36 PM" '
                                   'src="https://user-images.githubusercontent.com/54961543/70836654-c1724900-1db5-11ea-9260-5fc0678f6f39.png">\r\n'
                                   '\r\n'
                                   'The difference between the two expressions is that in '
                                   'the first, we de-bias only the moving average of the '
                                   'squared gradient, v_t. In the second, this bias '
                                   'correction is also applied to \\epsilon. This '
                                   'manifests as scaling up epilson quite a lot in very '
                                   'early training steps, reducing the magnitude of the '
                                   'gradient update.\r\n'
                                   '\r\n'
                                   'Note that the same bug was present in PyTorch prior '
                                   'to v1.3. It was fixed in this PR: '
                                   'https://github.com/pytorch/pytorch/pull/22628. That '
                                   'PR description provides a useful visualization.\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   'Implement the algorithm as described in the paper. If '
                                   'the old implementation is necessary to preserve '
                                   'back-compat, providing a flag to trigger the correct '
                                   'implementation would be most helpful.\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '[0] https://arxiv.org/pdf/1412.6980.pdf, see final 2 '
                                   'lines of Algorithm 1\r\n'
                                   '[1] Notable lines in TF implementation regarding this '
                                   'issue: \r\n'
                                   'https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/optimizer_v2/adam.py#L162\r\n'
                                   '\r\n'
                                   'https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/optimizer_v2/adam.py#L245\r\n'
                                   '\r\n'
                                   'https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/training_ops.cc#L373\r\n'
                                   '\r\n',
                           'created_at': '2019-12-1'},
                          {'body': '**System information**\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): OSX 10.14.6\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'source\r\n'
                                   '- TensorFlow version: 1.15.0 (same observation for '
                                   'version 2.0), from '
                                   'https://github.com/tensorflow/tensorflow/releases/tag/v1.15.0\r\n'
                                   '- Python version: python3\r\n'
                                   '- GCC/Compiler version (if compiling from source): '
                                   'arm-none-eabi-g++\r\n'
                                   '\r\n'
                                   '**Describe the problem**\r\n'
                                   'The standalone projects generated with Tensorflow '
                                   'Lite seem to be missing some headers.\r\n'
                                   '\r\n'
                                   'Following this tutorial: \r\n'
                                   '[https://www.tensorflow.org/lite/microcontrollers/library#generate_projects_for_other_platforms\r\n'
                                   '](https://www.tensorflow.org/lite/microcontrollers/library#generate_projects_for_other_platforms\r\n'
                                   ')\r\n'
                                   '\r\n'
                                   'I run the following command (the link seems to be off '
                                   "here in the tutorial, as 'micro' is in another "
                                   "subfolder' experimental'):\r\n"
                                   '`gmake -f '
                                   'tensorflow/lite/experimental/micro/tools/make/Makefile '
                                   'TARGET=sparkfun_edge generate_projects`\r\n'
                                   '\r\n'
                                   'After this command is finished, the files are '
                                   'generated as expected in:\r\n'
                                   '`tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/prj`\r\n'
                                   '\r\n'
                                   'But when trying to build the micro_speech binary like '
                                   'this:\r\n'
                                   '```\r\n'
                                   'cd '
                                   'tensorflow/lite/experimental/micro/tools/make/gen/sparkfun_edge_cortex-m4/prj/micro_speech/make\r\n'
                                   'gmake\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'I am getting the following error:\r\n'
                                   '```\r\n'
                                   'arm-none-eabi-g++ -O3 -DNDEBUG -std=c++11 -g '
                                   '-DTF_LITE_STATIC_MEMORY -DPART_apollo3 '
                                   '-DAM_PACKAGE_BGA -DAM_PART_APOLLO3 '
                                   '-DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK '
                                   '-DTF_LITE_STATIC_MEMORY -DNDEBUG '
                                   '-DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 '
                                   '-DARM_MATH_CM4 -fno-rtti -fmessage-length=0 '
                                   '-fno-exceptions -fno-unwind-tables -fno-builtin '
                                   '-ffunction-sections -fdata-sections -funsigned-char '
                                   '-MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 '
                                   '-mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra '
                                   '-Wno-unused-parameter -Wno-missing-field-initializers '
                                   '-Wno-write-strings -Wno-sign-compare '
                                   '-fno-delete-null-pointer-checks -fomit-frame-pointer '
                                   '-fpermissive -nostdlib -ggdb -O3 -I. '
                                   '-I./third_party/gemmlowp '
                                   '-I./third_party/flatbuffers/include '
                                   '-I./third_party/kissfft  -c '
                                   'tensorflow/lite/experimental/micro/sparkfun_edge/debug_log.cc '
                                   '-o '
                                   'tensorflow/lite/experimental/micro/sparkfun_edge/debug_log.o\r\n'
                                   'tensorflow/lite/experimental/micro/sparkfun_edge/debug_log.cc:22:10: '
                                   'fatal error: am_bsp.h: No such file or directory\r\n'
                                   ' #include "am_bsp.h"   // NOLINT\r\n'
                                   '          ^~~~~~~~~~\r\n'
                                   'compilation terminated.\r\n'
                                   'make: *** '
                                   '[tensorflow/lite/experimental/micro/sparkfun_edge/debug_log.o] '
                                   'Error 1\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'This is the header file of the sparkfun edge board '
                                   'that I want to build this for.\r\n',
                           'created_at': '2019-12-1'},
                          {'body': '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow):\r\n'
                                   '- OS Platform and Distribution: Linux Ubuntu 16.04\r\n'
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device:\r\n'
                                   '- TensorFlow installed from (source or binary):\r\n'
                                   '- TensorFlow version (use command below): 2.0\r\n'
                                   '- Python version: 3.6.8\r\n'
                                   '- Bazel version (if compiling from source):\r\n'
                                   '- GCC/Compiler version (if compiling from source):\r\n'
                                   '- CUDA/cuDNN version:\r\n'
                                   '- GPU model and memory:\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   '\r\n'
                                   '<img width="368" alt=" 2019-12-13 6 06 20" '
                                   'src="https://user-images.githubusercontent.com/22017000/70792077-6c453000-1dd3-11ea-8489-5b6131950515.png">\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   '\r\n'
                                   'The tf.data.Dataset instance should be freed in every '
                                   'step.\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   '\r\n'
                                   '```python\r\n'
                                   'import tensorflow as tf\r\n'
                                   'import os\r\n'
                                   'import numpy as np\r\n'
                                   'import psutil\r\n'
                                   '\r\n'
                                   'def _generator():\r\n'
                                   '    for i in range(100):\r\n'
                                   '        yield "1,2,3,4,5,6,7,8"\r\n'
                                   '\r\n'
                                   'def _py_parse_data(record):\r\n'
                                   '    record = record.numpy()\r\n'
                                   '    record = bytes.decode(record)\r\n'
                                   '    rl = record.split(",")\r\n'
                                   '    rl = [str(int(r) + 1) for r in rl]\r\n'
                                   '    return [",".join(rl)]\r\n'
                                   '\r\n'
                                   'def parse_data(record, shape=10):\r\n'
                                   '    sparse_data = tf.strings.split([record], '
                                   'sep=",")\r\n'
                                   '    sparse_data = '
                                   'tf.strings.to_number(sparse_data[0], tf.int64)\r\n'
                                   '    ids_num = tf.cast(tf.size(sparse_data), '
                                   'tf.int64)\r\n'
                                   '    indices = tf.range(0, ids_num, dtype=tf.int64)\r\n'
                                   '    indices = tf.reshape(indices, shape=(-1, 1))\r\n'
                                   '    sparse_data = tf.sparse.SparseTensor(\r\n'
                                   '                indices, sparse_data, '
                                   'dense_shape=(shape,)\r\n'
                                   '    )\r\n'
                                   '    return sparse_data\r\n'
                                   '\r\n'
                                   'process = psutil.Process(os.getpid())\r\n'
                                   '\r\n'
                                   'step = 0\r\n'
                                   'while (step < 10000):\r\n'
                                   '    t = tf.data.Dataset.from_generator(_generator, '
                                   'output_types=tf.string)\r\n'
                                   '    t = t.map(lambda record: '
                                   'tf.py_function(_py_parse_data, [record], '
                                   '[tf.string]))\r\n'
                                   '    t = t.map(parse_data)\r\n'
                                   '    for d in t:\r\n'
                                   '        a = 1\r\n'
                                   '    if step % 10 == 0:\r\n'
                                   '        print("Memory : ", '
                                   'process.memory_info().rss)\r\n'
                                   '    step += 1\r\n'
                                   '```\r\n'
                                   '\r\n',
                           'created_at': '2019-12-1'},
                          {'body': 'Thank you for submitting a TensorFlow documentation '
                                   'issue. Per our GitHub\r\n'
                                   'policy, we only address code/doc bugs, performance '
                                   'issues, feature requests, and\r\n'
                                   'build/installation issues on GitHub.\r\n'
                                   '\r\n'
                                   'The TensorFlow docs are open source! To get involved, '
                                   'read the documentation\r\n'
                                   'contributor guide: '
                                   'https://www.tensorflow.org/community/contribute/docs\r\n'
                                   '\r\n'
                                   '## URL(s) with the issue:\r\n'
                                   '\r\n'
                                   'Please provide a link to the documentation entry, for '
                                   'example:\r\n'
                                   'https://www.tensorflow.org/api_docs/python/tf/audio\r\n'
                                   '\r\n'
                                   '## Description of issue (what needs changing):\r\n'
                                   'Currently, there are no usage examples for tf.audio '
                                   'APIs , which makes it difficult for new users to '
                                   'implement the same.\r\n'
                                   '\r\n'
                                   '### Clear description\r\n'
                                   '\r\n'
                                   'For example, why should someone use this method? How '
                                   'is it useful?\r\n'
                                   '**Audio is an area not really explored in machine '
                                   'learning to extent image and text has. While '
                                   'TensorFlow does provide a good amount of '
                                   'documentation for the general Args and Returns of the '
                                   'various functions under tf.audio, since most new '
                                   'users will have very little experience with audio as '
                                   'compared to tf.image**\n'
                                   '\r\n'
                                   '### Correct links\r\n'
                                   '\r\n'
                                   'Is the link to the source code correct?\r\n'
                                   '**Yes**\r\n'
                                   '\r\n'
                                   '### Parameters defined\r\n'
                                   '\r\n'
                                   'Are all parameters defined and formatted '
                                   'correctly?\r\n'
                                   '**Yes**\r\n'
                                   '\r\n'
                                   '### Returns defined\r\n'
                                   '\r\n'
                                   'Are return values defined?\r\n'
                                   '**Yes**\r\n'
                                   '\r\n'
                                   '### Raises listed and defined\r\n'
                                   '\r\n'
                                   'Are the errors defined? For example,\r\n'
                                   'https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n'
                                   '**No**\r\n'
                                   '\r\n'
                                   '### Usage example\r\n'
                                   '\r\n'
                                   'Is there a usage example?\r\n'
                                   '**No**\r\n'
                                   '\r\n'
                                   'See the API guide: '
                                   'https://www.tensorflow.org/community/contribute/docs_ref\r\n'
                                   'on how to write testable usage examples.\r\n'
                                   '\r\n'
                                   '### Request visuals, if applicable\r\n'
                                   '\r\n'
                                   'Are there currently visuals? If not, will it clarify '
                                   'the content?\r\n'
                                   '**Formatted code blocks are present, which are '
                                   'satisfactory.**\r\n'
                                   '\r\n'
                                   '### Submit a pull request?\r\n'
                                   '\r\n'
                                   'Are you planning to also submit a pull request to fix '
                                   'the issue? See the docs\r\n'
                                   'contributor guide: '
                                   'https://www.tensorflow.org/community/contribute/docs,\r\n'
                                   'docs API guide: '
                                   'https://www.tensorflow.org/community/contribute/docs_ref '
                                   'and the\r\n'
                                   'docs style guide: '
                                   'https://www.tensorflow.org/community/contribute/docs_style\r\n'
                                   '**Yes, I think I can provide a detailed usage '
                                   'example.**\r\n'
                                   '  ',
                           'created_at': '2019-12-1'},
                          {'body': 'TensorFlow Lite for Microcontrollers has a MAXPOOL '
                                   'operation, but it only supports float and uint8 '
                                   'execution, not int8.',
                           'created_at': '2019-12-1'}],
            '2020-01-2': [{'body': '<em>Please make sure that this is a '
                                   'build/installation issue. As per our [GitHub '
                                   'Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), '
                                   'we only address code/doc bugs, performance issues, '
                                   'feature requests and build/installation issues on '
                                   'GitHub. tag:build_template</em>\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Windows 10 x64\r\n'
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device: N/A\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'source\r\n'
                                   '- TensorFlow version: master 2.1.0\r\n'
                                   '- Python version: 3.7.6\r\n'
                                   '- Installed using virtualenv? pip? conda?: N/A\r\n'
                                   '- Bazel version (if compiling from source): 1.2.1\r\n'
                                   '- GCC/Compiler version (if compiling from source):  '
                                   'Visual Studio 2019 C++ compiler\r\n'
                                   '- CUDA/cuDNN version: 10.2 / 7.6.5\r\n'
                                   '- GPU model and memory:\r\n'
                                   '\r\n'
                                   'RTX2080Ti GDDR6 11GB\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Describe the problem**\r\n'
                                   'bazel build failed\r\n'
                                   '**Provide the exact sequence of commands / steps that '
                                   'you executed before running into the problem**\r\n'
                                   'bazel build '
                                   '//tensorflwo/tools/pip_package:build_pip_package\r\n'
                                   '\r\n'
                                   '**Any other info / logs**\r\n'
                                   'Include any logs or source code that would be helpful '
                                   'to diagnose the problem. If including tracebacks, '
                                   'please include the full traceback. Large logs and '
                                   'files should be attached.\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'ERROR: D:/repo/tensorflow/tensorflow/BUILD:867:1: '
                                   'Executing genrule //tensorflow:tf_python_api_gen_v2 '
                                   'failed (Exit 1)\r\n'
                                   'C:\\Anaconda3\\lib\\site-packages\\numpy\\__init__.py:140: '
                                   'UserWarning: mkl-service package failed to import, '
                                   'therefore Intel(R) MKL initialization ensuring its '
                                   'correct out-of-the box operation under condition when '
                                   'Gnu OpenMP had already been loaded by Python process '
                                   'is not assured. Please install mkl-service package, '
                                   'see http://github.com/IntelPython/mkl-service\r\n'
                                   '  from . import _distributor_init\r\n'
                                   'Traceback (most recent call last):\r\n'
                                   '  File '
                                   '"C:\\Anaconda3\\lib\\site-packages\\numpy\\core\\__init__.py", '
                                   'line 24, in <module>\r\n'
                                   '    from . import multiarray\r\n'
                                   '  File '
                                   '"C:\\Anaconda3\\lib\\site-packages\\numpy\\core\\multiarray.py", '
                                   'line 14, in <module>\r\n'
                                   '    from . import overrides\r\n'
                                   '  File '
                                   '"C:\\Anaconda3\\lib\\site-packages\\numpy\\core\\overrides.py", '
                                   'line 7, in <module>\r\n'
                                   '    from numpy.core._multiarray_umath import (\r\n'
                                   'ImportError: DLL load failed: The specified module '
                                   'could not be found.\r\n'
                                   '\r\n'
                                   'During handling of the above exception, another '
                                   'exception occurred:\r\n'
                                   '\r\n'
                                   'Traceback (most recent call last):\r\n'
                                   '  File '
                                   '"\\\\?\\C:\\Users\\ALAN-W~1\\AppData\\Local\\Temp\\Bazel.runfiles_t25kvwuy\\runfiles\\org_tensorflow\\tensorflow\\python\\tools\\api\\generator\\create_python_api.py", '
                                   'line 27, in <module>\r\n'
                                   '    from tensorflow.python.tools.api.generator import '
                                   'doc_srcs\r\n'
                                   '  File '
                                   '"\\\\?\\C:\\Users\\ALAN-W~1\\AppData\\Local\\Temp\\Bazel.runfiles_t25kvwuy\\runfiles\\org_tensorflow\\tensorflow\\python\\__init__.py", '
                                   'line 48, in <module>\r\n'
                                   '    import numpy as np\r\n'
                                   '  File '
                                   '"C:\\Anaconda3\\lib\\site-packages\\numpy\\__init__.py", '
                                   'line 142, in <module>\r\n'
                                   '    from . import core\r\n'
                                   '  File '
                                   '"C:\\Anaconda3\\lib\\site-packages\\numpy\\core\\__init__.py", '
                                   'line 54, in <module>\r\n'
                                   '    raise ImportError(msg)\r\n'
                                   'ImportError:\r\n'
                                   '\r\n'
                                   'IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO '
                                   'SOLVE THIS ISSUE!\r\n'
                                   '\r\n'
                                   'Importing the numpy c-extensions failed.\r\n'
                                   '- Try uninstalling and reinstalling numpy.\r\n'
                                   '- If you have already done that, then:\r\n'
                                   '  1. Check that you expected to use Python3.7 from '
                                   '"C:\\Anaconda3\\python.exe",\r\n'
                                   '     and that you have no directories in your PATH or '
                                   'PYTHONPATH that can\r\n'
                                   '     interfere with the Python and numpy version '
                                   '"1.18.1" you\'re trying to use.\r\n'
                                   '  2. If (1) looks fine, you can open a new issue '
                                   'at\r\n'
                                   '     https://github.com/numpy/numpy/issues.  Please '
                                   'include details on:\r\n'
                                   '     - how you installed Python\r\n'
                                   '     - how you installed numpy\r\n'
                                   '     - your operating system\r\n'
                                   '     - whether or not you have multiple versions of '
                                   'Python installed\r\n'
                                   '     - if you built from source, your compiler '
                                   'versions and ideally a build log\r\n'
                                   '\r\n'
                                   "- If you're working with a numpy git repository, try "
                                   '`git clean -xdf`\r\n'
                                   '  (removes all files not under version control) and '
                                   'rebuild numpy.\r\n'
                                   '\r\n'
                                   'Note: this error has many possible causes, so please '
                                   "don't comment on\r\n"
                                   'an existing issue about this - open a new one '
                                   'instead.\r\n'
                                   '\r\n'
                                   'Original error was: DLL load failed: The specified '
                                   'module could not be found.\r\n'
                                   '\r\n'
                                   'Target '
                                   '//tensorflow/tools/pip_package:build_pip_package '
                                   'failed to build\r\n'
                                   'ERROR: '
                                   'D:/repo/tensorflow/tensorflow/tools/pip_package/BUILD:229:1 '
                                   'Executing genrule //tensorflow:tf_python_api_gen_v2 '
                                   'failed (Exit 1)\r\n'
                                   '```\r\n',
                           'created_at': '2020-01-1'},
                          {'body': 'This PR enables the kernel Relu for float16 on ROCm '
                                   "and removes some obsolete #ifdef's from "
                                   'relu_op_gpu.cu.cc.',
                           'created_at': '2020-01-1'},
                          {'body': '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): yes\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Mac OS X Catalina (10.15.2)\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'binary\r\n'
                                   '- TensorFlow version (use command below): '
                                   'v2.0.0-rc2-26-g64c3d382ca 2.0.0\r\n'
                                   '- Python version: 3.7.5\r\n'
                                   '- GPU model and memory: Intel Iris Pro 1536 MB\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   '\r\n'
                                   'I get the errors\r\n'
                                   '\r\n'
                                   '> tensorflow.python.eager.core._FallbackException: '
                                   'This function does not handle the case of the path '
                                   'where all inputs are not already EagerTensors.\r\n'
                                   '\r\n'
                                   'then \r\n'
                                   '\r\n'
                                   "> AttributeError: 'Tensor' object has no attribute "
                                   "'_datatype_enum'\r\n"
                                   '\r\n'
                                   'and then\r\n'
                                   '\r\n'
                                   "> AttributeError: 'ProgbarLogger' object has no "
                                   "attribute 'log_values'\r\n"
                                   '\r\n'
                                   'when I add the following callback to the list of '
                                   'callbacks of `my_model.fit`\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'my_callback = '
                                   'tf.keras.callbacks.LambdaCallback(on_batch_begin=lambda '
                                   'batch, logs: tf.print(my_model.losses))\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   '\r\n'
                                   'No error.\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'import tensorflow as tf\r\n'
                                   '\r\n'
                                   '\r\n'
                                   'def get_model():\r\n'
                                   '    inp = tf.keras.layers.Input(shape=(1,))\r\n'
                                   '    x = tf.keras.layers.Dense(8, '
                                   'activity_regularizer=tf.keras.regularizers.l1(0.01))(inp)\r\n'
                                   '    x = tf.keras.layers.Dense(16, '
                                   'activity_regularizer=tf.keras.regularizers.l1(0.01))(x)\r\n'
                                   '    out = tf.keras.layers.Dense(1)(x)\r\n'
                                   '    model = tf.keras.Model(inputs=inp, '
                                   'outputs=out)\r\n'
                                   '    return model\r\n'
                                   '\r\n'
                                   '\r\n'
                                   'def train():\r\n'
                                   '    my_model = get_model()\r\n'
                                   '    my_model.compile(optimizer="adam", loss="mse")\r\n'
                                   '    my_callback = '
                                   'tf.keras.callbacks.LambdaCallback(on_batch_begin=lambda '
                                   'batch, logs: tf.print(my_model.losses))\r\n'
                                   '    my_model.fit([1, 2, 3, 4], [0.1, 0.2, 0.4, 0.2], '
                                   'callbacks=[my_callback])\r\n'
                                   '\r\n'
                                   '\r\n'
                                   "if __name__ == '__main__':\r\n"
                                   '    train()\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'This issue may be related to '
                                   'https://github.com/tensorflow/tensorflow/issues/28924 '
                                   'and '
                                   'https://github.com/tensorflow/tensorflow/issues/29931. '
                                   "Note that, if I don't use any regulariser, `tf.print` "
                                   'prints an empty list and no error occurs.',
                           'created_at': '2020-01-1'},
                          {'body': '**System information**\r\n'
                                   '- Custom code\r\n'
                                   '- TensorFlow version 2.1.0\r\n'
                                   '- Python version: 3.7\r\n'
                                   '- GPU model: 4 V100 GPUs on Kubernetes Engine\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'On multi GPU loading the model from a h5 file is not '
                                   'working. \r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   'Saving and reloading the model from a h5 file using '
                                   'model.save and  keras.models.load_model should work '
                                   'on both single and multi GPU.\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   '``` python \r\n'
                                   'import tensorflow as tf \r\n'
                                   'import os\r\n'
                                   'import contextlib\r\n'
                                   'import numpy as np\r\n'
                                   'import tensorflow.keras as keras  \r\n'
                                   '\r\n'
                                   'def get_model():\r\n'
                                   '    model = keras.Sequential([\r\n'
                                   '        keras.layers.Flatten(input_shape=(28, '
                                   '28)),\r\n'
                                   '        keras.layers.Dense(10, '
                                   'activation=tf.nn.softmax)\r\n'
                                   '    ])\r\n'
                                   '    '
                                   'model.compile(optimizer=tf.keras.optimizers.Adam(),\r\n'
                                   '                      '
                                   "loss='sparse_categorical_crossentropy')\r\n"
                                   '    return model\r\n'
                                   '\r\n'
                                   'def get_model_path():\r\n'
                                   "    model_dir = '/tmp/m' + str(np.random.randint(0, "
                                   '1000000))\r\n'
                                   '    os.makedirs(model_dir)\r\n'
                                   "    model_path = os.path.join(model_dir, 'model')\r\n"
                                   '    return model_path + ".h5"\r\n'
                                   '\r\n'
                                   'def attempt_save_and_reload(model_path, '
                                   'distributed_training=False):\r\n'
                                   '    fashion_mnist = keras.datasets.fashion_mnist\r\n'
                                   '    (train_images, train_labels), (test_images, '
                                   'test_labels) = fashion_mnist.load_data()\r\n'
                                   '    train_images = train_images / 255.0\r\n'
                                   '    test_images = test_images / 255.0\r\n'
                                   '\r\n'
                                   '    with strategy.scope() if distributed_training '
                                   'else contextlib.nullcontext():\r\n'
                                   '        model = get_model()\r\n'
                                   '        model.fit(\r\n'
                                   '            train_images,\r\n'
                                   '            train_labels,\r\n'
                                   '            epochs=1,\r\n'
                                   '        )\r\n'
                                   '        model.save(model_path)\r\n'
                                   '        model = '
                                   'tf.keras.models.load_model(model_path)\r\n'
                                   '\r\n'
                                   "if __name__ == '__main__':\r\n"
                                   '    strategy = tf.distribute.MirroredStrategy()\r\n'
                                   '    for distributed_training in [False, True]:\r\n'
                                   "        print('distributed training: ', "
                                   'distributed_training)\r\n'
                                   '        model_path = get_model_path()\r\n'
                                   '        try:\r\n'
                                   '            attempt_save_and_reload(model_path, '
                                   'distributed_training)\r\n'
                                   '        except Exception as e:\r\n'
                                   "            print('Exception raised: \\n', e)\r\n"
                                   '        print()\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**other info/ logs**\r\n'
                                   'I need to use h5 files since saving the optimizer '
                                   'state does not work otherwise (see #33424).  The logs '
                                   'I get are: \r\n'
                                   '```\r\n'
                                   'INFO:tensorflow:Using MirroredStrategy with devices '
                                   "('/job:localhost/replica:0/task:0/device:GPU:0', "
                                   "'/job:localhost/replica:0/task:0/device:GPU:1', "
                                   "'/job:localhost/replica:0/task:0/device:GPU:2', "
                                   "'/job:localhost/replica:0/task:0/device:GPU:3')\r\n"
                                   'distributed training:  False\r\n'
                                   'Train on 60000 samples\r\n'
                                   '60000/60000 [==============================] - 3s '
                                   '52us/sample - loss: 0.5991\r\n'
                                   '\r\n'
                                   'distributed training:  True\r\n'
                                   'Train on 60000 samples\r\n'
                                   'INFO:tensorflow:batch_all_reduce: 2 all-reduces with '
                                   'algorithm = nccl, num_packs = 1, '
                                   'agg_small_grads_max_bytes = 0 and '
                                   'agg_small_grads_max_group = 10\r\n'
                                   'INFO:tensorflow:Reduce to '
                                   '/job:localhost/replica:0/task:0/device:CPU:0 then '
                                   'broadcast to '
                                   "('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n"
                                   'INFO:tensorflow:Reduce to '
                                   '/job:localhost/replica:0/task:0/device:CPU:0 then '
                                   'broadcast to '
                                   "('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n"
                                   'INFO:tensorflow:batch_all_reduce: 2 all-reduces with '
                                   'algorithm = nccl, num_packs = 1, '
                                   'agg_small_grads_max_bytes = 0 and '
                                   'agg_small_grads_max_group = 10\r\n'
                                   'INFO:tensorflow:Reduce to '
                                   '/job:localhost/replica:0/task:0/device:CPU:0 then '
                                   'broadcast to '
                                   "('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n"
                                   'INFO:tensorflow:Reduce to '
                                   '/job:localhost/replica:0/task:0/device:CPU:0 then '
                                   'broadcast to '
                                   "('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n"
                                   '60000/60000 [==============================] - 9s '
                                   '152us/sample - loss: 0.6016\r\n'
                                   'Exception raised: \r\n'
                                   ' `handle` is not available outside the replica '
                                   'context or a `tf.distribute.Strategy.update()` '
                                   'call.\r\n'
                                   '```\r\n'
                                   '\r\n',
                           'created_at': '2020-01-1'},
                          {'body': 'My code works in `GPU` based tensorflow environment '
                                   'without any fuss but fails in `CPU` based '
                                   'environments. Some other people also are facing the '
                                   'same issue. `Training` works without any issues but '
                                   "it's the `predict` method that's failing.\r\n"
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): Yes\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'Source\r\n'
                                   '- Other system related information below:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'Collecting system information...\r\n'
                                   '/tmp/check_os.py:18: DeprecationWarning: dist() and '
                                   'linux_distribution() functions are deprecated in '
                                   'Python 3.5\r\n'
                                   '  platform.linux_distribution(),\r\n'
                                   '/tmp/check_os.py:19: DeprecationWarning: dist() and '
                                   'linux_distribution() functions are deprecated in '
                                   'Python 3.5\r\n'
                                   '  platform.dist(),\r\n'
                                   'cat: /proc/1/cgroup: No such file or directory\r\n'
                                   '2020-01-16 15:58:53.661018: I '
                                   'tensorflow/core/platform/cpu_feature_guard.cc:145] '
                                   'This TensorFlow binary is optimized with Intel(R) '
                                   'MKL-DNN to use the following CPU instructions in '
                                   'performance critical operations:  SSE4.1 SSE4.2 AVX '
                                   'AVX2 FMA\r\n'
                                   'To enable them in non-MKL-DNN operations, rebuild '
                                   'TensorFlow with the appropriate compiler flags.\r\n'
                                   '2020-01-16 15:58:53.661360: I '
                                   'tensorflow/core/common_runtime/process_util.cc:115] '
                                   'Creating new thread pool with default inter op '
                                   'setting: 12. Tune using inter_op_parallelism_threads '
                                   'for best performance.\r\n'
                                   "')\r\n"
                                   "architecture: ('64bit', '')\r\n"
                                   'machine: x86_64\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '== are we in docker '
                                   '=============================================\r\n'
                                   'No\r\n'
                                   '\r\n'
                                   '== compiler '
                                   '=====================================================\r\n'
                                   'Apple LLVM version 10.0.1 (clang-1001.0.46.4)\r\n'
                                   'Target: x86_64-apple-darwin18.7.0\r\n'
                                   'Thread model: posix\r\n'
                                   'InstalledDir: '
                                   '/Library/Developer/CommandLineTools/usr/bin\r\n'
                                   '\r\n'
                                   '== check pips '
                                   '===================================================\r\n'
                                   'numpy                         1.17.4             \r\n'
                                   'protobuf                      3.11.2             \r\n'
                                   'tensorflow                    2.1.0              \r\n'
                                   'tensorflow-estimator          2.1.0              \r\n'
                                   'tensorflow-hub                0.7.0              \r\n'
                                   '\r\n'
                                   '== check for virtualenv '
                                   '=========================================\r\n'
                                   'False\r\n'
                                   '\r\n'
                                   '== tensorflow import '
                                   '============================================\r\n'
                                   'tf.version.VERSION = 2.0.0\r\n'
                                   'tf.version.GIT_VERSION = unknown\r\n'
                                   'tf.version.COMPILER_VERSION = 4.2.1 Compatible Clang '
                                   '4.0.1 (tags/RELEASE_401/final)\r\n'
                                   'Sanity check: array([1], dtype=int32)\r\n'
                                   '\r\n'
                                   '== env '
                                   '==========================================================\r\n'
                                   'LD_LIBRARY_PATH is unset\r\n'
                                   'DYLD_LIBRARY_PATH is unset\r\n'
                                   '\r\n'
                                   '== nvidia-smi '
                                   '===================================================\r\n'
                                   'tf_env_cololect.sh: line 147: nvidia-smi: command not '
                                   'found\r\n'
                                   '\r\n'
                                   '== cuda libs  '
                                   '===================================================\r\n'
                                   '\r\n'
                                   '== tensorflow installed from info '
                                   '==================\r\n'
                                   'Name: tensorflow\r\n'
                                   'Version: 2.1.0\r\n'
                                   'Summary: TensorFlow is an open source machine '
                                   'learning framework for everyone.\r\n'
                                   'Home-page: https://www.tensorflow.org/\r\n'
                                   'Author-email: packages@tensorflow.org\r\n'
                                   'License: Apache 2.0\r\n'
                                   'Location: '
                                   '/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages\r\n'
                                   'Required-by: \r\n'
                                   '\r\n'
                                   '== python version  '
                                   '==============================================\r\n'
                                   '(major, minor, micro, releaselevel, serial)\r\n'
                                   "(3, 7, 6, 'final', 0)\r\n"
                                   '\r\n'
                                   '== bazel version  '
                                   '===============================================\r\n'
                                   'Build label: 1.2.1\r\n'
                                   'Build time: Tue Nov 26 15:27:31 2019 (1574782051)\r\n'
                                   'Build timestamp: 1574782051\r\n'
                                   'Build timestamp as int: 1574782051\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'The code is running successfully in `GPU` based '
                                   'environment and failing in `CPU` based '
                                   'environments.\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   'It should run/fail in the same way in both `GPU` and '
                                   '`CPU` based environments.\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   'Code in the following link has the same behavior:\r\n'
                                   'https://www.kaggle.com/xhlulu/disaster-nlp-keras-bert-using-tfhub\r\n'
                                   '\r\n'
                                   'And also people are talking about this issue in the '
                                   'comments.\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Other info / logs**\r\n'
                                   '```\r\n'
                                   'Making predictions\r\n'
                                   'Traceback (most recent call last):\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/Egnyte/Private/sardar.mrinal/workspace/competitions/kaggle_nlp_disaster/working/NLP_disaster_bert.py", '
                                   'line 218, in <module>\r\n'
                                   '    df_sub = model_bert.predict(df_eval)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/Egnyte/Private/sardar.mrinal/workspace/competitions/kaggle_nlp_disaster/working/NLP_disaster_bert.py", '
                                   'line 186, in predict\r\n'
                                   '    prediction = self.model.predict(x=X)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py", '
                                   'line 909, in predict\r\n'
                                   '    use_multiprocessing=use_multiprocessing)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py", '
                                   'line 462, in predict\r\n'
                                   '    steps=steps, callbacks=callbacks, **kwargs)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py", '
                                   'line 444, in _model_iteration\r\n'
                                   '    total_epochs=1)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py", '
                                   'line 123, in run_one_epoch\r\n'
                                   '    batch_outs = execution_function(iterator)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py", '
                                   'line 86, in execution_function\r\n'
                                   '    distributed_function(input_fn))\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", '
                                   'line 457, in __call__\r\n'
                                   '    result = self._call(*args, **kwds)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", '
                                   'line 503, in _call\r\n'
                                   '    self._initialize(args, kwds, '
                                   'add_initializers_to=initializer_map)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", '
                                   'line 408, in _initialize\r\n'
                                   '    *args, **kwds))\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", '
                                   'line 1848, in '
                                   '_get_concrete_function_internal_garbage_collected\r\n'
                                   '    graph_function, _, _ = '
                                   'self._maybe_define_function(args, kwargs)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", '
                                   'line 2150, in _maybe_define_function\r\n'
                                   '    graph_function = '
                                   'self._create_graph_function(args, kwargs)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", '
                                   'line 2041, in _create_graph_function\r\n'
                                   '    capture_by_value=self._capture_by_value),\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py", '
                                   'line 915, in func_graph_from_py_func\r\n'
                                   '    func_outputs = python_func(*func_args, '
                                   '**func_kwargs)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", '
                                   'line 358, in wrapped_fn\r\n'
                                   '    return weak_wrapped_fn().__wrapped__(*args, '
                                   '**kwds)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py", '
                                   'line 73, in distributed_function\r\n'
                                   '    per_replica_function, args=(model, x, y, '
                                   'sample_weights))\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py", '
                                   'line 760, in experimental_run_v2\r\n'
                                   '    return self._extended.call_for_each_replica(fn, '
                                   'args=args, kwargs=kwargs)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py", '
                                   'line 1787, in call_for_each_replica\r\n'
                                   '    return self._call_for_each_replica(fn, args, '
                                   'kwargs)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py", '
                                   'line 2132, in _call_for_each_replica\r\n'
                                   '    return fn(*args, **kwargs)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py", '
                                   'line 292, in wrapper\r\n'
                                   '    return func(*args, **kwargs)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py", '
                                   'line 162, in _predict_on_batch\r\n'
                                   '    return predict_on_batch(model, x)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py", '
                                   'line 370, in predict_on_batch\r\n'
                                   '    return model(inputs)  # pylint: '
                                   'disable=not-callable\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py", '
                                   'line 847, in __call__\r\n'
                                   '    outputs = call_fn(cast_inputs, *args, '
                                   '**kwargs)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py", '
                                   'line 708, in call\r\n'
                                   '    '
                                   'convert_kwargs_to_constants=base_layer_utils.call_context().saving)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py", '
                                   'line 860, in _run_internal_graph\r\n'
                                   '    output_tensors = layer(computed_tensors, '
                                   '**kwargs)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py", '
                                   'line 847, in __call__\r\n'
                                   '    outputs = call_fn(cast_inputs, *args, '
                                   '**kwargs)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py", '
                                   'line 292, in wrapper\r\n'
                                   '    return func(*args, **kwargs)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py", '
                                   'line 218, in call\r\n'
                                   '    lambda: f(training=False))\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/smart_cond.py", '
                                   'line 56, in smart_cond\r\n'
                                   '    return false_fn()\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py", '
                                   'line 218, in <lambda>\r\n'
                                   '    lambda: f(training=False))\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py", '
                                   'line 436, in _call_attribute\r\n'
                                   '    return instance.__call__(*args, **kwargs)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", '
                                   'line 457, in __call__\r\n'
                                   '    result = self._call(*args, **kwds)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", '
                                   'line 494, in _call\r\n'
                                   '    results = self._stateful_fn(*args, **kwds)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", '
                                   'line 1822, in __call__\r\n'
                                   '    graph_function, args, kwargs = '
                                   'self._maybe_define_function(args, kwargs)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", '
                                   'line 2150, in _maybe_define_function\r\n'
                                   '    graph_function = '
                                   'self._create_graph_function(args, kwargs)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", '
                                   'line 2041, in _create_graph_function\r\n'
                                   '    capture_by_value=self._capture_by_value),\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py", '
                                   'line 915, in func_graph_from_py_func\r\n'
                                   '    func_outputs = python_func(*func_args, '
                                   '**func_kwargs)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", '
                                   'line 358, in wrapped_fn\r\n'
                                   '    return weak_wrapped_fn().__wrapped__(*args, '
                                   '**kwds)\r\n'
                                   '  File '
                                   '"/Users/sardarmrinal/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/function_deserialization.py", '
                                   'line 262, in restored_function_body\r\n'
                                   '    "\\n\\n".join(signature_descriptions)))\r\n'
                                   'ValueError: Could not find matching function to call '
                                   'loaded from the SavedModel. Got:\r\n'
                                   '  Positional arguments (3 total):\r\n'
                                   "    * [<tf.Tensor 'inputs:0' shape=(None, 3) "
                                   "dtype=int64>, <tf.Tensor 'inputs_1:0' shape=(None, 3) "
                                   "dtype=int64>, <tf.Tensor 'inputs_2:0' shape=(None, 3) "
                                   'dtype=int64>]\r\n'
                                   '    * False\r\n'
                                   '    * None\r\n'
                                   '  Keyword arguments: {}\r\n'
                                   '\r\n'
                                   'Expected these arguments to match one of the '
                                   'following 4 option(s):\r\n'
                                   '\r\n'
                                   'Option 1:\r\n'
                                   '  Positional arguments (3 total):\r\n'
                                   '    * [TensorSpec(shape=(None, None), dtype=tf.int32, '
                                   "name='input_word_ids'), TensorSpec(shape=(None, "
                                   "None), dtype=tf.int32, name='input_mask'), "
                                   'TensorSpec(shape=(None, None), dtype=tf.int32, '
                                   "name='input_type_ids')]\r\n"
                                   '    * True\r\n'
                                   '    * None\r\n'
                                   '  Keyword arguments: {}\r\n'
                                   '\r\n'
                                   'Option 2:\r\n'
                                   '  Positional arguments (3 total):\r\n'
                                   '    * [TensorSpec(shape=(None, None), dtype=tf.int32, '
                                   "name='input_word_ids'), TensorSpec(shape=(None, "
                                   "None), dtype=tf.int32, name='input_mask'), "
                                   'TensorSpec(shape=(None, None), dtype=tf.int32, '
                                   "name='input_type_ids')]\r\n"
                                   '    * False\r\n'
                                   '    * None\r\n'
                                   '  Keyword arguments: {}\r\n'
                                   '\r\n'
                                   'Option 3:\r\n'
                                   '  Positional arguments (3 total):\r\n'
                                   '    * [TensorSpec(shape=(None, None), dtype=tf.int32, '
                                   "name='inputs/0'), TensorSpec(shape=(None, None), "
                                   "dtype=tf.int32, name='inputs/1'), "
                                   'TensorSpec(shape=(None, None), dtype=tf.int32, '
                                   "name='inputs/2')]\r\n"
                                   '    * True\r\n'
                                   '    * None\r\n'
                                   '  Keyword arguments: {}\r\n'
                                   '\r\n'
                                   'Option 4:\r\n'
                                   '  Positional arguments (3 total):\r\n'
                                   '    * [TensorSpec(shape=(None, None), dtype=tf.int32, '
                                   "name='inputs/0'), TensorSpec(shape=(None, None), "
                                   "dtype=tf.int32, name='inputs/1'), "
                                   'TensorSpec(shape=(None, None), dtype=tf.int32, '
                                   "name='inputs/2')]\r\n"
                                   '    * False\r\n'
                                   '    * None\r\n'
                                   '  Keyword arguments: {}\r\n'
                                   '```\r\n',
                           'created_at': '2020-01-1'},
                          {'body': 'This PR implements GPU kernels ApplyAdagrad, '
                                   'ApplyAdagradV2, ApplyAdadelta, ApplyRMSProp, and '
                                   'ApplyCenteredRMSProp for ROCm, and enables '
                                   'corresponding unit tests.',
                           'created_at': '2020-01-1'},
                          {'body': 'Minor fixes for StructuredTensor pydocs that had '
                                   'incorrect example code and Python 2 style print '
                                   'statements.',
                           'created_at': '2020-01-1'},
                          {'body': '<em>Please make sure that this is a bug. As per our '
                                   '[GitHub '
                                   'Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), '
                                   'we only address code/doc bugs, performance issues, '
                                   'feature requests and build/installation issues on '
                                   'GitHub. tag:bug_template</em>\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow):\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04):Windows\r\n'
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device:\r\n'
                                   '- TensorFlow installed from (source or '
                                   'binary):binary\r\n'
                                   '- TensorFlow version (use command '
                                   'below):tf-nightly\r\n'
                                   '- Python version:3.7.5\r\n'
                                   '- Bazel version (if compiling from source):\r\n'
                                   '- GCC/Compiler version (if compiling from source):\r\n'
                                   '- CUDA/cuDNN version:\r\n'
                                   '- GPU model and memory:\r\n'
                                   '\r\n'
                                   'You can collect some of this information using our '
                                   'environment capture\r\n'
                                   '[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\n'
                                   'You can also obtain the TensorFlow version with: 1. '
                                   'TF 1.0: `python -c "import\r\n'
                                   'tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"` '
                                   '2. TF 2.0: `python -c\r\n'
                                   '"import tensorflow as tf; '
                                   'print(tf.version.GIT_VERSION, '
                                   'tf.version.VERSION)"`\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'File '
                                   '"\\\\?\\C:\\Users\\RUNNER~1\\AppData\\Local\\Temp\\Bazel.runfiles_e847arzc\\runfiles\\__main__\\tensorflow_addons\\activations\\rrelu_test.py", '
                                   'line 88, in benchmarkRreluOp\r\n'
                                   '    self.run_op_benchmark(sess, result.op, '
                                   'min_iters=25)\r\n'
                                   '  File '
                                   '"C:\\hostedtoolcache\\windows\\Python\\3.7.5\\x64\\lib\\site-packages\\tensorflow_core\\python\\platform\\benchmark.py", '
                                   'line 389, in run_op_benchmark\r\n'
                                   '    "throughput": mbs / median_delta\r\n'
                                   'ZeroDivisionError: float division by zero\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   'Same behavior as ubuntu\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   'Provide a reproducible test case that is the bare '
                                   'minimum necessary to generate the problem.\r\n'
                                   '```python \r\n'
                                   'self.run_op_benchmark(sess, result.op, '
                                   'min_iters=25)\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '**Other info / logs**\r\n'
                                   '\r\n'
                                   'https://github.com/tensorflow/addons/issues/839\r\n'
                                   'It seems '
                                   '[```time.time()```](https://github.com/tensorflow/tensorflow/blob/590d6eef7e91a6a7392c8ffffb7b58f2e0c8bc6b/tensorflow/python/platform/benchmark.py#L294) '
                                   'cause the problem and ```timeit.default_timer()``` '
                                   'could fix the problem',
                           'created_at': '2020-01-1'},
                          {'body': '<em>Please make sure that this is a bug. As per our '
                                   '[GitHub '
                                   'Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), '
                                   'we only address code/doc bugs, performance issues, '
                                   'feature requests and build/installation issues on '
                                   'GitHub. tag:bug_template</em>\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): '
                                   'Stateless LSTM from Keras tutorial using tf '
                                   'backend\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Windows 10\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'binary\r\n'
                                   '- TensorFlow version (use command below): 2.1.0\r\n'
                                   '- Python version: 3.7.4\r\n'
                                   '- CUDA/cuDNN version: 10.1\r\n'
                                   '- GPU model and memory: MX150 10GB\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'When using tf.keras.callbacks.TensorBoard() without '
                                   'the profile_batch setting, it gives out errors of '
                                   'CUPTI_ERROR_INSUFFICIENT_PRIVILEGES and '
                                   'CUPTI_ERROR_INVALID_PARAMETER from '
                                   'tensorflow/core/profiler/internal/gpu/cupti_tracer.cc.\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   'With profile_batch = 0, these two errors are '
                                   'gone. \r\n'
                                   'But comes back when profile_batch = 1, or other '
                                   'non-zero values.\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'from __future__ import print_function\r\n'
                                   'import numpy as np\r\n'
                                   'import matplotlib.pyplot as plt\r\n'
                                   'import pandas as pd\r\n'
                                   'import tensorflow as tf\r\n'
                                   'from tensorflow.keras.models import Sequential\r\n'
                                   'from tensorflow.keras.layers import Dense, LSTM\r\n'
                                   '\r\n'
                                   '\r\n'
                                   'input_len = 1000\r\n'
                                   'tsteps = 2\r\n'
                                   'lahead = 1\r\n'
                                   'batch_size = 1\r\n'
                                   'epochs = 5\r\n'
                                   '\r\n'
                                   'print("*" * 33)\r\n'
                                   'if lahead >= tsteps:\r\n'
                                   '    print("STATELESS LSTM WILL ALSO CONVERGE")\r\n'
                                   'else:\r\n'
                                   '    print("STATELESS LSTM WILL NOT CONVERGE")\r\n'
                                   'print("*" * 33)\r\n'
                                   '\r\n'
                                   'np.random.seed(1986)\r\n'
                                   '\r\n'
                                   "print('Generating Data...')\r\n"
                                   '\r\n'
                                   '\r\n'
                                   'def gen_uniform_amp(amp=1, xn=10000):\r\n'
                                   '\r\n'
                                   '    data_input = np.random.uniform(-1 * amp, +1 * '
                                   'amp, xn)\r\n'
                                   '    data_input = pd.DataFrame(data_input)\r\n'
                                   '    return data_input\r\n'
                                   '\r\n'
                                   '\r\n'
                                   'to_drop = max(tsteps - 1, lahead - 1)\r\n'
                                   'data_input = gen_uniform_amp(amp=0.1, xn=input_len + '
                                   'to_drop)\r\n'
                                   '\r\n'
                                   'expected_output = data_input.rolling(window=tsteps, '
                                   'center=False).mean()\r\n'
                                   '\r\n'
                                   'if lahead > 1:\r\n'
                                   '    data_input = np.repeat(data_input.values, '
                                   'repeats=lahead, axis=1)\r\n'
                                   '    data_input = pd.DataFrame(data_input)\r\n'
                                   '    for i, c in enumerate(data_input.columns):\r\n'
                                   '        data_input[c] = data_input[c].shift(i)\r\n'
                                   '\r\n'
                                   'expected_output = expected_output[to_drop:]\r\n'
                                   'data_input = data_input[to_drop:]\r\n'
                                   '\r\n'
                                   '\r\n'
                                   'def create_model(stateful):\r\n'
                                   '    model = Sequential()\r\n'
                                   '    model.add(LSTM(20,\r\n'
                                   '              input_shape=(lahead, 1),\r\n'
                                   '              batch_size=batch_size,\r\n'
                                   '              stateful=stateful))\r\n'
                                   '    model.add(Dense(1))\r\n'
                                   "    model.compile(loss='mse', optimizer='adam')\r\n"
                                   '    return model\r\n'
                                   '\r\n'
                                   "print('Creating Stateful Model...')\r\n"
                                   'model_stateful = create_model(stateful=True)\r\n'
                                   '\r\n'
                                   '\r\n'
                                   'def split_data(x, y, ratio=0.8):\r\n'
                                   '    to_train = int(input_len * ratio)\r\n'
                                   '    to_train -= to_train % batch_size\r\n'
                                   '    x_train = x[:to_train]\r\n'
                                   '    y_train = y[:to_train]\r\n'
                                   '    x_test = x[to_train:]\r\n'
                                   '    y_test = y[to_train:]\r\n'
                                   '\r\n'
                                   '    # tweak to match with batch_size\r\n'
                                   '    to_drop = x.shape[0] % batch_size\r\n'
                                   '    if to_drop > 0:\r\n'
                                   '        x_test = x_test[:-1 * to_drop]\r\n'
                                   '        y_test = y_test[:-1 * to_drop]\r\n'
                                   '\r\n'
                                   '    # some reshaping\r\n'
                                   '    reshape_3 = lambda x: '
                                   'x.values.reshape((x.shape[0], x.shape[1], 1))\r\n'
                                   '    x_train = reshape_3(x_train)\r\n'
                                   '    x_test = reshape_3(x_test)\r\n'
                                   '\r\n'
                                   '    reshape_2 = lambda x: '
                                   'x.values.reshape((x.shape[0], 1))\r\n'
                                   '    y_train = reshape_2(y_train)\r\n'
                                   '    y_test = reshape_2(y_test)\r\n'
                                   '\r\n'
                                   '    return (x_train, y_train), (x_test, y_test)\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '(x_train, y_train), (x_test, y_test) = '
                                   'split_data(data_input, expected_output)\r\n'
                                   "print('x_train.shape: ', x_train.shape)\r\n"
                                   "print('y_train.shape: ', y_train.shape)\r\n"
                                   "print('x_test.shape: ', x_test.shape)\r\n"
                                   "print('y_test.shape: ', y_test.shape)\r\n"
                                   '\r\n'
                                   "print('Creating Stateless Model...')\r\n"
                                   'model_stateless = create_model(stateful=False)\r\n'
                                   '\r\n'
                                   'import os\r\n'
                                   'import datetime\r\n'
                                   'ROOT_DIR = os.getcwd()\r\n'
                                   "log_dir = os.path.join('callback_tests')\r\n"
                                   'if not os.path.exists(log_dir):\r\n'
                                   '    os.makedirs(log_dir)\r\n'
                                   'print(log_dir)\r\n'
                                   'tensorboard_callback = '
                                   'tf.keras.callbacks.TensorBoard(log_dir=log_dir)\r\n'
                                   '                                       \r\n'
                                   "print('Training')\r\n"
                                   'history = model_stateless.fit(x_train,\r\n'
                                   '                    y_train,\r\n'
                                   '                    batch_size=batch_size,\r\n'
                                   '                    epochs=epochs,\r\n'
                                   '                    verbose=1,\r\n'
                                   '                    validation_data=(x_test, '
                                   'y_test),\r\n'
                                   '                    shuffle=False,\r\n'
                                   '                    '
                                   'callbacks=[tensorboard_callback]\r\n'
                                   '                    )\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '**Other info / logs**\r\n'
                                   'Train on 800 samples, validate on 200 samples\r\n'
                                   '2020-01-14 21:30:27.591905: I '
                                   'tensorflow/core/profiler/lib/profiler_session.cc:225] '
                                   'Profiler session started.\r\n'
                                   '2020-01-14 21:30:27.594743: I '
                                   'tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1259] '
                                   'Profiler found 1 GPUs\r\n'
                                   '2020-01-14 21:30:27.599172: I '
                                   'tensorflow/stream_executor/platform/default/dso_loader.cc:44] '
                                   'Successfully opened dynamic library '
                                   'cupti64_101.dll\r\n'
                                   '2020-01-14 21:30:27.704083: E '
                                   'tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] '
                                   'function cupti_interface_->Subscribe( &subscriber_, '
                                   '(CUpti_CallbackFunc)ApiCallback, this)failed with '
                                   'error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\r\n'
                                   '2020-01-14 21:30:27.716790: E '
                                   'tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] '
                                   'function cupti_interface_->ActivityRegisterCallbacks( '
                                   'AllocCuptiActivityBuffer, '
                                   'FreeCuptiActivityBuffer)failed with error '
                                   'CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\r\n'
                                   'Epoch 1/5\r\n'
                                   '2020-01-14 21:30:28.370429: I '
                                   'tensorflow/stream_executor/platform/default/dso_loader.cc:44] '
                                   'Successfully opened dynamic library '
                                   'cublas64_10.dll\r\n'
                                   '2020-01-14 21:30:28.651767: I '
                                   'tensorflow/stream_executor/platform/default/dso_loader.cc:44] '
                                   'Successfully opened dynamic library cudnn64_7.dll\r\n'
                                   '2020-01-14 21:30:29.662864: E '
                                   'tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] '
                                   'function cupti_interface_->EnableCallback( 0 , '
                                   'subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed '
                                   'with error CUPTI_ERROR_INVALID_PARAMETER\r\n'
                                   '2020-01-14 21:30:29.670282: I '
                                   'tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  '
                                   'GpuTracer has collected 0 callback api events and 0 '
                                   'activity events.\r\n'
                                   '800/800 [==============================] - 5s '
                                   '6ms/sample - loss: 0.0011 - val_loss: 0.0011\r\n'
                                   'Epoch 2/5\r\n'
                                   '800/800 [==============================] - 3s '
                                   '4ms/sample - loss: 8.5921e-04 - val_loss: 0.0010\r\n'
                                   'Epoch 3/5\r\n'
                                   '800/800 [==============================] - 3s '
                                   '3ms/sample - loss: 8.5613e-04 - val_loss: 0.0010\r\n'
                                   'Epoch 4/5\r\n'
                                   '800/800 [==============================] - 3s '
                                   '4ms/sample - loss: 8.5458e-04 - val_loss: '
                                   '9.9713e-04\r\n'
                                   'Epoch 5/5\r\n'
                                   '800/800 [==============================] - 3s '
                                   '4ms/sample - loss: 8.5345e-04 - val_loss: '
                                   '9.8825e-04\r\n',
                           'created_at': '2020-01-1'},
                          {'body': '<em>Please make sure that this is a bug. As per our '
                                   '[GitHub '
                                   'Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), '
                                   'we only address code/doc bugs, performance issues, '
                                   'feature requests and build/installation issues on '
                                   'GitHub. tag:bug_template</em>\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): Yes\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): colab\r\n'
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device:\r\n'
                                   '- TensorFlow installed from (source or binary):\r\n'
                                   '- TensorFlow version (use command below): '
                                   '2.1.0-rc1\r\n'
                                   '- Python version: 3.6.9\r\n'
                                   '- Bazel version (if compiling from source):\r\n'
                                   '- GCC/Compiler version (if compiling from '
                                   'source): \r\n'
                                   '- CUDA/cuDNN version: V10.1.243\r\n'
                                   '- GPU model and memory:\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'I use tf.image.random_brightness api for '
                                   'augmentation. With dataset api I put those '
                                   'augmentation functions in parser method and use '
                                   'Dataset.map api for applying the method to the '
                                   'dataset and _Transformed dataset_ is not reproducible '
                                   'when I put non negative integer > 0 in '
                                   '_num_parallel_calls_ argument of Dataset.map api. It '
                                   'is also the same if I use '
                                   'tf.data.experimental.AUTOTUNE for num_parallel_calls '
                                   'argument.\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   '[here is the colab link to reproduce the '
                                   'issue](https://colab.research.google.com/drive/1uNpn1Rf1_WvG2lnAS41g36IDWOB2IW7-)\r\n'
                                   '\r\n'
                                   '**Other info / logs**\r\n'
                                   'It looks like tf.random.uniform method is the reason '
                                   'of happening this. The implementation of '
                                   'tf.image.random_brightness use tensorflow random '
                                   'uniform method and the method is not reproducible '
                                   'with multiprocessing. I have tested '
                                   'tf.image.random_contrast and '
                                   'tf.image.random_saturation. They are not reproducible '
                                   'also.\r\n',
                           'created_at': '2020-01-1'},
                          {'body': '**System information**\r\n'
                                   '- TensorFlow version (you are using): \r\n'
                                   'TF 2.0.0\r\n'
                                   '- Are you willing to contribute it (Yes/No):\r\n'
                                   'Yes\r\n'
                                   '\r\n'
                                   '**Describe the feature and the current '
                                   'behaviour/state.**\r\n'
                                   'Currently `tf.keras.models.Model.fit` method allows '
                                   "the user to pass either 'sample_weight' and "
                                   "'class_weight' parameters. These are used to compute "
                                   'at [some '
                                   'point](https://github.com/tensorflow/tensorflow/blob/1cf0898dd4331baf93fe77205550f2c2e6c90ee5/tensorflow/python/keras/engine/training.py#L2527 '
                                   ") a standardised 'sample_weights' and used later on "
                                   'while calculating the loss.\r\n'
                                   '\r\n'
                                   'This feature request is about extending the '
                                   "'tf.keras.Model.evaluate' API so that is permits "
                                   'using `class_weight` directly. The `evaluate` '
                                   'function already permits for `sample_weight`.\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Will this change the current api? How?**\r\n'
                                   'current API\r\n'
                                   '```\r\n'
                                   'evaluate(\r\n'
                                   '    x=None,\r\n'
                                   '    y=None,\r\n'
                                   '    batch_size=None,\r\n'
                                   '    verbose=1,\r\n'
                                   '    sample_weight=None,\r\n'
                                   '    steps=None,\r\n'
                                   '    callbacks=None,\r\n'
                                   '    max_queue_size=10,\r\n'
                                   '    workers=1,\r\n'
                                   '    use_multiprocessing=False\r\n'
                                   ')\r\n'
                                   '```\r\n'
                                   'new API\r\n'
                                   '```\r\n'
                                   'evaluate(\r\n'
                                   '    x=None,\r\n'
                                   '    y=None,\r\n'
                                   '    batch_size=None,\r\n'
                                   '    verbose=1,\r\n'
                                   '    sample_weight=None,\r\n'
                                   '>>>    class_weight=None,\r\n'
                                   '    steps=None,\r\n'
                                   '    callbacks=None,\r\n'
                                   '    max_queue_size=10,\r\n'
                                   '    workers=1,\r\n'
                                   '    use_multiprocessing=False\r\n'
                                   ')\r\n'
                                   '```\r\n'
                                   '**Who will benefit with this feature?**\r\n'
                                   '\r\n'
                                   'Those users of the API who would like to perform the '
                                   'evaluation of a model that was trained with bespoke '
                                   'class weights.\r\n'
                                   '\r\n'
                                   '**Any Other info.**\r\n',
                           'created_at': '2020-01-1'},
                          {
                              'body': 'https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_lite/tflite_c04_exercise_convert_model_to_tflite_solution.ipynb\r\n'
                                      '\r\n'
                                      'Under "Create a Dataset from Images and Labels", we '
                                      'have this code\r\n'
                                      '\r\n'
                                      '`train_batches=train_examples.cache().shuffle(num_examples//4).batch(BATCH_SIZE).map(format_example).prefetch(1)`\r\n'
                                      '\r\n'
                                      'and similar for the validation and test '
                                      'examples...\r\n'
                                      '\r\n'
                                      'Is this a right practise?? \r\n'
                                      "Shouldn't we first format the raw images and then "
                                      'batch them together rather than opposite way?',
                              'created_at': '2020-01-1'},
                          {'body': '<em>Please make sure that this is a '
                                   'build/installation issue. As per our [GitHub '
                                   'Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), '
                                   'we only address code/doc bugs, performance issues, '
                                   'feature requests and build/installation issues on '
                                   'GitHub. tag:build_template</em>\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Windows 10 home\r\n'
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device: PC\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   '1.13.0\r\n'
                                   '- TensorFlow version:\r\n'
                                   '- Python version: 3.6\r\n'
                                   '- Installed using virtualenv? pip? conda?: conda\r\n'
                                   '- Bazel version (if compiling from source): 0.21.0\r\n'
                                   '- GCC/Compiler version (if compiling from source):\r\n'
                                   '- CUDA/cuDNN version: 10.0 7.4.2.24\r\n'
                                   '- GPU model and memory: RTX 2080 Ti\r\n'
                                   '- CPU model and make: AMD Ryzen 7 3800X 8-Core '
                                   'Processor 3.89GHz\r\n'
                                   '- Anaconda Python Command Prompt\r\n'
                                   '\r\n'
                                   '**Describe the problem**\r\n'
                                   '\r\n'
                                   'Trying to build TF 1.13 from source. Issue at the '
                                   'creation of wheel file with bazel. Attached exact '
                                   'sequence of commands issued. Trying to conver a *.pb '
                                   'file into a TFLite file that was trained in '
                                   'tensorflow 1.13\r\n'
                                   '\r\n'
                                   '**Exact sequence of commands / steps executed before '
                                   'running into the problem**\r\n'
                                   '\r\n'
                                   'conda update -n base -c defaults conda\r\n'
                                   'conda update --all\r\n'
                                   'conda create -n tensorflow-build pip python=3.6\r\n'
                                   'conda activate tensorflow-build\r\n'
                                   'python -m pip install --upgrade pip\r\n'
                                   'conda install -c anaconda git\r\n'
                                   'set PATH=%PATH%;C:\\msys64\\usr\\bin\r\n'
                                   'pip install six numpy wheel\r\n'
                                   'pip install keras_applications==1.0.6 --no-deps\r\n'
                                   'pip install keras_preprocessing==1.0.5 --no-deps\r\n'
                                   'conda install -c conda-forge bazel=0.21.0\r\n'
                                   'mkdir C:\\tensorflow-build\r\n'
                                   'cd C:\\tensorflow-build\r\n'
                                   'git clone '
                                   'https://github.com/tensorflow/tensorflow.git \r\n'
                                   'cd tensorflow\r\n'
                                   'git checkout r1.13\r\n'
                                   'python ./configure.py\r\n'
                                   '\r\n'
                                   'You have bazel 0.21.0- (@non-git) installed. \r\n'
                                   '\r\n'
                                   'Please specify the location of python. [Default is '
                                   'C:\\ProgramData\\Anaconda3\\envs\\tensorflow-build\\python.exe]: \r\n'
                                   '  \r\n'
                                   'Found possible Python library paths: \r\n'
                                   '\r\n'
                                   '  '
                                   'C:\\ProgramData\\Anaconda3\\envs\\tensorflow-build\\lib\\site-packages \r\n'
                                   '\r\n'
                                   'Please input the desired Python library path to use.  '
                                   'Default is '
                                   '[C:\\ProgramData\\Anaconda3\\envs\\tensorflow-build\\lib\\site-packages] \r\n'
                                   '\r\n'
                                   'Do you wish to build TensorFlow with XLA JIT support? '
                                   '[y/N]: n \r\n'
                                   'No XLA JIT support will be enabled for '
                                   'TensorFlow. \r\n'
                                   '\r\n'
                                   'Do you wish to build TensorFlow with ROCm support? '
                                   '[y/N]: n \r\n'
                                   'No ROCm support will be enabled for TensorFlow. \r\n'
                                   '  \r\n'
                                   'Do you wish to build TensorFlow with CUDA support? '
                                   '[y/N]: y \r\n'
                                   '\r\n'
                                   'Please specify the CUDA SDK version you want to use. '
                                   '[Leave empty to default to CUDA 10.0]: 10.0\r\n'
                                   '\r\n'
                                   'Please specify the location where CUDA 10.0 toolkit '
                                   'is installed. Refer to README.md for more details. '
                                   '[Default is C:/Program Files/NVIDIA GPU Computing '
                                   'Toolkit/CUDA/v10.0]:\r\n'
                                   '\r\n'
                                   'Please specify the cuDNN version you want to use. '
                                   '[Leave empty to default to cuDNN 7]: 7.4\r\n'
                                   '\r\n'
                                   'Please specify the location where cuDNN 7 library is '
                                   'installed. Refer to README.md for more details. '
                                   '[Default is C:/Program Files/NVIDIA GPU Computing '
                                   'Toolkit/CUDA/v10.0]:\r\n'
                                   '\r\n'
                                   'Please specify a list of comma-separated Cuda compute '
                                   'capabilities you want to build with.\r\n'
                                   'You can find the compute capability of your device '
                                   'at: https://developer.nvidia.com/cuda-gpus.\r\n'
                                   'Please note that each additional compute capability '
                                   'significantly increases your build time and binary '
                                   'size. [Default is: 3.5,7.0]: 7.5\r\n'
                                   '\r\n'
                                   'Please specify optimization flags to use during '
                                   'compilation when bazel option "--config=opt" is '
                                   'specified [Default is /arch:AVX]:\r\n'
                                   '\r\n'
                                   'Would you like to override eigen strong inline for '
                                   'some C++ compilation to reduce the compilation time? '
                                   '[Y/n]: y\r\n'
                                   'Eigen strong inline overridden.\r\n'
                                   '\r\n'
                                   'bazel build --config=opt --config=cuda '
                                   '--define=no_tensorflow_py_deps=true '
                                   '//tensorflow/tools/pip_package:build_pip_package\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**info / logs**\r\n'
                                   '\r\n'
                                   '////////////////////////////////////////////////////////LOG/////////////////////////////////////////////////////\r\n'
                                   '\r\n'
                                   'ERROR: '
                                   'C:/tensorflow-build/tensorflow/tensorflow/BUILD:579:1: '
                                   'Executing genrule //tensorflow:tf_python_api_gen_v1 '
                                   'failed (Exit 1): bash.exe failed: error executing '
                                   'command\r\n'
                                   '  cd '
                                   'C:/users/eduar/_bazel_eduar/j7bi4x5j/execroot/org_tensorflow\r\n'
                                   '  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU '
                                   'Computing Toolkit/CUDA/v10.0\r\n'
                                   '    SET CUDNN_INSTALL_PATH=C:/Program Files/NVIDIA '
                                   'GPU Computing Toolkit/CUDA/v10.0\r\n'
                                   '    SET PATH=C:\\msys64\\usr\\bin;C:\\msys64\\bin\r\n'
                                   '    SET '
                                   'PYTHON_BIN_PATH=C:/Users/eduar/.conda/envs/tensorflow-build/python.exe\r\n'
                                   '    SET '
                                   'PYTHON_LIB_PATH=C:/Users/eduar/.conda/envs/tensorflow-build/lib/site-packages\r\n'
                                   '    SET TF_CUDA_CLANG=0\r\n'
                                   '    SET TF_CUDA_COMPUTE_CAPABILITIES=7.5\r\n'
                                   '    SET TF_CUDA_VERSION=10.0\r\n'
                                   '    SET TF_CUDNN_VERSION=7\r\n'
                                   '    SET TF_NEED_CUDA=1\r\n'
                                   '    SET TF_NEED_OPENCL_SYCL=0\r\n'
                                   '    SET TF_NEED_ROCM=0\r\n'
                                   '  C:/msys64/usr/bin/bash.exe '
                                   'bazel-out/x64_windows-opt/genfiles/tensorflow/tf_python_api_gen_v1.genrule_script.sh\r\n'
                                   'Execution platform: '
                                   '@bazel_tools//platforms:host_platform\r\n'
                                   'Traceback (most recent call last):\r\n'
                                   '  File '
                                   '"\\\\?\\C:\\Users\\eduar\\AppData\\Local\\Temp\\Bazel.runfiles_fxnhn1zo\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow.py", '
                                   'line 58, in <module>\r\n'
                                   '    from tensorflow.python.pywrap_tensorflow_internal '
                                   'import *\r\n'
                                   '  File '
                                   '"\\\\?\\C:\\Users\\eduar\\AppData\\Local\\Temp\\Bazel.runfiles_fxnhn1zo\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow_internal.py", '
                                   'line 28, in <module>\r\n'
                                   '    _pywrap_tensorflow_internal = '
                                   'swig_import_helper()\r\n'
                                   '  File '
                                   '"\\\\?\\C:\\Users\\eduar\\AppData\\Local\\Temp\\Bazel.runfiles_fxnhn1zo\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow_internal.py", '
                                   'line 24, in swig_import_helper\r\n'
                                   '    _mod = '
                                   "imp.load_module('_pywrap_tensorflow_internal', fp, "
                                   'pathname, description)\r\n'
                                   '  File '
                                   '"C:\\Users\\eduar\\.conda\\envs\\tensorflow-build\\lib\\imp.py", '
                                   'line 243, in load_module\r\n'
                                   '    return load_dynamic(name, filename, file)\r\n'
                                   '  File '
                                   '"C:\\Users\\eduar\\.conda\\envs\\tensorflow-build\\lib\\imp.py", '
                                   'line 343, in load_dynamic\r\n'
                                   '    return _load(spec)\r\n'
                                   'ImportError: DLL load failed: The specified module '
                                   'could not be found.\r\n'
                                   '\r\n'
                                   'During handling of the above exception, another '
                                   'exception occurred:\r\n'
                                   '\r\n'
                                   'Traceback (most recent call last):\r\n'
                                   '  File '
                                   '"\\\\?\\C:\\Users\\eduar\\AppData\\Local\\Temp\\Bazel.runfiles_fxnhn1zo\\runfiles\\org_tensorflow\\tensorflow\\python\\tools\\api\\generator\\create_python_api.py", '
                                   'line 27, in <module>\r\n'
                                   '    from tensorflow.python.tools.api.generator import '
                                   'doc_srcs\r\n'
                                   '  File '
                                   '"\\\\?\\C:\\Users\\eduar\\AppData\\Local\\Temp\\Bazel.runfiles_fxnhn1zo\\runfiles\\org_tensorflow\\tensorflow\\python\\__init__.py", '
                                   'line 49, in <module>\r\n'
                                   '    from tensorflow.python import '
                                   'pywrap_tensorflow\r\n'
                                   '  File '
                                   '"\\\\?\\C:\\Users\\eduar\\AppData\\Local\\Temp\\Bazel.runfiles_fxnhn1zo\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow.py", '
                                   'line 74, in <module>\r\n'
                                   '    raise ImportError(msg)\r\n'
                                   'ImportError: Traceback (most recent call last):\r\n'
                                   '  File '
                                   '"\\\\?\\C:\\Users\\eduar\\AppData\\Local\\Temp\\Bazel.runfiles_fxnhn1zo\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow.py", '
                                   'line 58, in <module>\r\n'
                                   '    from tensorflow.python.pywrap_tensorflow_internal '
                                   'import *\r\n'
                                   '  File '
                                   '"\\\\?\\C:\\Users\\eduar\\AppData\\Local\\Temp\\Bazel.runfiles_fxnhn1zo\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow_internal.py", '
                                   'line 28, in <module>\r\n'
                                   '    _pywrap_tensorflow_internal = '
                                   'swig_import_helper()\r\n'
                                   '  File '
                                   '"\\\\?\\C:\\Users\\eduar\\AppData\\Local\\Temp\\Bazel.runfiles_fxnhn1zo\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow_internal.py", '
                                   'line 24, in swig_import_helper\r\n'
                                   '    _mod = '
                                   "imp.load_module('_pywrap_tensorflow_internal', fp, "
                                   'pathname, description)\r\n'
                                   '  File '
                                   '"C:\\Users\\eduar\\.conda\\envs\\tensorflow-build\\lib\\imp.py", '
                                   'line 243, in load_module\r\n'
                                   '    return load_dynamic(name, filename, file)\r\n'
                                   '  File '
                                   '"C:\\Users\\eduar\\.conda\\envs\\tensorflow-build\\lib\\imp.py", '
                                   'line 343, in load_dynamic\r\n'
                                   '    return _load(spec)\r\n'
                                   'ImportError: DLL load failed: The specified module '
                                   'could not be found.\r\n'
                                   '\r\n'
                                   '\r\n'
                                   'Failed to load the native TensorFlow runtime.\r\n'
                                   '\r\n'
                                   'See https://www.tensorflow.org/install/errors\r\n'
                                   '\r\n'
                                   'for some common reasons and solutions.  Include the '
                                   'entire stack trace\r\n'
                                   'above this error message when asking for help.\r\n'
                                   'Target '
                                   '//tensorflow/tools/pip_package:build_pip_package '
                                   'failed to build\r\n'
                                   'INFO: Elapsed time: 1319.085s, Critical Path: '
                                   '291.62s\r\n'
                                   'INFO: 4651 processes: 4651 local.\r\n'
                                   'FAILED: Build did NOT complete successfully\r\n'
                                   '\r\n'
                                   '///////////////////////////////////////////////////////////////////////////////////////////////////////////////////\r\n'
                                   'Include any logs or source code that would be helpful '
                                   'to diagnose the problem. If including tracebacks, '
                                   'please include the full traceback. Large logs and '
                                   'files should be attached.\r\n',
                           'created_at': '2020-01-1'},
                          {'body': '<em>Please make sure that this is a '
                                   'build/installation issue. As per our [GitHub '
                                   'Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), '
                                   'we only address code/doc bugs, performance issues, '
                                   'feature requests and build/installation issues on '
                                   'GitHub. tag:build_template</em>\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- OS Platform and Distribution : Windows 10\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'Source\r\n'
                                   '- TensorFlow version: 2.1\r\n'
                                   '- Python version: 3.7\r\n'
                                   '- Bazel version (if compiling from source): 0.29.1\r\n'
                                   '- GCC/Compiler version (if compiling from source): '
                                   'VS2019\r\n'
                                   '- CUDA/cuDNN version: 10.1 / 7.6\r\n'
                                   '- GPU model and memory: 2070 Max Q\r\n'
                                   '\r\n'
                                   'I setup it using configure with the following options '
                                   'selected : \r\n'
                                   '- XLA JIT\r\n'
                                   '- Cuda\r\n'
                                   '- /arch:AVX\r\n'
                                   '- Eigen strong inline overridden\r\n'
                                   '\r\n'
                                   'When attempting to build from source using the '
                                   'following command. \r\n'
                                   '\r\n'
                                   'bazel build --config=opt --config=cuda '
                                   '--define=no_tensorflow_py_deps=true '
                                   '//tensorflow:libtensorflow.so\r\n'
                                   '\r\n'
                                   'I get the following error.\r\n'
                                   '\r\n'
                                   'ERROR: '
                                   'C:/sdks/tensorflow/tensorflow/compiler/xla/service/gpu/BUILD:1616:1: '
                                   'C++ compilation of rule '
                                   "'//tensorflow/compiler/xla/service/gpu:hlo_algorithm_blacklist' "
                                   'failed (Exit 2)\r\n'
                                   'cl : Command line warning D9002 : ignoring unknown '
                                   "option '-std=c++14'\r\n"
                                   'tensorflow/compiler/xla/service/gpu/hlo_algorithm_blacklist.cc(28): '
                                   'error C2131: expression did not evaluate to a '
                                   'constant\r\n'
                                   'external/com_google_absl\\absl/strings/string_view.h(186): '
                                   'note: a non-constant (sub-)expression was '
                                   'encountered\r\n',
                           'created_at': '2020-01-1'},
                          {'body': '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): see '
                                   'below\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Windows, Linux\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'pip\r\n'
                                   '- TensorFlow version (use command below): 2.1.0\r\n'
                                   '- Python version: 3.7.6\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'In this example, no error is raised although session '
                                   'kwargs are not supported in eager mode. kwargs are '
                                   'simply silently ignored.\r\n'
                                   '```\r\n'
                                   'import tensorflow as tf\r\n'
                                   'from tensorflow import keras\r\n'
                                   '\r\n'
                                   'fetches = [lambda: '
                                   'whatever_I_write_here_is_ignored]\r\n'
                                   '\r\n'
                                   'var = tf.Variable([[3.0]])\r\n'
                                   'model = '
                                   'keras.models.Sequential([keras.layers.Dense(1, '
                                   'input_shape=(1,))])\r\n'
                                   'model.compile(loss="mse", optimizer="adam")\r\n'
                                   'model._function_kwargs = {"fetches": fetches, '
                                   '"should_fail": "ignored_as_well"}\r\n'
                                   '\r\n'
                                   'model.fit([[7.0]], [[9.0]], epochs=2)\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   'An error should be raised. I am aware that '
                                   '`model._function_kwargs` is not part of the public '
                                   'API, but `keras` (as opposed to `tf.keras`) does '
                                   'raise an error here:\r\n'
                                   '```\r\n'
                                   'import keras\r\n'
                                   'import tensorflow as tf\r\n'
                                   '\r\n'
                                   'fetches = [lambda: '
                                   'whatever_I_write_here_is_ignored]\r\n'
                                   '\r\n'
                                   'var = tf.Variable([[3.0]])\r\n'
                                   'model = '
                                   'keras.models.Sequential([keras.layers.Dense(1, '
                                   'input_shape=(1,))])\r\n'
                                   'model.compile(loss="mse", optimizer="adam")\r\n'
                                   'model._function_kwargs = {"fetches": fetches, '
                                   '"should_fail": "ignored_as_well"}\r\n'
                                   '\r\n'
                                   'model.fit([[7.0]], [[9.0]], epochs=2)\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'outputs\r\n'
                                   '```\r\n'
                                   'Exception has occurred: ValueError\r\n'
                                   'Session keyword arguments are not support during '
                                   "eager execution. You passed: {'fetches': [<function "
                                   "<lambda> at 0x7f94681be3b0>], 'should_fail': "
                                   "'ignored_as_well'}\r\n"
                                   '  File '
                                   '"/home/bersbersbers/.pyenv/versions/3.7.6/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py", '
                                   'line 3759, in function\r\n'
                                   '```\r\n'
                                   'Somewhat related: '
                                   'https://github.com/tensorflow/tensorflow/issues/34448',
                           'created_at': '2020-01-1'},
                          {'body': 'Tf Version: 2.0.0\r\n'
                                   'Python: 3.7.5\r\n'
                                   'IDE: Spyder\r\n'
                                   'OS: Windows\r\n'
                                   '\r\n'
                                   'I wrote a subclass of custom loss function and tried '
                                   'to list it in the arguments of a checkpoint as '
                                   'follows. The model is an arbitrary one\r\n'
                                   '```\r\n'
                                   'class SoftDiceLoss(tf.keras.losses.Loss):\r\n'
                                   "    '''\r\n"
                                   '    SoftDiceLoss calculates multi-class soft dice '
                                   'loss\r\n'
                                   '    loss = '
                                   'avg_batch(1-(sum(W_k*sum(yPred.*yTrue)))/(sum(W_ksum(yPred^2+yTrue^2))))\r\n'
                                   '    where W_k = 1/(number of voxels in class '
                                   'k)^wPow\r\n'
                                   '    Class number of segmented regions includes '
                                   'background\r\n'
                                   '    Args:\r\n'
                                   '        yPred/yTrue: prediced and desired outputs '
                                   'shaped as [mbSize, classNum, tensor dimensions]. '
                                   'Also, both must be float-point\r\n'
                                   '    \twPow, power of weiight. A higher one favours '
                                   'classes with a smaller number of voxels\r\n'
                                   '    Return:\r\n'
                                   '        loss: a scalar tensor\r\n'
                                   "    '''\r\n"
                                   '    def __init__(self, wPow=2.0, '
                                   "name='SoftDiceLoss'):\r\n"
                                   '        super().__init__(name=name)\r\n'
                                   '        self.epsilon = 1e-16 \r\n'
                                   '        self.wPow = wPow\r\n'
                                   '\r\n'
                                   '    def call(self, yPred, yTrue):\r\n'
                                   '        yTrue =tf.dtypes.cast(yTrue, '
                                   'dtype=yPred.dtype)\r\n'
                                   '\t\t# Dot product yPred and yTrue and sum them up for '
                                   'each datum and class\r\n'
                                   '        crossProd=tf.multiply(yPred, yTrue)\r\n'
                                   '\t\t# As a symbolic tensor, dimensions and shapes '
                                   'etc. cannot be extracted from data, nor can it be '
                                   'used in subroutines.\r\n'
                                   '        crossProdSum=tf.math.reduce_sum(crossProd, '
                                   'axis=np.arange(2, 5)) #tf.rank(yTrue)))\r\n'
                                   '\t\t# Calculate weight for each datum and class \r\n'
                                   '        weight = tf.math.reduce_sum(yTrue, '
                                   'axis=np.arange(2, 5))#tf.rank(yTrue)))\r\n'
                                   '\t\t#weight = tf.math.divide(1, '
                                   'tf.math.square(weight)+self.epsilon)\r\n'
                                   '        weight = tf.math.divide(1, '
                                   'tf.math.pow(weight, self.wPow)+self.epsilon)\r\n'
                                   '\t\t# Weighted sum over classes\r\n'
                                   '        numerator = '
                                   '2*tf.math.reduce_sum(tf.multiply(crossProdSum, '
                                   'weight), axis=1)\r\n'
                                   '\t\t# Saquared summation \r\n'
                                   '        yySum = '
                                   'tf.math.reduce_sum(tf.math.square(yPred) + '
                                   'tf.math.square(yTrue), axis=np.arange(2, '
                                   '5))#tf.rank(yTrue)))\r\n'
                                   '\t\t# Weighted sum over classes\r\n'
                                   '        denominator = '
                                   'tf.math.reduce_sum(tf.multiply(weight, yySum), '
                                   'axis=1)\r\n'
                                   '\t\t# Get individual loss and average over '
                                   'minibatch\r\n'
                                   '        loss = tf.math.reduce_mean(1 - '
                                   'tf.math.divide(numerator, '
                                   'denominator+self.epsilon))\r\n'
                                   '\t\t\t\r\n'
                                   '        return loss\r\n'
                                   '    \r\n'
                                   '    def get_config(self):\r\n'
                                   '        config = super(SoftDiceLoss, '
                                   'self).get_config()\r\n'
                                   '        return config\r\n'
                                   '\r\n'
                                   'curOpt = '
                                   'tf.keras.optimizers.Adam(learning_rate=1e-4)\t\r\n'
                                   'lossFunc=SoftDiceLoss(2.0)\r\n'
                                   'ckpt = tf.train.Checkpoint(model=myModel(...), '
                                   'optimizer=curOpt, lossFunc=lossFunc, '
                                   'accFunc=accFunc)\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'I got the following error\r\n'
                                   '```\r\n'
                                   'ckpt = tf.train.Checkpoint(model=myModel(...), '
                                   'optimizer=curOpt, lossFunc=lossFunc, '
                                   'accFunc=accFunc)\r\n'
                                   'Traceback (most recent call last):\r\n'
                                   '\r\n'
                                   '  File "<ipython-input-17-a4d9163bdda3>", line 2, in '
                                   '<module>\r\n'
                                   '    optimizer=curOpt, lossFunc=lossFunc, '
                                   'accFunc=accFunc)\r\n'
                                   '\r\n'
                                   '  File '
                                   '"D:\\TProgramFiles\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\util.py", '
                                   'line 1779, in __init__\r\n'
                                   '    % (v,))\r\n'
                                   '\r\n'
                                   'ValueError: `Checkpoint` was expecting a trackable '
                                   'object (an object derived from `TrackableBase`), got '
                                   '<SoftDiceLoss object at 0x0000000011F6F7C8>. If you '
                                   'believe this object should be trackable (i.e. it is '
                                   'part of the TensorFlow Python API and manages state), '
                                   'please open an issue.\r\n'
                                   '```\r\n'
                                   'I am not sure if a subclass is trackable or not. Is '
                                   'that an intention of design? Or shall such a feature '
                                   'be added? \r\n'
                                   'By the way, if I change the subclass into a normal '
                                   'function, it works fine. Actually, my accFunc(...) is '
                                   'just a normal function.',
                           'created_at': '2020-01-1'},
                          {'body': '<em>Please make sure that this is a bug. As per our '
                                   '[GitHub '
                                   'Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), '
                                   'we only address code/doc bugs, performance issues, '
                                   'feature requests and build/installation issues on '
                                   'GitHub. tag:bug_template</em>\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): yes\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Mac OS 10.14.5\r\n'
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device: N/A\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'binary\r\n'
                                   '- TensorFlow version (use command below): 2.1.0\r\n'
                                   '- Python version: 3.6.8\r\n'
                                   '- Bazel version (if compiling from source): N/A\r\n'
                                   '- GCC/Compiler version (if compiling from source): '
                                   'N/A\r\n'
                                   '- CUDA/cuDNN version: N/A\r\n'
                                   '- GPU model and memory:  N/A\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   '\r\n'
                                   'See the code:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'import numpy as np\r\n'
                                   'import tensorflow as tf\r\n'
                                   '\r\n'
                                   'm = 3\r\n'
                                   'n = 3\r\n'
                                   'x = tf.cast(np.random.randn(1, m, 32), tf.float32)\r\n'
                                   'z = tf.tile(x, [n, 1, 1])\r\n'
                                   '\r\n'
                                   'layer = tf.keras.layers.Dense(32)\r\n'
                                   'w = layer(z)\r\n'
                                   '\r\n'
                                   'tf.print(tf.norm(z[0, :, :] - z[1, :, :]), '
                                   'tf.norm(z[1, :, :] - z[n-1, :, :]))\r\n'
                                   'tf.print(tf.norm(w[0, :, :] - w[1, :, :]), '
                                   'tf.norm(w[1, :, :] - w[n-1, :, :]))\r\n'
                                   '```\r\n'
                                   'In the code we replicate the input `x` 3 times and '
                                   'apply a dense layer upon it. We expect to get the '
                                   'same results for the 3 replicates. In fact the 1st '
                                   'and 2nd results are indeed same, while the 3rd result '
                                   'is different. Here is the results of the script '
                                   'above:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   '0 0\r\n'
                                   '0 1.0617149e-06 # this error is not fixed for each '
                                   'run\r\n'
                                   '```\r\n'
                                   'where we expect all results to be 0.\r\n'
                                   '\r\n'
                                   'Strangely enough, this bug only appears for some '
                                   '`(m,n)` pairs (in the example above `m=n=3`). I ran '
                                   'the code for all `m` and `n` from 1 to 100 and found '
                                   'that there are ~40% combinations that will cause a '
                                   "bug, but I didn't find any obvious pattern...",
                           'created_at': '2020-01-1'},
                          {'body': '**System information**\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Windows 10\r\n'
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device: N/A\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'binary\r\n'
                                   '- TensorFlow version: 2.1.0\r\n'
                                   '- Python version: 3.6.10\r\n'
                                   '- Installed using virtualenv? pip? conda?: pip\r\n'
                                   '- Bazel version (if compiling from source): N/A\r\n'
                                   '- GCC/Compiler version (if compiling from source): '
                                   'N/A\r\n'
                                   '- CUDA/cuDNN version: N/A\r\n'
                                   '- GPU model and memory: N/A\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Describe the problem**\r\n'
                                   '\r\n'
                                   'TensorFlow 2.1.0 added `scipy` as a required '
                                   'dependency.  However, as far as I can tell TensorFlow '
                                   "doesn't actually need scipy. Judging from this PR "
                                   'https://github.com/tensorflow/tensorflow/pull/35278 '
                                   '(which introduced the requirement), the intention was '
                                   'just to avoid a bug with scipy==1.4.0. But it seems '
                                   'that simply not having scipy installed would be '
                                   'another way to avoid that bug, and adding scipy as a '
                                   'requirement to every tensorflow installation seems '
                                   "like kind of a drastic solution. It also wasn't "
                                   "mentioned in the release notes at all, so I'm "
                                   'wondering whether this was an intentional change or '
                                   'not.\r\n'
                                   '\r\n'
                                   '**Provide the exact sequence of commands / steps that '
                                   'you executed before running into the problem**\r\n'
                                   '\r\n'
                                   '`pip install tensorflow`\r\n',
                           'created_at': '2020-01-0'},
                          {'body': '**System information**\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Linux Ubuntu 18.04\r\n'
                                   '- TensorFlow installed from (source or '
                                   'binary):binary\r\n'
                                   '- TensorFlow version:1.14\r\n'
                                   '- Python version:3.7.4\r\n'
                                   '- Installed using virtualenv? pip? conda?:conda\r\n'
                                   '- Bazel version (if compiling from source):\r\n'
                                   '- GCC/Compiler version (if compiling from '
                                   'source):7.4\r\n'
                                   '- CUDA/cuDNN version:10.2\r\n'
                                   '- GPU model and memory:GeForce GTX 960M/PCIe/SSE2, '
                                   '16GB\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Describe the problem**\r\n'
                                   '2020-01-09 12:25:17.491189: F '
                                   'tensorflow/lite/toco/graph_transformations/quantize.cc:611] '
                                   'Check failed: is_rnn_state_array \r\n'
                                   '\r\n'
                                   '**Provide the exact sequence of commands / steps that '
                                   'you executed before running into the problem**\r\n'
                                   'I am converting a quantized graph def (.pb ) to a '
                                   'quantized tflite (.tflite) using the dummy '
                                   'quantization and encounter error as follows\r\n'
                                   '```\r\n'
                                   '(tf_gpu_clone) '
                                   'ridlr@ridlr107:~/TensorFlow/exported_model_12k_quantized$ '
                                   'tflite_convert --output_file tflite_graph.tflite '
                                   '--graph_def_file tflite_graph.pb --input_arrays '
                                   'image_tensor --output_arrays '
                                   'TFLite_Detection_PostProcess --input_shapes '
                                   '1,576,720,3 --allow_custom_ops --inference_type '
                                   'QUANTIZED_UINT8 --std_dev_values 127 --mean_values '
                                   '128 --default_ranges_min 0 --default_ranges_max 6\r\n'
                                   '2020-01-09 12:25:15.452049: I '
                                   'tensorflow/core/platform/cpu_feature_guard.cc:142] '
                                   'Your CPU supports instructions that this TensorFlow '
                                   'binary was not compiled to use: AVX2 FMA\r\n'
                                   '2020-01-09 12:25:15.474575: I '
                                   'tensorflow/core/platform/profile_utils/cpu_utils.cc:94] '
                                   'CPU Frequency: 2808000000 Hz\r\n'
                                   '2020-01-09 12:25:15.475004: I '
                                   'tensorflow/compiler/xla/service/service.cc:168] XLA '
                                   'service 0x561bb6736540 executing computations on '
                                   'platform Host. Devices:\r\n'
                                   '2020-01-09 12:25:15.475031: I '
                                   'tensorflow/compiler/xla/service/service.cc:175]   '
                                   'StreamExecutor device (0): <undefined>, '
                                   '<undefined>\r\n'
                                   'Traceback (most recent call last):\r\n'
                                   '  File "/home/ridlr/anaconda3/bin/tflite_convert", '
                                   'line 10, in <module>\r\n'
                                   '    sys.exit(main())\r\n'
                                   '  File '
                                   '"/home/ridlr/anaconda3/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py", '
                                   'line 503, in main\r\n'
                                   '    app.run(main=run_main, argv=sys.argv[:1])\r\n'
                                   '  File '
                                   '"/home/ridlr/anaconda3/lib/python3.7/site-packages/tensorflow/python/platform/app.py", '
                                   'line 40, in run\r\n'
                                   '    _run(main=main, argv=argv, '
                                   'flags_parser=_parse_flags_tolerate_undef)\r\n'
                                   '  File '
                                   '"/home/ridlr/anaconda3/lib/python3.7/site-packages/absl/app.py", '
                                   'line 299, in run\r\n'
                                   '    _run_main(main, args)\r\n'
                                   '  File '
                                   '"/home/ridlr/anaconda3/lib/python3.7/site-packages/absl/app.py", '
                                   'line 250, in _run_main\r\n'
                                   '    sys.exit(main(argv))\r\n'
                                   '  File '
                                   '"/home/ridlr/anaconda3/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py", '
                                   'line 499, in run_main\r\n'
                                   '    _convert_tf1_model(tflite_flags)\r\n'
                                   '  File '
                                   '"/home/ridlr/anaconda3/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py", '
                                   'line 193, in _convert_tf1_model\r\n'
                                   '    output_data = converter.convert()\r\n'
                                   '  File '
                                   '"/home/ridlr/anaconda3/lib/python3.7/site-packages/tensorflow/lite/python/lite.py", '
                                   'line 904, in convert\r\n'
                                   '    **converter_kwargs)\r\n'
                                   '  File '
                                   '"/home/ridlr/anaconda3/lib/python3.7/site-packages/tensorflow/lite/python/convert.py", '
                                   'line 373, in toco_convert_graph_def\r\n'
                                   '    input_data.SerializeToString())\r\n'
                                   '  File '
                                   '"/home/ridlr/anaconda3/lib/python3.7/site-packages/tensorflow/lite/python/convert.py", '
                                   'line 172, in toco_convert_protos\r\n'
                                   '    "TOCO failed. See console for info.\\n%s\\n%s\\n" '
                                   '% (stdout, stderr))\r\n'
                                   'tensorflow.lite.python.convert.ConverterError: TOCO '
                                   'failed. See console for info.\r\n'
                                   '2020-01-09 12:25:16.861669: I '
                                   'tensorflow/lite/toco/import_tensorflow.cc:1336] '
                                   'Converting unsupported operation: '
                                   'TFLite_Detection_PostProcess\r\n'
                                   '2020-01-09 12:25:16.957738: I '
                                   'tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] '
                                   'Before Removing unused ops: 1537 operators, 2264 '
                                   'arrays (0 quantized)\r\n'
                                   '2020-01-09 12:25:17.017901: I '
                                   'tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] '
                                   'Before general graph transformations: 1537 operators, '
                                   '2264 arrays (0 quantized)\r\n'
                                   '2020-01-09 12:25:17.482076: I '
                                   'tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] '
                                   'After general graph transformations pass 1: 181 '
                                   'operators, 341 arrays (0 quantized)\r\n'
                                   '2020-01-09 12:25:17.485583: I '
                                   'tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] '
                                   'Before pre-quantization graph transformations: 181 '
                                   'operators, 341 arrays (0 quantized)\r\n'
                                   '2020-01-09 12:25:17.486877: I '
                                   'tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] '
                                   'After pre-quantization graph transformations pass 1: '
                                   '99 operators, 259 arrays (0 quantized)\r\n'
                                   '2020-01-09 12:25:17.488034: I '
                                   'tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] '
                                   'Before Group bidirectional sequence lstm/rnn: 99 '
                                   'operators, 259 arrays (0 quantized)\r\n'
                                   '2020-01-09 12:25:17.489088: I '
                                   'tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] '
                                   'Before default min-max range propagation graph '
                                   'transformations: 99 operators, 259 arrays (0 '
                                   'quantized)\r\n'
                                   '2020-01-09 12:25:17.489972: I '
                                   'tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] '
                                   'After default min-max range propagation graph '
                                   'transformations pass 1: 99 operators, 259 arrays (0 '
                                   'quantized)\r\n'
                                   '2020-01-09 12:25:17.491160: I '
                                   'tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] '
                                   'Before quantization graph transformations: 99 '
                                   'operators, 259 arrays (0 quantized)\r\n'
                                   '2020-01-09 12:25:17.491189: F '
                                   'tensorflow/lite/toco/graph_transformations/quantize.cc:611] '
                                   'Check failed: is_rnn_state_array \r\n'
                                   'Fatal Python error: Aborted\r\n'
                                   '\r\n'
                                   'Current thread 0x00007fb839eed740 (most recent call '
                                   'first):\r\n'
                                   '  File '
                                   '"/home/ridlr/anaconda3/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py", '
                                   'line 33 in execute\r\n'
                                   '  File '
                                   '"/home/ridlr/anaconda3/lib/python3.7/site-packages/absl/app.py", '
                                   'line 250 in _run_main\r\n'
                                   '  File '
                                   '"/home/ridlr/anaconda3/lib/python3.7/site-packages/absl/app.py", '
                                   'line 299 in run\r\n'
                                   '  File '
                                   '"/home/ridlr/anaconda3/lib/python3.7/site-packages/tensorflow/python/platform/app.py", '
                                   'line 40 in run\r\n'
                                   '  File '
                                   '"/home/ridlr/anaconda3/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py", '
                                   'line 59 in main\r\n'
                                   '  File "/home/ridlr/anaconda3/bin/toco_from_protos", '
                                   'line 10 in <module>\r\n'
                                   'Aborted (core dumped)\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'However if I do not include the following specifiers '
                                   'a *.tflite is created.\r\n'
                                   '`--inference_type QUANTIZED_UINT8 --std_dev_values '
                                   '127 --mean_values 128 --default_ranges_min 0 '
                                   '--default_ranges_max 6 `\r\n'
                                   '\r\n'
                                   'This *.tflite file when used to convert to '
                                   '*_edgetpu.tflite (this model is used to run inference '
                                   'on Google coral) gives the following error\r\n'
                                   '```\r\n'
                                   '(tf_gpu_clone) '
                                   'ridlr@ridlr107:~/TensorFlow/exported_model_12k_quantized$ '
                                   'edgetpu_compiler tflite_graph.tflite \r\n'
                                   'Edge TPU Compiler version 2.0.267685300\r\n'
                                   'Invalid model: tflite_graph.tflite\r\n'
                                   'Model not quantized\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'Hence it is necessary to include the specifiers for '
                                   'quantization.\r\n'
                                   '\r\n',
                           'created_at': '2020-01-0'},
                          {'body': 'In working with TF 2.0, I noticed that the TF Feature '
                                   'Columns API seems to overlap with the Keras '
                                   'Preprocessing layers (or Keras Utils). For example, '
                                   'you can create an '
                                   '`tf.feature_column.indicator_column()` which creates '
                                   'a bunch of dummy variables or a one-hot encoded '
                                   'matrix based upon a categorical variable. With Keras '
                                   'preprocessing or Utils, you can use the '
                                   '`tf.keras.backend.one_hot()` function to perform the '
                                   'same operation. I think there are similar overlaps '
                                   'between TF Feature Columns like the embedding columns '
                                   'and similar Keras functions for embedding columns.\r\n'
                                   '\r\n'
                                   'I was just wondering if the steering committees for '
                                   'Tensorflow have any direction on whether they plan to '
                                   'promote one set of functions versus the other? Are '
                                   'there any plans to deprecate one set versus the '
                                   'other. For me, it is just a question of where to '
                                   'invest time and planning for code that might have to '
                                   'change in the future. Seems like maintaining the '
                                   'redundancy in the package will potentially lead to '
                                   'performance differences between similar functions, or '
                                   'confusion in setting up the code, etc. \r\n'
                                   '\r\n'
                                   '**NB** \r\n'
                                   'Oh yes, I actually asked this question in the '
                                   'Tensorflow Discussion forum, but no one answered it. '
                                   '@dynamicwebpaige even forwarded the message to '
                                   '@karmel and Mark Omernick, but no one responded. '
                                   'Hence, I posted here. \r\n',
                           'created_at': '2020-01-0'},
                          {'body': 'Hi, guys!\r\n'
                                   '\r\n'
                                   'Here are the prefetch-enabled input stream and yet '
                                   'another random access file with buffer we talked '
                                   "about earlier in #33023. Here come's the code, "
                                   'benchmark numbers are on the way.',
                           'created_at': '2020-01-0'},
                          {'body': '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): No\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): CentOS Linux\r\n'
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device:\r\n'
                                   '- TensorFlow installed from (source or binary): pip '
                                   'install\r\n'
                                   '- TensorFlow version (use command below): '
                                   'v2.0.0-rc2-26-g64c3d38 2.0.0\r\n'
                                   '- Python version: 3.6.9\r\n'
                                   '- Bazel version (if compiling from source):\r\n'
                                   '- GCC/Compiler version (if compiling from source):\r\n'
                                   '- CUDA/cuDNN version:\r\n'
                                   '- GPU model and memory: CPU\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   '\r\n'
                                   'For reference, numpy is planning to register numpy '
                                   'ndarray as a Sequence:\r\n'
                                   'https://github.com/numpy/numpy/issues/2776\r\n'
                                   '\r\n'
                                   'The sample ResNet50 code from '
                                   'https://keras.io/applications/ runs fine. But, if '
                                   'ndarray is registered as a sequence, then TF2 throws '
                                   'an InvalidArgumentError.\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'from keras.applications.resnet50 import ResNet50\r\n'
                                   'from keras.preprocessing import image\r\n'
                                   'from keras.applications.resnet50 import '
                                   'preprocess_input, decode_predictions\r\n'
                                   'import numpy as np\r\n'
                                   'import typing\r\n'
                                   'typing.Sequence.register(np.ndarray)\r\n'
                                   '\r\n'
                                   "model = ResNet50(weights='imagenet')\r\n"
                                   '\r\n'
                                   "img_path = 'elephant.jpg'\r\n"
                                   'img = image.load_img(img_path, target_size=(224, '
                                   '224))\r\n'
                                   'x = image.img_to_array(img)\r\n'
                                   'x = np.expand_dims(x, axis=0)\r\n'
                                   'x = preprocess_input(x)\r\n'
                                   '\r\n'
                                   'preds = model.predict(x)\r\n'
                                   '# decode the results into a list of tuples (class, '
                                   'description, probability)\r\n'
                                   '# (one such list for each sample in the batch)\r\n'
                                   "print('Predicted:', decode_predictions(preds, "
                                   'top=3)[0])\r\n'
                                   "# Predicted: [(u'n02504013', u'Indian_elephant', "
                                   "0.82658225), (u'n01871265', u'tusker', 0.1122357), "
                                   "(u'n02504458', u'African_elephant', 0.061040461)]\r\n"
                                   '```\r\n'
                                   '\r\n'
                                   'Two extra lines added to the sample ResNet50 code '
                                   'are:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'import typing\r\n'
                                   'typing.Sequence.register(np.ndarray)\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'The error is:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   '2020-01-07 13:48:16.421816: W '
                                   'tensorflow/core/common_runtime/base_collective_executor.cc:216] '
                                   'BaseCollectiveExecutor::StartAbort Invalid argument: '
                                   'The first dimension of padding\\s must be the rank of '
                                   'inputs[4,2] []\r\n'
                                   '         [[{{node conv1_pad/Pad}}]]\r\n'
                                   'Traceback (most recent call last):\r\n'
                                   '  File "test_d3m_imports.py", line 16, in <module>\r\n'
                                   '    preds = model.predict(x)\r\n'
                                   '  File '
                                   '"/data/dsbox/kyao/miniconda3/envs/dsbox-eval-2019-winter/lib/python3.6/site-packages/keras/engine/training.py", '
                                   'line 1462, in predict\r\n'
                                   '    callbacks=callbacks)\r\n'
                                   '  File '
                                   '"/data/dsbox/kyao/miniconda3/envs/dsbox-eval-2019-winter/lib/python3.6/site-packages/keras/engine/training_arrays.py", '
                                   'line 324, in predict_loop\r\n'
                                   '    batch_outs = f(ins_batch)\r\n'
                                   '  File '
                                   '"/data/dsbox/kyao/miniconda3/envs/dsbox-eval-2019-winter/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py", '
                                   'line 3740, in __call__\r\n'
                                   '    outputs = self._graph_fn(*converted_inputs)\r\n'
                                   '  File '
                                   '"/data/dsbox/kyao/miniconda3/envs/dsbox-eval-2019-winter/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", '
                                   'line 1081, in __call__\r\n'
                                   '    return self._call_impl(args, kwargs)\r\n'
                                   '  File '
                                   '"/data/dsbox/kyao/miniconda3/envs/dsbox-eval-2019-winter/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", '
                                   'line 1121, in _call_impl\r\n'
                                   '    return self._call_flat(args, '
                                   'self.captured_inputs, cancellation_manager)\r\n'
                                   '  File '
                                   '"/data/dsbox/kyao/miniconda3/envs/dsbox-eval-2019-winter/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", '
                                   'line 1224, in _call_flat\r\n'
                                   '    ctx, args, '
                                   'cancellation_manager=cancellation_manager)\r\n'
                                   '  File '
                                   '"/data/dsbox/kyao/miniconda3/envs/dsbox-eval-2019-winter/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", '
                                   'line 511, in call\r\n'
                                   '    ctx=ctx)\r\n'
                                   '  File '
                                   '"/data/dsbox/kyao/miniconda3/envs/dsbox-eval-2019-winter/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py", '
                                   'line 67, in quick_execute\r\n'
                                   '    six.raise_from(core._status_to_exception(e.code, '
                                   'message), None)\r\n'
                                   '  File "<string>", line 3, in raise_from\r\n'
                                   'tensorflow.python.framework.errors_impl.InvalidArgumentError:  '
                                   'The first dimension of paddings must be the rank of '
                                   'inputs[4,2] []\r\n'
                                   '         [[node conv1_pad/Pad (defined at '
                                   '/data/dsbox/kyao/miniconda3/envs/dsbox-eval-2019-winter/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1751) '
                                   ']] [O\\p:__inference_keras_scratch_graph_10370]\r\n'
                                   '\r\n'
                                   'Function call stack:\r\n'
                                   'keras_scratch_graph\r\n'
                                   '\r\n'
                                   '```\r\n',
                           'created_at': '2020-01-0'},
                          {'body': '<em>Please make sure that this is a '
                                   'build/installation issue. As per our [GitHub '
                                   'Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), '
                                   'we only address code/doc bugs, performance issues, '
                                   'feature requests and build/installation issues on '
                                   'GitHub. tag:build_template</em>\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): official tensorflow image from docker hub\r\n'
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device: n/a\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'n/a\r\n'
                                   '- TensorFlow version: 1.15.0\r\n'
                                   '- Python version: 3\r\n'
                                   '- Installed using virtualenv? pip? conda?: Docker\r\n'
                                   '- Bazel version (if compiling from source): n/a\r\n'
                                   '- GCC/Compiler version (if compiling from source): '
                                   'n/a\r\n'
                                   '- CUDA/cuDNN version: 10\r\n'
                                   '- GPU model and memory: n/a\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Describe the problem**\r\n'
                                   'Simple image built `FROM tensorflow/tensorflow:tag` '
                                   'fails to build when including `mysql-client`\r\n'
                                   '\r\n'
                                   '```dockerfile\r\n'
                                   'FROM tensorflow/tensorflow:1.15.0-gpu-py3-jupyter\r\n'
                                   '\r\n'
                                   '# Avoid ERROR: invoke-rc.d: policy-rc.d denied '
                                   'execution of start.\r\n'
                                   '# RUN sed -i "s/^exit 101$/exit 0/" '
                                   '/usr/sbin/policy-rc.d\r\n'
                                   '\r\n'
                                   '# --- Install any needed packages specified in '
                                   'requirements.apt\r\n'
                                   'COPY requirements.apt .\r\n'
                                   'RUN apt-get update && xargs apt-get install -y < '
                                   'requirements.apt\r\n'
                                   '\r\n'
                                   '# --- Install any needed packages specified in '
                                   'requirements.pip\r\n'
                                   'COPY requirements.pip .\r\n'
                                   'RUN pip install -U --trusted-host pypi.python.org -r '
                                   'requirements.pip\r\n'
                                   '\r\n'
                                   '# activate jupyter extensions\r\n'
                                   'RUN jupyter contrib nbextension install \\\r\n'
                                   '  && jupyter nbextension enable codefolding/main '
                                   '\\\r\n'
                                   '  && jupyter nbextension enable '
                                   'collapsible_headings/main\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Provide the exact sequence of commands / steps that '
                                   'you executed before running into the problem**\r\n'
                                   '\r\n'
                                   'A MWE [repo](https://gitlab.com/SumNeuron/mytf) '
                                   'contains the following files:\r\n'
                                   '\r\n'
                                   '- `Dockerfile.ai`: custom image built on top of '
                                   'official tensorflow/tensorflow\r\n'
                                   '- `docker-compose.ai.development.yml`: specifies '
                                   '`Dockerfile.ai` as build file and mounts `notebooks` '
                                   'directory\r\n'
                                   '- `requirements.pip`: pip requirements that may be '
                                   'used in images other than `Dockerfile.ai`\r\n'
                                   '- `requirements.apt`: packages needed to be installed '
                                   'via `apt-get`\r\n'
                                   '\r\n'
                                   'For convenience a python script `docker.py` is '
                                   'provided, e.g. \r\n'
                                   '```\r\n'
                                   'python docker.py -c {build | up | down}\r\n'
                                   '```\r\n'
                                   'instead of \r\n'
                                   '```\r\n'
                                   'docker-compose -f docker-compose.ai.development.yml '
                                   '{build | up | down}\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '**Any other info / logs**\r\n'
                                   'Include any logs or source code that would be helpful '
                                   'to diagnose the problem. If including tracebacks, '
                                   'please include the full traceback. Large logs and '
                                   'files should be attached.\r\n',
                           'created_at': '2020-01-0'},
                          {'body': 'Thank you for submitting a TensorFlow documentation '
                                   'issue. Per our GitHub\r\n'
                                   'policy, we only address code/doc bugs, performance '
                                   'issues, feature requests, and\r\n'
                                   'build/installation issues on GitHub.\r\n'
                                   '\r\n'
                                   'The TensorFlow docs are open source! To get involved, '
                                   'read the documentation\r\n'
                                   'contributor guide: '
                                   'https://www.tensorflow.org/community/contribute/docs\r\n'
                                   '\r\n'
                                   '## URL(s) with the issue:\r\n'
                                   '\r\n'
                                   'Please provide a link to the documentation entry, for '
                                   'example:\r\n'
                                   'https://www.tensorflow.org/api_docs/python/tf/gradients?version=stable\r\n'
                                   '\r\n'
                                   '## Description of issue (what needs changing):\r\n'
                                   "It's unclear how many list items are returned from "
                                   '`tf.gradients`.\r\n'
                                   '\r\n'
                                   'The second paragraph states that "It returns a list '
                                   'of Tensor of length `len(xs)` where each tensor is '
                                   'the `sum(dy/dx)` for y in `ys`." The "Returns" '
                                   'section says, "A list of `sum(dy/dx)` for each x in '
                                   '`xs`."\r\n'
                                   '\r\n'
                                   'So... which one is it? `sum(dy/dx)` for x in `xs` or '
                                   '`sum(dy/dx)` for y in `ys`? Besides the '
                                   'inconsistency, the summation notation in this '
                                   'documentation is ambiguous. When it says '
                                   '"`sum(dy/dx)` for x in `xs`" does that mean `dy/dx` '
                                   'is summed over the `ys` axis and there is one element '
                                   'produced for each `xs` or the other way around?\r\n'
                                   '\r\n'
                                   'A clarifying example would help and a statement along '
                                   'the lines of "returns a list of <whatever> with as '
                                   'many elements as `xs`" (or `ys` -- I don\'t know).\r\n'
                                   '\r\n'
                                   '### Clear description\r\n'
                                   '\r\n'
                                   'For example, why should someone use this method? How '
                                   'is it useful?\r\n'
                                   '\r\n'
                                   '### Correct links\r\n'
                                   '\r\n'
                                   'Is the link to the source code correct?\r\n'
                                   '\r\n'
                                   '### Parameters defined\r\n'
                                   '\r\n'
                                   'Are all parameters defined and formatted '
                                   'correctly?\r\n'
                                   '\r\n'
                                   '### Returns defined\r\n'
                                   '\r\n'
                                   'Are return values defined?\r\n'
                                   '\r\n'
                                   '### Raises listed and defined\r\n'
                                   '\r\n'
                                   'Are the errors defined? For example,\r\n'
                                   'https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n'
                                   '\r\n'
                                   '### Usage example\r\n'
                                   '\r\n'
                                   'Is there a usage example?\r\n'
                                   '\r\n'
                                   'See the API guide: '
                                   'https://www.tensorflow.org/community/contribute/docs_ref\r\n'
                                   'on how to write testable usage examples.\r\n'
                                   '\r\n'
                                   '### Request visuals, if applicable\r\n'
                                   '\r\n'
                                   'Are there currently visuals? If not, will it clarify '
                                   'the content?\r\n'
                                   '\r\n'
                                   '### Submit a pull request?\r\n'
                                   '\r\n'
                                   'Are you planning to also submit a pull request to fix '
                                   'the issue? See the docs\r\n'
                                   'contributor guide: '
                                   'https://www.tensorflow.org/community/contribute/docs,\r\n'
                                   'docs API guide: '
                                   'https://www.tensorflow.org/community/contribute/docs_ref '
                                   'and the\r\n'
                                   'docs style guide: '
                                   'https://www.tensorflow.org/community/contribute/docs_style\r\n',
                           'created_at': '2020-01-0'},
                          {'body': 'The codelab still links to the experimental folder '
                                   'for the makefile, which is incorrect.\r\n'
                                   '\r\n'
                                   'Visual:\r\n'
                                   '![image](https://user-images.githubusercontent.com/997157/71787651-3bc27180-2fe0-11ea-8318-424dc887efc5.png)\r\n'
                                   '\r\n'
                                   'Update the codelab at this link '
                                   'https://codelabs.developers.google.com/codelabs/sparkfun-tensorflow/#3\r\n'
                                   '\r\n'
                                   'Code should read:\r\n'
                                   '```\r\n'
                                   'make -f tensorflow/lite/micro/tools/make/Makefile '
                                   '\\                                    \r\n'
                                   'TARGET=sparkfun_edge micro_speech_bin\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '## URL(s) with the issue:\r\n'
                                   'https://codelabs.developers.google.com/codelabs/sparkfun-tensorflow/#3\r\n',
                           'created_at': '2020-01-0'},
                          {'body': 'Hi all, \r\n'
                                   '\r\n'
                                   'I am running a training loop using gradientTape which '
                                   'works well, however I am getting different training '
                                   'accuracy metrics when training using the gradientTape '
                                   'loop vs a straight model.fit method. I apologise if '
                                   'this should be a question for stack overflow, '
                                   'however, to the best of my knowledge the parameters '
                                   'are the same and therefore should be producing '
                                   'exactly the same results (or very close at least).. I '
                                   'therefore think there may be a bug and if any one can '
                                   'help me elucidate this i would really appreciate '
                                   'it!\r\n'
                                   '\r\n'
                                   'I have prepared a sequential model as follows:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'model=tf.keras.models.Sequential()\r\n'
                                   'model.add(tf.keras.layers.Dense(units=64, '
                                   'input_dim=5078, activation="relu"))\r\n'
                                   'model.add(tf.keras.layers.Dense(units=32, '
                                   'activation="relu"))\r\n'
                                   'model.add(tf.keras.layers.Dense(units=100, '
                                   'activation="relu"))\r\n'
                                   'model.add(tf.keras.layers.Dense(units=24, '
                                   'activation="sigmoid"))\r\n'
                                   '```\r\n'
                                   'and for the ` model.fit` method, fit as follows:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'model.compile(optimizer="Adam", '
                                   'loss="binary_crossentropy", metrics=["acc"])\r\n'
                                   '\r\n'
                                   'model.fit(X_train, y_train,\r\n'
                                   ' batch_size=32,\r\n'
                                   ' epochs=100, verbose=1,\r\n'
                                   ' validation_split=0.15,\r\n'
                                   ' shuffle=True)\r\n'
                                   '```\r\n'
                                   'This works well and produces the following results '
                                   '(please note 100 epochs is overkill and the model '
                                   'overfits, however this is just to keep the same '
                                   'epochs as the as the gradientTape loop, otherwise '
                                   'there would be an early-stopping callback '
                                   'normally...\r\n'
                                   '\r\n'
                                   'The model metrics are as follows:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   ' 32/119 [=======>......................] - ETA: 0s - '
                                   'loss: 0.0699 - acc: 0.9753\r\n'
                                   '119/119 [==============================] - 0s '
                                   '168us/sample - **loss: 0.0668** - acc: **0.9779** - '
                                   'val_loss: **0.2350** - val_acc: **0.9048**\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'This is the expected behaviour (minus the '
                                   'overfitting)... Now when I create the gradientTape '
                                   'loop as follows, the accuracy metrics are of by about '
                                   '~4-5% during the same 100 epochs, and the reason i '
                                   'suspect a bug is because i believe i am using the '
                                   'appropriate metrics:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'def random_batch(X,y, batch_size=32):\r\n'
                                   '    idx= np.random.randint(len(X), '
                                   'size=batch_size)\r\n'
                                   '    return X[idx], y[idx]\r\n'
                                   '\r\n'
                                   '##Further split train data to training set and '
                                   'validation set\r\n'
                                   '\r\n'
                                   'X_train, X_val, y_train, y_val = train_test_split(\r\n'
                                   '    X_train, y_train, test_size=0.15, '
                                   'random_state=1)\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   '##Run autodiff on model\r\n'
                                   '\r\n'
                                   'n_epochs=100\r\n'
                                   'batch_size=32\r\n'
                                   'n_steps=len(X_train)//batch_size\r\n'
                                   '\r\n'
                                   'optimizer=tf.keras.optimizers.Adam()\r\n'
                                   'loss=tf.keras.losses.BinaryCrossentropy()\r\n'
                                   '\r\n'
                                   'metricLoss=tf.keras.metrics.BinaryCrossentropy()\r\n'
                                   'metricsAcc=tf.keras.metrics.BinaryAccuracy()\r\n'
                                   '\r\n'
                                   'val_acc_metric=tf.keras.metrics.BinaryAccuracy()\r\n'
                                   'val_acc_loss=tf.keras.metrics.BinaryCrossentropy()\r\n'
                                   '\r\n'
                                   '\r\n'
                                   'train_loss_results = []\r\n'
                                   'train_accuracy_results = []\r\n'
                                   '\r\n'
                                   'validation_loss_results = []\r\n'
                                   'validation_accuracy_results = []\r\n'
                                   '\r\n'
                                   '# for loop iterate over epochs\r\n'
                                   'for epoch in range(n_epochs):\r\n'
                                   '\r\n'
                                   '    print("Epoch {}/{}".format(epoch, n_epochs))\r\n'
                                   '\r\n'
                                   '    # for loop iterate over batches\r\n'
                                   '    for step in range(1, n_steps + 1):\r\n'
                                   '        X_batch, y_batch=random_batch(X_train.values, '
                                   'y_train)\r\n'
                                   '\r\n'
                                   '        # gradientTape autodiff\r\n'
                                   '        with tf.GradientTape() as tape:\r\n'
                                   '            y_pred=model(X_batch, training=True)\r\n'
                                   '            loss_values=loss(y_batch, y_pred)\r\n'
                                   '        gradients=tape.gradient(loss_values, '
                                   'model.trainable_weights)\r\n'
                                   '        optimizer.apply_gradients(zip(gradients, '
                                   'model.trainable_weights))\r\n'
                                   '\r\n'
                                   '        metricLoss(y_batch, y_pred)\r\n'
                                   '        metricsAcc.update_state(y_batch, y_pred)\r\n'
                                   '\r\n'
                                   '        # Loss and accuracy\r\n'
                                   '        train_loss_results.append(loss_values)\r\n'
                                   '        '
                                   'train_accuracy_results.append(metricsAcc.result())\r\n'
                                   '\r\n'
                                   '        # Read out training results\r\n'
                                   "        readout = 'Epoch {}, Training loss: {}, "
                                   "Training accuracy: {}'\r\n"
                                   '        print(readout.format(epoch + 1, '
                                   'loss_values,\r\n'
                                   '                              metricsAcc.result() * '
                                   '100))\r\n'
                                   '\r\n'
                                   '        metricsAcc.reset_states\r\n'
                                   '\r\n'
                                   '        # Run a validation loop at the end of each '
                                   'epoch\r\n'
                                   '\r\n'
                                   '    for valbatch in range(1+ n_steps +1):\r\n'
                                   '        X_batchVal, y_batchVal = '
                                   'random_batch(X_val.values, y_val)\r\n'
                                   '\r\n'
                                   '        val_logits = model(X_batchVal)\r\n'
                                   '        # Update val metrics\r\n'
                                   '        val_acc_metric(y_batchVal, val_logits)\r\n'
                                   '        val_acc = val_acc_metric.result()\r\n'
                                   '\r\n'
                                   '        val_acc_metric.update_state(y_batchVal, '
                                   'val_logits)\r\n'
                                   '\r\n'
                                   '        val_loss=val_acc_loss(y_batchVal, '
                                   'val_logits)\r\n'
                                   '\r\n'
                                   '        validation_loss_results.append(val_loss)\r\n'
                                   '        '
                                   'validation_accuracy_results.append(val_acc_metric.result())\r\n'
                                   '\r\n'
                                   '        # Read out validation results\r\n'
                                   "        print( 'Validation loss: ' , "
                                   "float(val_loss),'Validation acc: %s' % (float(val_acc "
                                   '* 100),) )\r\n'
                                   '\r\n'
                                   '        val_acc_metric.reset_states()\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'When i run this code, it works fine, and the '
                                   'iterations update the states of the accuracy and '
                                   'loss: however, the training accuracy is much lower '
                                   'than the model.fit method, after running also for 100 '
                                   'epochs: showing final epoch result that is printed '
                                   '(each same epoch is iterating over each batch):\r\n'
                                   '\r\n'
                                   'Epoch 100, Training loss: 0.027735430747270584, '
                                   'Training accuracy: 93.6534423828125\r\n'
                                   'Epoch 100, Training loss: 0.03832387551665306, '
                                   'Training accuracy: 93.67249298095703\r\n'
                                   '**Epoch 100, Training loss: 0.035500235855579376, '
                                   'Training accuracy: 93.69097900390625**\r\n'
                                   'Validation loss:  0.3204055726528168 Validation acc: '
                                   '90.36458587646484\r\n'
                                   'Validation loss:  0.32066160440444946 Validation acc: '
                                   '89.71354675292969\r\n'
                                   'Validation loss:  0.32083287835121155 Validation acc: '
                                   '90.49479675292969\r\n'
                                   'Validation loss:  0.3209479749202728 Validation acc: '
                                   '90.10416412353516\r\n'
                                   '**Validation loss:  0.32088229060173035 Validation '
                                   'acc: 90.625**\r\n'
                                   '\r\n'
                                   'As you can see,  the training accuracy is ~4-5% lower '
                                   'compared to the model.fit method. The loss records '
                                   'fine, and also, the validation data looks pretty much '
                                   'just like the validation data in the model.fit '
                                   'method. \r\n'
                                   '\r\n'
                                   'Additionally, when i plot accuracy and loss in both '
                                   'model.fit and geadientTape methods, the shape of the '
                                   'curves look pretty much the same, and they both begin '
                                   'to overfit at similar points! but again, there is a '
                                   'huge discrepancy in the training accuracy. \r\n'
                                   '\r\n'
                                   'I have specified the adam optimizer as well '
                                   'binary_crossentropy loss in model.fit and '
                                   'gradientTape. For model.fit, when I specific '
                                   "'accuracy' or 'acc' for metrics, my understanding is "
                                   'that it will call on the binary_accuracy for '
                                   'calculating the accuracy. So as far as I am aware the '
                                   'parameters are similar that results should be fairly '
                                   'similar. \r\n'
                                   '\r\n'
                                   'Additionally, when i call` model.compile` after '
                                   'training the model with `gradientTape` just to '
                                   'confirm evaluation, the results are slightly '
                                   'different again and look more like the model.fit '
                                   'method:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   '**Training**\r\n'
                                   'model.compile(optimizer=optimizer, '
                                   'loss=tf.keras.losses.binary_crossentropy, '
                                   "metrics=['acc'])\r\n"
                                   "print('\\n', model.evaluate(X_train, y_train, "
                                   'verbose=1)[1])\r\n'
                                   '\r\n'
                                   '32/101 [========>.....................] - ETA: 0s - '
                                   'loss: 0.0336 - acc: 0.9948\r\n'
                                   '101/101 [==============================] - 0s '
                                   '307us/sample - **loss: 0.0330 - acc: 0.9942**\r\n'
                                   '\r\n'
                                   '**Validation**\r\n'
                                   'model.compile(optimizer=optimizer, '
                                   'loss=tf.keras.losses.binary_crossentropy, '
                                   "metrics=['acc'])\r\n"
                                   "print('\\n', model.evaluate(X_val, y_val, "
                                   'verbose=1)[1])\r\n'
                                   '\r\n'
                                   '18/18 [==============================] - 0s '
                                   '111us/sample - **loss: 0.3879 - acc: 0.9028**\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'Now model.evaluate shows a loss and accuracy that are '
                                   'very similar to the model.fit method when i call '
                                   'evaluate on X_train and y_train. This is why i am '
                                   'suspect of a bug? Interestingly, the model.evaluate '
                                   'on validation data look similar to the gradientTape '
                                   'loop which leaves me really confused as i am '
                                   'therefore unsure of the true training accuracy and '
                                   'loss!\r\n'
                                   '\r\n'
                                   'If anyone can help i would really appreciate this... '
                                   'I am happy to provide further code upstream of the '
                                   'model etc.. Again, apologies if this is not a bug but '
                                   'this seems really confusing to me like an incorrect '
                                   'behaviour...\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '\r\n',
                           'created_at': '2020-01-0'},
                          {'body': 'Hi,\r\n'
                                   '\r\n'
                                   'We have a TF code to create a graph which later on '
                                   "it's being loaded into our Scala/Java "
                                   'application. \r\n'
                                   '[Code to generate the '
                                   'graph](https://github.com/JohnSnowLabs/spark-nlp/blob/9407da076eced850ec840cfc61e665887400de12/python/tensorflow/lib/ner/ner_model.py)\r\n'
                                   '\r\n'
                                   'In TF `1.12.0` and TF `1.13.1` we used to only see '
                                   'the device placement logs in the console, but in TF '
                                   '`1.15.0` it logs over thousands of lines complaining '
                                   'about:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'Failed to place the graph without changing the '
                                   'devices of some resources. Some of the operations '
                                   '(that had to be colocated with resource generating '
                                   "operations) are not supported on the resources' "
                                   'devices. Current candidate devices are [\r\n'
                                   '  /job:localhost/replica:0/task:0/device:CPU:0].\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'The full log is here due to the length:\r\n'
                                   'https://gist.github.com/maziyarpanahi/83f179e01634db2de12cb82501177c8d\r\n'
                                   '\r\n'
                                   'I understand what the log is saying and I know there '
                                   'is no way to control the logging level through Java '
                                   'API, but I would like to understand what has changed '
                                   'in TF 1.15.0 that we have now all these logs without '
                                   'any change in our process.  \r\n'
                                   '\r\n'
                                   'Issue: It is really hard to debug with that many logs '
                                   'in the console and also the Travis fails due to '
                                   'exceeding logs limit since we have many unit tests '
                                   'using this graph and every time there will be 1000 '
                                   "lines of logs saying something we really don't "
                                   'care.\r\n'
                                   '\r\n'
                                   'Any help to manage to suppress these logs would be '
                                   'highly appreciated.\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '\r\n',
                           'created_at': '2020-01-0'},
                          {'body': '**System information**\r\n'
                                   'Google Colab system (GPU mode) with TensorFlow '
                                   '2.1-rc2 and Python 3.\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'Take a long time to build/compile a seq2seq model '
                                   "when use ``set_floatx('float16')`` instead float32 "
                                   '(default)\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   "I don't know if is normal, but default value "
                                   '``float32`` takes 1-2 second\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   'I coded an example '
                                   '[here](https://drive.google.com/open?id=170KpjIGFmNNt-SS-6oXgVbRnZR4-7ah_)',
                           'created_at': '2020-01-0'},
                          {'body': '** Base System information**\r\n'
                                   '- Linux Ubuntu 18.04\r\n'
                                   '- nvidia-docker: Docker version 19.03.5, build '
                                   '633a0ea838\r\n'
                                   '- nvidia driver via: `sudo apt-get install '
                                   'nvidia-driver-418`\r\n'
                                   '- CUDA/cuDNN version: 10.1\r\n'
                                   '- GPU model and memory:\r\n'
                                   '```\r\n'
                                   '$ nvidia-smi \r\n'
                                   'Thu Jan  2 12:08:27 2020       \r\n'
                                   '+-----------------------------------------------------------------------------+\r\n'
                                   '| NVIDIA-SMI 430.64       Driver Version: '
                                   '430.64       CUDA Version: 10.1     |\r\n'
                                   '|-------------------------------+----------------------+----------------------+\r\n'
                                   '| GPU  Name        Persistence-M| Bus-Id        '
                                   'Disp.A | Volatile Uncorr. ECC |\r\n'
                                   '| Fan  Temp  Perf  Pwr:Usage/Cap|         '
                                   'Memory-Usage | GPU-Util  Compute M. |\r\n'
                                   '|===============================+======================+======================|\r\n'
                                   '|   0  GeForce GT 710      Off  | 00000000:AF:00.0 '
                                   'N/A |                  N/A |\r\n'
                                   '| 40%   46C    P0    N/A /  N/A |      0MiB /  '
                                   '2002MiB |     N/A      Default |\r\n'
                                   '+-------------------------------+----------------------+----------------------+\r\n'
                                   '|   1  GeForce RTX 207...  Off  | 00000000:D8:00.0 '
                                   'Off |                  N/A |\r\n'
                                   '| 34%   39C    P0     1W / 215W |      0MiB /  '
                                   '7982MiB |      0%      Default |\r\n'
                                   '+-------------------------------+----------------------+----------------------+\r\n'
                                   '                                                                               \r\n'
                                   '+-----------------------------------------------------------------------------+\r\n'
                                   '| '
                                   'Processes:                                                       '
                                   'GPU Memory |\r\n'
                                   '|  GPU       PID   Type   Process '
                                   'name                             Usage      |\r\n'
                                   '|=============================================================================|\r\n'
                                   '|    0                    Not '
                                   'Supported                                       |\r\n'
                                   '+-----------------------------------------------------------------------------+\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '** Docker container information**\r\n'
                                   '- Linux Ubuntu 18.04\r\n'
                                   '- TensorFlow installed from: pip3\r\n'
                                   '- TensorFlow version: 1.14.0\r\n'
                                   '- Python version: 3.6.9\r\n'
                                   '- CUDA/cuDNN version:\r\n'
                                   '- GPU model and memory: nvidia-smi output (see '
                                   'above)\r\n'
                                   '- my Dockerfile:\r\n'
                                   '```\r\n'
                                   '#https://www.tensorflow.org/install/gpu\r\n'
                                   'FROM nvidia/cuda:10.0-base-ubuntu18.04\r\n'
                                   '\r\n'
                                   'ENV '
                                   'PATH=/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/conda/bin:$PATH\r\n'
                                   'RUN apt-get update && apt-get upgrade -y && apt-get '
                                   'install -y \\\r\n'
                                   '        nodejs \\\r\n'
                                   '        npm \\\r\n'
                                   '        python3-pip \\\r\n'
                                   '        wget \\\r\n'
                                   '        libmysqlclient-dev \\\r\n'
                                   '        python-dev\r\n'
                                   '#RUN wget -nv '
                                   'https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh '
                                   '&& bash Miniconda3-latest-Linux-x86_64.sh -b -p '
                                   '/opt/conda && rm Miniconda3-latest-Lin$\r\n'
                                   'RUN mkdir /etc/skel/notebooks\r\n'
                                   'RUN npm install -g configurable-http-proxy && pip3 '
                                   'install \\\r\n'
                                   '        jupyterhub \\\r\n'
                                   '        jupyterhub-ldapauthenticator \\\r\n'
                                   '        jupyterlab \\\r\n'
                                   '        notebook \\\r\n'
                                   '        tensorflow-gpu\r\n'
                                   'RUN pip3 install \\\r\n'
                                   '        folium \\\r\n'
                                   '        keras \\\r\n'
                                   '        matplotlib \\\r\n'
                                   '        mysql \\\r\n'
                                   '        mysql-connector \\\r\n'
                                   '        pandas \\\r\n'
                                   '        pymysql \\\r\n'
                                   '        seaborn \\\r\n'
                                   '        sklearn\r\n'
                                   'VOLUME ["/home"]\r\n'
                                   'RUN useradd -ms /bin/bash user -p "$(openssl passwd '
                                   '-1 test)"\r\n'
                                   'COPY ./jupyterhub_config.py '
                                   '/etc/jupyterhub/jupyterhub_config.py\r\n'
                                   'COPY ./jupyterhub_cookie_secret '
                                   '/etc/jupyterhub/jupyterhub_cookie_secret\r\n'
                                   'COPY ./jupyterhub.sqlite '
                                   '/etc/jupyterhub/jupyterhub.sqlite\r\n'
                                   '#CMD ["/usr/local/bin/jupyterhub", "upgrade-db", '
                                   '"--db=sqlite:////etc/jupyterhub/jupyterhub.sqlite"]\r\n'
                                   'EXPOSE 8000\r\n'
                                   'CMD ["/usr/local/bin/jupyterhub", "-f", '
                                   '"/etc/jupyterhub/jupyterhub_config.py", "--debug"]\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Describe the problem**\r\n'
                                   '\r\n'
                                   'I created a Docker container based on the Dockerfile '
                                   '(see above) for a multiuser jupyterhub (with notebook '
                                   'and lab). The basics works fine, I can log in and use '
                                   'the desired python packages and running my projects. '
                                   'However, the container lacks the GPU capabiltites.\r\n'
                                   '\r\n'
                                   '- container will be started by: `$ nvidia-docker run '
                                   '-d -p 8000:8000 --runtime=nvidia --restart '
                                   'unless-stopped --gpus all -v ~/myDocker/home:/home '
                                   'jupyterhub`\r\n'
                                   '- `nvidia-smi` works within the container\r\n'
                                   '- `device_lib.list_local_devices()` prints:\r\n'
                                   '```[name: "/device:CPU:0"\r\n'
                                   'device_type: "CPU"\r\n'
                                   'memory_limit: 268435456\r\n'
                                   'locality {\r\n'
                                   '}\r\n'
                                   'incarnation: 9710542890831123693\r\n'
                                   ', name: "/device:XLA_GPU:0"\r\n'
                                   'device_type: "XLA_GPU"\r\n'
                                   'memory_limit: 17179869184\r\n'
                                   'locality {\r\n'
                                   '}\r\n'
                                   'incarnation: 12724683280898329209\r\n'
                                   'physical_device_desc: "device: XLA_GPU device"\r\n'
                                   ', name: "/device:XLA_GPU:1"\r\n'
                                   'device_type: "XLA_GPU"\r\n'
                                   'memory_limit: 17179869184\r\n'
                                   'locality {\r\n'
                                   '}\r\n'
                                   'incarnation: 12608392157467121046\r\n'
                                   'physical_device_desc: "device: XLA_GPU device"\r\n'
                                   ', name: "/device:XLA_CPU:0"\r\n'
                                   'device_type: "XLA_CPU"\r\n'
                                   'memory_limit: 17179869184\r\n'
                                   'locality {\r\n'
                                   '}\r\n'
                                   'incarnation: 16188673672643731433\r\n'
                                   'physical_device_desc: "device: XLA_CPU device"\r\n'
                                   ']\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '- `from keras import backend as K\r\n'
                                   'K.tensorflow_backend._get_available_gpus()` prints an '
                                   'empty field\r\n'
                                   '- `tf.test.is_gpu_available()` says `False`\r\n'
                                   '\r\n'
                                   'I can see that tensorflow is looking for the '
                                   'following ones and cannot find them:\r\n'
                                   '- libcublas.so.10.0\r\n'
                                   '- libcufft.so.10.0\r\n'
                                   '- libcurand.so.10.0\r\n'
                                   '- libcusolver.so.10.0\r\n'
                                   '- libcusparse.so.10.0\r\n'
                                   '- libcudnn.so.7\r\n'
                                   '\r\n'
                                   'It is strange, I never installed nvidia-smi within '
                                   'the container, I seems to be deployed by docker, but '
                                   'necessary parts are missing for tensorflow. However, '
                                   'if I install CUDA or/and nvidia-toolkits and other '
                                   'software parts in the container, tensorflow is '
                                   'reporting about incorpatible versions:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   '2020-01-01 20:50:11.429852: I '
                                   'tensorflow/core/platform/cpu_feature_guard.cc:142] '
                                   'Your CPU supports instructions that this TensorFlow '
                                   'binary was not compiled to use: AVX2 AVX512F FMA\r\n'
                                   '2020-01-01 20:50:11.466847: I '
                                   'tensorflow/stream_executor/platform/default/dso_loader.cc:42] '
                                   'Successfully opened dynamic library libcuda.so.1\r\n'
                                   '2020-01-01 20:50:11.468037: E '
                                   'tensorflow/stream_executor/cuda/cuda_driver.cc:318] '
                                   'failed call to cuInit: '
                                   'CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has '
                                   'unsupported display driver / cuda driver '
                                   'combination\r\n'
                                   '2020-01-01 20:50:11.468085: I '
                                   'tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] '
                                   'retrieving CUDA diagnostic information for host: '
                                   '9f9f93453aee\r\n'
                                   '2020-01-01 20:50:11.468093: I '
                                   'tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] '
                                   'hostname: 9f9f93453aee\r\n'
                                   '2020-01-01 20:50:11.468236: I '
                                   'tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] '
                                   'libcuda reported version is: 440.33.1\r\n'
                                   '2020-01-01 20:50:11.468265: I '
                                   'tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] '
                                   'kernel reported version is: 430.64.0\r\n'
                                   '2020-01-01 20:50:11.468285: E '
                                   'tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] '
                                   'kernel version 430.64.0 does not match DSO version '
                                   '440.33.1 -- cannot find working devices in this '
                                   'configuration\r\n'
                                   '2020-01-01 20:50:11.489100: I '
                                   'tensorflow/core/platform/profile_utils/cpu_utils.cc:94] '
                                   'CPU Frequency: 2100000000 Hz\r\n'
                                   '2020-01-01 20:50:11.493082: I '
                                   'tensorflow/compiler/xla/service/service.cc:168] XLA '
                                   'service 0x4c12f30 executing computations on platform '
                                   'Host. Devices:\r\n'
                                   '2020-01-01 20:50:11.493143: I '
                                   'tensorflow/compiler/xla/service/service.cc:175]   '
                                   'StreamExecutor device (0): <undefined>, '
                                   '<undefined>\r\n'
                                   '```\r\n'
                                   'I do not think that it is an tensorflow issue. It is '
                                   'moreover the question, how to create an own docker '
                                   'container with tensorflow-gpu with CUDA support. Is '
                                   'the docker base image the right one?',
                           'created_at': '2020-01-0'},
                          {'body': '<em>Please make sure that this is a bug. As per our '
                                   '[GitHub '
                                   'Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), '
                                   'we only address code/doc bugs, performance issues, '
                                   'feature requests and build/installation issues on '
                                   'GitHub. tag:bug_template</em>\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow):\r\n'
                                   'yes\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04):\r\n'
                                   'Linux Ubuntu 18.04\r\n'
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device:\r\n'
                                   'NA\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'binary wheel via PyPI\r\n'
                                   '- TensorFlow version (use command below):\r\n'
                                   '2.1.0-dev20191231 (v1.12.1-21412-g3a094e6 '
                                   '2.1.0-dev20191231)\r\n'
                                   '- Python version:\r\n'
                                   '- Bazel version (if compiling from source):\r\n'
                                   'NA\r\n'
                                   '- GCC/Compiler version (if compiling from source):\r\n'
                                   'NA\r\n'
                                   '- CUDA/cuDNN version:\r\n'
                                   'CUDA 10.0 \r\n'
                                   '- GPU model and memory:\r\n'
                                   'V100 32 GB\r\n'
                                   'You can collect some of this information using our '
                                   'environment capture\r\n'
                                   '[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\n'
                                   'You can also obtain the TensorFlow version with: 1. '
                                   'TF 1.0: `python -c "import\r\n'
                                   'tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"` '
                                   '2. TF 2.0: `python -c\r\n'
                                   '"import tensorflow as tf; '
                                   'print(tf.version.GIT_VERSION, '
                                   'tf.version.VERSION)"`\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   '\r\n'
                                   "I'm suspecting a CPU memory leak when loading "
                                   'multiple models.\r\n'
                                   'When im running infinite loop that keeps loading the '
                                   'same model while using the same variable the memory '
                                   '(private bytes and working set) of the process keep '
                                   'increasing. At some points the working set seems to '
                                   'free some memory, but the trend is that the memory '
                                   'keeps on rising.\r\n'
                                   'I used a simple model (attached).\r\n'
                                   '\r\n'
                                   'This trend happens even though I call gc.collect() on '
                                   'every iteration and '
                                   'tf.keras.backend.clear_session().\r\n'
                                   '\r\n'
                                   'the issue also happens in TF 2.0 '
                                   '(v2.0.0-rc2-26-g64c3d38 2.0.0).\r\n'
                                   'for a specific model:\r\n'
                                   '    running in TF 2.0 each iteration adds 16 MiB\r\n'
                                   '    running in TF 2.1 each iteration adds 2 MiB\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   '\r\n'
                                   'The memory shouldnt increase on each interation\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   '`\r\n'
                                   '```\r\n'
                                   'import os\r\n'
                                   'import tensorflow as tf\r\n'
                                   'import gc # garbage collector\r\n'
                                   'import objgraph\r\n'
                                   'from memory_profiler import profile\r\n'
                                   '\r\n'
                                   'def mem_stat():\r\n'
                                   '  objs = gc.get_objects()\r\n'
                                   '  print("total objects count", len(objs))\r\n'
                                   '\r\n'
                                   '@profile\r\n'
                                   'def profile_own_model():\r\n'
                                   '    model = tf.keras.models.Sequential([\r\n'
                                   '        tf.keras.layers.Flatten(input_shape=(28, '
                                   '28)),\r\n'
                                   '        tf.keras.layers.Dense(128, '
                                   "activation='relu'),\r\n"
                                   '        tf.keras.layers.Dropout(0.2),\r\n'
                                   '        tf.keras.layers.Dense(10, '
                                   "activation='softmax')\r\n"
                                   '    ])\r\n'
                                   "    # model.save('my_model')\r\n"
                                   '    tf.keras.backend.clear_session()\r\n'
                                   '    del model\r\n'
                                   '    gc.collect()\r\n'
                                   '\r\n'
                                   '@profile\r\n'
                                   'def profile_load_model(path):\r\n'
                                   '    model = tf.keras.models.load_model(model_path, '
                                   'compile=False)\r\n'
                                   '    tf.keras.backend.clear_session()\r\n'
                                   '    del model\r\n'
                                   '    gc.collect()\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '\r\n'
                                   "model_path = f'/my_model.hd5'\r\n"
                                   'print("load model in loops:")\r\n'
                                   '\r\n'
                                   'c = 1\r\n'
                                   'while True:\r\n'
                                   '    print("----------- iter", c)\r\n'
                                   '    profile_load_model(model_path)\r\n'
                                   '\r\n'
                                   '    print("mem stat after model creation:")\r\n'
                                   '    mem_stat()\r\n'
                                   '    objgraph.show_growth(limit=30)\r\n'
                                   '    c += 1\r\n'
                                   '```\r\n'
                                   '`\r\n'
                                   '\r\n'
                                   '**Other info / logs**\r\n'
                                   '![memory tf 2 '
                                   '1](https://user-images.githubusercontent.com/27951762/71644038-d9f5c500-2cca-11ea-96e3-b8aedd2e4efb.png)\r\n'
                                   '\r\n'
                                   '\r\n'
                                   'Include any logs or source code that would be helpful '
                                   'to diagnose the problem. If including tracebacks, '
                                   'please include the full traceback. Large logs and '
                                   'files should be attached.\r\n'
                                   '\r\n',
                           'created_at': '2020-01-0'},
                          {'body': 'the function `files_io.get_matching_files` says it '
                                   'takes a "filepath", but actually it takes a glob\r\n'
                                   '\r\n'
                                   'this means that if you save your checkpoints to a '
                                   "folder like `x=[abc]`, then you can't load the "
                                   'previous checkpoint using something like:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'def load_checkpoint(sess, checkpoint_path):\r\n'
                                   '  saver = tf.train.Saver(tf.global_variables())\r\n'
                                   '  ckpt = '
                                   'tf.train.get_checkpoint_state(checkpoint_path)\r\n'
                                   "  tf.logging.info('Loading model %s.', "
                                   'ckpt.model_checkpoint_path)\r\n'
                                   '  saver.restore(sess, ckpt.model_checkpoint_path)\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'where `checkpoint_path="./logs/x=[abc]"`.',
                           'created_at': '2019-12-3'},
                          {'body': 'Incompatible flag '
                                   '--incompatible_no_implicit_file_export will be '
                                   'enabled by default in a future Bazel release [1], '
                                   'thus breaking TensorFlow.\n'
                                   '\n'
                                   'The flag is documented here: '
                                   'https://github.com/bazelbuild/bazel/issues/10225\n'
                                   '\n'
                                   'Please check the following CI builds for build and '
                                   'test results:\n'
                                   '\n'
                                   '* <a '
                                   'href="https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/361#3e0dba20-d84a-4394-bbe8-4155855f8aa5" '
                                   'target="_blank"><img '
                                   'src="https://raw.githubusercontent.com/buildkite/emojis/master/img-buildkite-64/mac.png" '
                                   'height="16"/>macOS, OpenJDK 8</a>\n'
                                   '* <a '
                                   'href="https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/361#8067be5e-7d21-4333-a4e1-6e2817d456d4" '
                                   'target="_blank"><img '
                                   'src="https://raw.githubusercontent.com/buildkite/emojis/master/img-buildkite-64/ubuntu.png" '
                                   'height="16"/>Ubuntu 18.04, OpenJDK 11</a>\n'
                                   '* <a '
                                   'href="https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/361#5664296d-5125-45bc-a16b-80fb8b5b94f1" '
                                   'target="_blank"><img '
                                   'src="https://raw.githubusercontent.com/buildkite/emojis/master/img-buildkite-64/windows.png" '
                                   'height="16"/>Windows, OpenJDK 8</a>\n'
                                   '\n'
                                   'Never heard of incompatible flags before? We have '
                                   '[documentation](https://docs.bazel.build/versions/master/backward-compatibility.html) '
                                   'that explains everything.\n'
                                   '\n'
                                   "If you don't want to receive any future issues for "
                                   'TensorFlow or if you have any questions,\n'
                                   'please file an issue in '
                                   'https://github.com/bazelbuild/continuous-integration\n'
                                   '\n'
                                   '**Important**: Please do NOT modify the issue title '
                                   'since that might break our tools.\n'
                                   '\n'
                                   "[1] The target release hasn't been determined yet. "
                                   'Our tool will update the issue title once the flag '
                                   'flip has been scheduled.\n',
                           'created_at': '2019-12-2'},
                          {'body': '**System information**\r\n'
                                   '- windows\r\n'
                                   '- TensorFlow installed from conda\r\n'
                                   '- TensorFlow version:2.0\r\n'
                                   '- Python version:3.7.4\r\n'
                                   '- CUDA/cuDNN version: 10.2/7.6\r\n'
                                   '- GPU model and memory: 2 nvidia rtx 2070s 8GB\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'i follow the distributed training tutorials to change '
                                   'my code(custom model) for cumtom training loop. but '
                                   'when i run the script, it shows mistake "ValueError: '
                                   'Flattening a PerReplica to components is not '
                                   'supported in replica context.". i don\'t understande '
                                   'why it is happens.  it can run in the train step,  '
                                   "but it can't run in the test step\r\n"
                                   '**Describe the expected behavior**\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   'Provide a reproducible test case that is the bare '
                                   'minimum necessary to generate the problem.\r\n'
                                   '```\r\n'
                                   '# i use this strategy before,but it make the same '
                                   'mistake\r\n'
                                   '# strategy = tf.distribute.MirroredStrategy(\r\n'
                                   '#     '
                                   'cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\r\n'
                                   '\r\n'
                                   'strategy = tf.distribute.MirroredStrategy(\r\n'
                                   '        '
                                   'cross_device_ops=tf.distribute.ReductionToOneDevice("/device:CPU:0"))\r\n'
                                   '\r\n'
                                   'def train_step_fn(rgb, spec):\r\n'
                                   '            with tf.GradientTape() as tape:\r\n'
                                   '                fake_spec = model(rgb, '
                                   'training=True)\r\n'
                                   '                loss = compute_loss(spec, '
                                   'fake_spec)\r\n'
                                   '\r\n'
                                   '            gradients = tape.gradient(loss, '
                                   'model.trainable_variables)\r\n'
                                   '            opt.apply_gradients(zip(gradients, '
                                   'model.trainable_variables))\r\n'
                                   '            # update metrics\r\n'
                                   '            rmse1.update_state(spec, fake_spec)\r\n'
                                   '            rmse2.update_state(spec, fake_spec)\r\n'
                                   '            rrmse1.update_state(spec, fake_spec)\r\n'
                                   '            rrmse2.update_state(spec, fake_spec)\r\n'
                                   '            sam.update_state(spec, fake_spec)\r\n'
                                   '            return loss\r\n'
                                   '\r\n'
                                   'def test_step_fn(rgb, sepc):\r\n'
                                   '            fake_spec = model(rgb, training=False)\r\n'
                                   '            loss = loss_object(spec, fake_spec)\r\n'
                                   '            # update metrics\r\n'
                                   '            rmse1.update_state(spec, fake_spec)\r\n'
                                   '            rmse2.update_state(spec, fake_spec)\r\n'
                                   '            rrmse1.update_state(spec, fake_spec)\r\n'
                                   '            rrmse2.update_state(spec, fake_spec)\r\n'
                                   '            sam.update_state(spec, fake_spec)\r\n'
                                   '            return loss\r\n'
                                   '\r\n'
                                   '@tf.function\r\n'
                                   'def distributed_train_step(rgb, spec):\r\n'
                                   '            per_replica_losses = '
                                   'strategy.experimental_run_v2(train_step_fn,\r\n'
                                   '                                                              '
                                   'args=(rgb, spec))\r\n'
                                   '            return '
                                   'strategy.reduce(tf.distribute.ReduceOp.SUM,\r\n'
                                   '                                   '
                                   'per_replica_losses,\r\n'
                                   '                                   axis=None)\r\n'
                                   '\r\n'
                                   '@tf.function\r\n'
                                   'def distributed_test_step(rgb, spec):\r\n'
                                   '            return '
                                   'strategy.experimental_run_v2(test_step_fn, args=(rgb, '
                                   'spec))\r\n'
                                   '\r\n'
                                   'for epoch in range(parser.epochs):\r\n'
                                   '            # train\r\n'
                                   '            for step, (rgb, spec) in '
                                   'enumerate(datas[0]):\r\n'
                                   '                train_mean_loss = '
                                   'distributed_train_step(rgb, spec)\r\n'
                                   '                steps += 1\r\n'
                                   '                ckpt.steps.assign(steps)\r\n'
                                   '                if step == 50:\r\n'
                                   '                    break\r\n'
                                   '            # val\r\n'
                                   '             rmse1.reset_state()\r\n'
                                   '             rmse2.reset_state()\r\n'
                                   '             rrmse1.reset_state()\r\n'
                                   '             rrmse2.reset_state()\r\n'
                                   '             sam.reset_state()\r\n'
                                   '            for step, (rgb, spec) in '
                                   'enumerate(datas[1]):\r\n'
                                   '\r\n'
                                   '                test_mean_loss = '
                                   'distributed_test_step(rgb, spec)\r\n'
                                   '```\r\n'
                                   '**Other info / logs**\r\n'
                                   '```\r\n'
                                   'ValueError: in converted code:\r\n'
                                   '    mytrainT.py:163 distributed_test_step  *\r\n'
                                   '        return '
                                   'strategy.experimental_run_v2(test_step_fn, args=(rgb, '
                                   'spec))\r\n'
                                   '    '
                                   'C:\\Users\\zhangstation\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py:760 '
                                   'experimental_run_v2\r\n'
                                   '        return '
                                   'self._extended.call_for_each_replica(fn, args=args, '
                                   'kwargs=kwargs)\r\n'
                                   '    mytrainT.py:144 test_step_fn  *\r\n'
                                   '        loss = loss_object(spec, fake_spec)\r\n'
                                   '    '
                                   'C:\\Users\\zhangstation\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\losses.py:125 '
                                   '__call__\r\n'
                                   '        with K.name_scope(scope_name or '
                                   'self.__class__.__name__), graph_ctx:\r\n'
                                   '    '
                                   'C:\\Users\\zhangstation\\Anaconda3\\envs\\tf\\lib\\contextlib.py:112 '
                                   '__enter__\r\n'
                                   '        return next(self.gen)\r\n'
                                   '    '
                                   'C:\\Users\\zhangstation\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\tf_utils.py:435 '
                                   'graph_context_for_symbolic_tensors\r\n'
                                   '        if any(is_symbolic_tensor(v) for v in '
                                   'list(args) + list(kwargs.values())):\r\n'
                                   '    '
                                   'C:\\Users\\zhangstation\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\tf_utils.py:435 '
                                   '<genexpr>\r\n'
                                   '        if any(is_symbolic_tensor(v) for v in '
                                   'list(args) + list(kwargs.values())):\r\n'
                                   '    '
                                   'C:\\Users\\zhangstation\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\tf_utils.py:345 '
                                   'is_symbolic_tensor\r\n'
                                   '        return tensor._is_graph_tensor  # pylint: '
                                   'disable=protected-access\r\n'
                                   '    '
                                   'C:\\Users\\zhangstation\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\framework\\composite_tensor.py:119 '
                                   '_is_graph_tensor\r\n'
                                   '        components = '
                                   'self._type_spec._to_components(self)  # pylint: '
                                   'disable=protected-access\r\n'
                                   '    '
                                   'C:\\Users\\zhangstation\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\distribute\\values.py:500 '
                                   '_to_components\r\n'
                                   '        "Flattening a PerReplica to components is not '
                                   'supported in replica "\r\n'
                                   '\r\n'
                                   '    ValueError: Flattening a PerReplica to components '
                                   'is not supported in replica context.\r\n'
                                   '```',
                           'created_at': '2019-12-2'},
                          {'body': '**System information**\r\n'
                                   '* Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): yes\r\n'
                                   '* OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Ubuntu 18.04.3 LTS\r\n'
                                   '* TensorFlow installed from (source or binary): '
                                   'binary\r\n'
                                   '* TensorFlow version (use command below): '
                                   'v2.1.0-rc0-47-g064e153 2.1.0-rc1 (`python3 -c "import '
                                   'tensorflow as tf; print(tf.version.GIT_VERSION, '
                                   'tf.version.VERSION)"`)\r\n'
                                   '* Python version: Python 3.6.8\r\n'
                                   '* CUDA/cuDNN version: Driver Version: 440.33.01, CUDA '
                                   'Version: 10.2, cuDNN 7.6.2\r\n'
                                   '* GPU model and memory: Tesla V100-SXM2-16GB\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'Compiling autograph function is 4-5x slower in '
                                   'Distributed Mirrored Strategy:\r\n'
                                   '* Single-GPU Distributed Mirrored Strategy: under 5 '
                                   'minutes\r\n'
                                   '* Multi-GPU Distributed Mirrored Strategy: about 30 '
                                   'minutes\r\n'
                                   'The tensorflow code is identical in both setups.\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   'Autograph compilation should take roughly the same '
                                   'time in single and multi-GPU Distributed Mode with '
                                   'Mirrored Strategy.\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   'Training loop (hierarchical VAE in the current '
                                   'configuration):\r\n'
                                   'https://github.com/olegmyrk/SPADE-Tensorflow/blob/4681ac60f2078144d55178f23fa885d3ed191450/SPADE.py#L1151\r\n'
                                   '\r\n'
                                   'The code is adapted from TF1.x repository:\r\n'
                                   'https://github.com/olegmyrk/SPADE-Tensorflow/blob/8866a0b1457cbd4be5d6f549f9bf4075d49b2486/SPADE.py#L1045\r\n'
                                   'and is compiled using TF2.x @tf.function '
                                   'annotation.\r\n'
                                   '\r\n'
                                   'It uses a dry-run of the model to pre-create '
                                   'variables using tf.compat.v1.variable_scope(scope, '
                                   'reuse=tf.compat.v1.AUTO_REUSE):\r\n'
                                   'https://github.com/olegmyrk/SPADE-Tensorflow/blob/4681ac60f2078144d55178f23fa885d3ed191450/SPADE.py#L1174\r\n'
                                   '(it takes about 10 minutes to compile and run it in '
                                   'multi-gpu mode)\r\n'
                                   '\r\n'
                                   'Then it runs the actual training step(s)\r\n'
                                   'https://github.com/olegmyrk/SPADE-Tensorflow/blob/4681ac60f2078144d55178f23fa885d3ed191450/SPADE.py#L1257\r\n'
                                   '(it takes about 20 minutes to compile and run it for '
                                   'the first time in multi-gpu mode)\r\n'
                                   '\r\n'
                                   'It looks that just disabling lines with '
                                   "'optim.apply_gradients'\r\n"
                                   'https://github.com/olegmyrk/SPADE-Tensorflow/blob/4681ac60f2078144d55178f23fa885d3ed191450/SPADE.py#L1229\r\n'
                                   'https://github.com/olegmyrk/SPADE-Tensorflow/blob/4681ac60f2078144d55178f23fa885d3ed191450/SPADE.py#L1231\r\n'
                                   'https://github.com/olegmyrk/SPADE-Tensorflow/blob/4681ac60f2078144d55178f23fa885d3ed191450/SPADE.py#L1233\r\n'
                                   'slashes about 10 out 20 minutes needed for initial '
                                   'run in multi-gpu mode. Which is essentially compiling '
                                   'back-propagation?\r\n'
                                   '\r\n'
                                   'After the first training step that takes 20 minutes '
                                   'the following training steps run at normal speed.\r\n'
                                   '\r\n'
                                   'The total number of mirrored parameters is around '
                                   '500MB.\r\n'
                                   '\r\n'
                                   'With 4 V100 GPUs training step is around 5x slower '
                                   'than with single V100 GPU.\r\n'
                                   '\r\n'
                                   'Command:\r\n'
                                   'NCCL_DEBUG=INFO NCCL_DEBUG_SUBSYS=ALL nohup python3 '
                                   'main.py --dataset CelebAMask-HQ --img_height 256 '
                                   '--img_width 256 --ch 16 --img_ch 3 --phase train '
                                   '--save_freq 10000 --batch_size 12 --gan_type hinge '
                                   '--code_gan_type gan --n_critic 1 --code_num_layers=4 '
                                   '--code_dist_num_layers=0 --augment_flag false '
                                   '--sn=False --train_main=true --train_nondet=true --lr '
                                   '0.0002 --epoch=50 --decay_epoch=25 --print_freq 100 '
                                   '&> train.CelebAMask-HQ.log&\r\n'
                                   '\r\n'
                                   '**Other info / logs**\r\n'
                                   '[train.CelebAMask-HQ.slow_compile.log](https://github.com/tensorflow/tensorflow/files/3993026/train.CelebAMask-HQ.slow_compile.log)\r\n',
                           'created_at': '2019-12-2'},
                          {'body': 'An external developer pointed out that the test for '
                                   'the quantized fully connected operation passes in a '
                                   'non-zero weight offset to the kernel for int8 '
                                   'tests:\r\n'
                                   'https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/kernels/fully_connected_test.cc#L118-L119\r\n'
                                   '\r\n'
                                   'The quantization specification promises that int8 '
                                   'kernels will always receive zero weight offsets:\r\n'
                                   'https://www.tensorflow.org/lite/performance/quantization_spec\r\n'
                                   '\r\n'
                                   'This failing test is preventing an optimized kernel '
                                   'for a hardware platform from being accepted.',
                           'created_at': '2019-12-2'},
                          {'body': '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): Yes, '
                                   'see minimal example.\r\n'
                                   '- OS Platform and Distribution: Ubuntu 18.04.3 LTS\r\n'
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device:  '
                                   'N/A\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'binary (specifically, '
                                   '`tensorflow/tensorflow:nightly-py3` Docker image)\r\n'
                                   '- TensorFlow version (use command below): '
                                   '2.1.0-dev20191216\r\n'
                                   '- Python version: 3.6.9\r\n'
                                   '- Bazel version (if compiling from source): N/A\r\n'
                                   '- GCC/Compiler version (if compiling from source): '
                                   'N/A\r\n'
                                   '- CUDA/cuDNN version: N/A\r\n'
                                   '- GPU model and memory: N/A\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   '\r\n'
                                   'A multi-output Keras model compiled so that one '
                                   "output doesn't have a loss function raises an "
                                   'exception when calling `.fit`.\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   '\r\n'
                                   'Training should minimise the losses defined for the '
                                   'other output(s).\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'import numpy as np\r\n'
                                   'import tensorflow as tf\r\n'
                                   'import tensorflow.keras as keras\r\n'
                                   '\r\n'
                                   'input_a = keras.layers.Input(shape=(10,), '
                                   'name="input_a")\r\n'
                                   'input_b = keras.layers.Input(shape=(20,), '
                                   'name="input_b")\r\n'
                                   'output_a = keras.layers.Dense(1, '
                                   'name="output_a")(input_a)\r\n'
                                   'output_b = keras.layers.Dense(1, '
                                   'name="output_b")(input_b)\r\n'
                                   'model = keras.Model(inputs=[input_a, input_b], '
                                   'outputs=[output_a, output_b])\r\n'
                                   'model.compile(optimizer="sgd", loss={"output_a": '
                                   'None, "output_b": "mse"})\r\n'
                                   '\r\n'
                                   'n = 128\r\n'
                                   'input_a = np.ones((n, 10))\r\n'
                                   'input_b = np.ones((n, 20))\r\n'
                                   'output_a = np.ones((n, 1))\r\n'
                                   'output_b = np.ones((n, 1))\r\n'
                                   '\r\n'
                                   'dataset = tf.data.Dataset.from_tensor_slices(\r\n'
                                   '    ((input_a, input_b), (output_a, output_b))\r\n'
                                   ').batch(64)\r\n'
                                   '\r\n'
                                   'model.fit(dataset)\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'Raises:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'ValueError: Error when checking model target: the '
                                   'list of Numpy arrays that you are passing to your '
                                   'model is not the size the model expected. Expected to '
                                   "see 1 array(s), for inputs ['output_b'] but instead "
                                   'got the following list of 2 arrays: [<tf.Tensor '
                                   "'args_2:0' shape=(None, 1) dtype=float64>, <tf.Tensor "
                                   "'args_3:0' shape=(None, 1) dtype=float64>]...\r\n"
                                   '```',
                           'created_at': '2019-12-1'},
                          {'body': 'Incompatible flag '
                                   '--incompatible_disable_target_provider_fields will '
                                   'break TensorFlow once Bazel 1.2.1 is released.\n'
                                   '\n'
                                   'Please see the following CI builds for more '
                                   'information:\n'
                                   '\n'
                                   '* [:darwin: (OpenJDK 8)](<a '
                                   'href="https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/342#042f4c72-2a23-4d7b-9d3b-d78619ea3fc7" '
                                   'target="_blank">:darwin: (OpenJDK 8)</a>)\n'
                                   '* [:windows: (OpenJDK 8)](<a '
                                   'href="https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/342#65246ccf-c676-40de-b693-3e1408052faa" '
                                   'target="_blank">:windows: (OpenJDK 8)</a>)\n'
                                   '* [:ubuntu: 18.04 (OpenJDK 11)](<a '
                                   'href="https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/342#42574ec2-097a-4fa6-9c82-5de0093a2ed1" '
                                   'target="_blank">:ubuntu: 18.04 (OpenJDK 11)</a>)\n'
                                   '\n'
                                   'Questions? Please file an issue in '
                                   'https://github.com/bazelbuild/continuous-integration\n'
                                   '\n'
                                   '**Important**: Please do NOT modify the issue title '
                                   'since that might break our tools.\n',
                           'created_at': '2019-12-1'},
                          {'body': '@tensorflow/micro\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- macOS 10.15 Catalina\r\n'
                                   '- TensorFlow installed from source \r\n'
                                   '- Tensorflow version (commit SHA if '
                                   'source):2ba0b2ef68d4259e8b02fa8be77a9372020b81b7 '
                                   '(Dec. 16)\r\n'
                                   '- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 '
                                   'etc.): bluepill\r\n'
                                   '\r\n'
                                   '**Describe the problem**\r\n'
                                   '```\r\n'
                                   'arm-none-eabi-g++ -O3 -DNDEBUG -std=c++11 -g '
                                   '-DTF_LITE_STATIC_MEMORY -fno-rtti '
                                   '-DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK '
                                   '-DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG '
                                   '-fno-rtti -fmessage-length=0 -fno-exceptions '
                                   '-fno-unwind-tables -fno-builtin -ffunction-sections '
                                   '-fdata-sections -funsigned-char -MMD -mcpu=cortex-m3 '
                                   '-mthumb -std=gnu++11 -Wvla -Wall -Wextra '
                                   '-Wno-unused-parameter -Wno-missing-field-initializers '
                                   '-Wno-write-strings -Wno-sign-compare '
                                   '-fno-delete-null-pointer-checks -fomit-frame-pointer '
                                   '-fpermissive -nostdlib -g -Os -I. '
                                   '-Itensorflow/lite/micro/tools/make/downloads/ '
                                   '-Itensorflow/lite/micro/tools/make/downloads/gemmlowp '
                                   '-Itensorflow/lite/micro/tools/make/downloads/flatbuffers/include '
                                   '-isystemtensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ '
                                   '-Itensorflow/lite/micro/tools/make/downloads/stm32_bare_lib/include '
                                   '-Itensorflow/lite/micro/tools/make/downloads/kissfft '
                                   '-o '
                                   'tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/hello_world '
                                   'tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/obj/tensorflow/lite/micro/examples/hello_world/main.o '
                                   'tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/obj/tensorflow/lite/micro/examples/hello_world/main_functions.o '
                                   'tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/obj/tensorflow/lite/micro/examples/hello_world/sine_model_data.o '
                                   'tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/obj/tensorflow/lite/micro/examples/hello_world/output_handler.o '
                                   'tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/obj/tensorflow/lite/micro/examples/hello_world/constants.o  '
                                   'tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/lib/libtensorflow-microlite.a '
                                   '-T '
                                   'tensorflow/lite/micro/tools/make/targets/bluepill/bluepill.lds '
                                   '-Wl,-Map=tensorflow/lite/micro/tools/make/gen/bluepill.map,--cref '
                                   '-Wl,--gc-sections -lm\r\n'
                                   'tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/obj/tensorflow/lite/micro/examples/hello_world/main_functions.o: '
                                   "In function `setup()':\r\n"
                                   '/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/examples/hello_world/main_functions.cc:47: '
                                   "undefined reference to `__cxa_guard_acquire'\r\n"
                                   '/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/examples/hello_world/main_functions.cc:47: '
                                   "undefined reference to `__cxa_guard_release'\r\n"
                                   '/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/examples/hello_world/main_functions.cc:63: '
                                   "undefined reference to `__cxa_guard_acquire'\r\n"
                                   '/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/examples/hello_world/main_functions.cc:63: '
                                   "undefined reference to `__cxa_guard_release'\r\n"
                                   '/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/examples/hello_world/main_functions.cc:67: '
                                   "undefined reference to `__cxa_guard_acquire'\r\n"
                                   '/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/examples/hello_world/main_functions.cc:67: '
                                   "undefined reference to `__cxa_guard_release'\r\n"
                                   '/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/examples/hello_world/main_functions.cc:83: '
                                   "undefined reference to `__dso_handle'\r\n"
                                   'tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/lib/libtensorflow-microlite.a(greedy_memory_planner.o): '
                                   'In function '
                                   "`tflite::GreedyMemoryPlanner::~GreedyMemoryPlanner()':\r\n"
                                   '/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/memory_planner/greedy_memory_planner.cc:70: '
                                   "undefined reference to `operator delete(void*)'\r\n"
                                   "`__lock___atexit_recursive_mutex' referenced in "
                                   "section `.data.__atexit_recursive_mutex' of "
                                   '/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/tools/make/downloads/gcc_embedded/bin/../lib/gcc/arm-none-eabi/7.3.1/../../../../arm-none-eabi/lib/thumb/v7-m/libc.a(lib_a-__call_atexit.o): '
                                   "defined in discarded section `COMMON' of "
                                   '/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/tools/make/downloads/gcc_embedded/bin/../lib/gcc/arm-none-eabi/7.3.1/../../../../arm-none-eabi/lib/thumb/v7-m/libc.a(lib_a-lock.o)\r\n'
                                   '/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/tools/make/downloads/gcc_embedded/bin/../lib/gcc/arm-none-eabi/7.3.1/../../../../arm-none-eabi/bin/ld: '
                                   'tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/hello_world: '
                                   "hidden symbol `__dso_handle' isn't defined\r\n"
                                   '/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/tools/make/downloads/gcc_embedded/bin/../lib/gcc/arm-none-eabi/7.3.1/../../../../arm-none-eabi/bin/ld: '
                                   'final link failed: Bad value\r\n'
                                   'collect2: error: ld returned 1 exit status\r\n'
                                   'gmake: *** '
                                   '[tensorflow/lite/micro/examples/hello_world/Makefile.inc:42: '
                                   'tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/hello_world] '
                                   'Error 1\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   '**Please provide the exact sequence of commands/steps '
                                   'when you ran into the problem**\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   '$ /opt/local/bin/gmake -j1 -f '
                                   'tensorflow/lite/micro/tools/make/Makefile '
                                   'TARGET=bluepill hello_world\r\n'
                                   '```\r\n',
                           'created_at': '2019-12-1'},
                          {'body': 'Add TfLite micro Squeeze reference kernel and tests '
                                   '(uint8, int8, float32).\r\n'
                                   '\r\n'
                                   'Signed-off-by: SiCongLi <sicong.li@arm.com>',
                           'created_at': '2019-12-1'},
                          {'body': '**System information**\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Ubuntu 18.04\r\n'
                                   '- TensorFlow installed from: pip\r\n'
                                   '- TensorFlow version (use command below): 1.13.1\r\n'
                                   '- Python version: python3.7\r\n'
                                   '- CUDA/cuDNN version: 10.1\r\n'
                                   '- GPU model and memory: GTX 1080 ti\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   '\r\n'
                                   'Since g++7 is now the default version on Ubuntu 18 '
                                   'and most distributions, most builds will use  '
                                   '`_GLIBCXX_USE_CXX11_ABI=1`. It seems also that when '
                                   'tensorflow is built with  `_GLIBCXX_USE_CXX11_ABI=0`, '
                                   'it implies recompiling all other libraries of the '
                                   'project with this flag which can be unconvenient. \r\n'
                                   '\r\n'
                                   'We noticed that building with '
                                   '`_GLIBCXX_USE_CXX11_ABI=1` increases the RAM by a '
                                   'lot. \r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   '\r\n'
                                   'Both packages should consume the same amount of '
                                   'RAM.\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   '\r\n'
                                   'You can install tensorflow using `python3.7 -m pip '
                                   'install tensorflow==1.13.1` (related to '
                                   'https://github.com/tensorflow/tensorflow/issues/27078) '
                                   'and makes sure \r\n'
                                   '`python3.7 -c "import tensorflow; '
                                   'print(tensorflow.sysconfig.get_compile_flags())"` '
                                   'prints `-D_GLIBCXX_USE_CXX11_ABI=1`. \r\n'
                                   'Then you can install it in python3.6 `python3.6 -m '
                                   'pip install tensorflow==1.13.1` and make sure ` '
                                   'python3.6 -c "import tensorflow; '
                                   'print(tensorflow.sysconfig.get_compile_flags())"` '
                                   'prints `D_GLIBCXX_USE_CXX11_ABI=0`.\r\n'
                                   '\r\n'
                                   'Now run this script with python3.6 and python3.7 and '
                                   'you will see that the second one consume a lot more '
                                   '(x3 on the model I use). Any `saved_model.pb` should '
                                   'work.\r\n'
                                   '\r\n'
                                   '```python\r\n'
                                   'import io\r\n'
                                   'import os\r\n'
                                   'import sys\r\n'
                                   'try:\r\n'
                                   '    from urllib import urlopen\r\n'
                                   'except ImportError:\r\n'
                                   '    from urllib.request import urlopen\r\n'
                                   '\r\n'
                                   'import numpy\r\n'
                                   'import psutil\r\n'
                                   'from PIL import Image\r\n'
                                   '\r\n'
                                   'import tensorflow as tf\r\n'
                                   'from tensorflow.core.protobuf import '
                                   'saved_model_pb2\r\n'
                                   'from tensorflow.python.platform import gfile\r\n'
                                   'from tensorflow.python.util import compat\r\n'
                                   '\r\n'
                                   'process = psutil.Process(os.getpid())\r\n'
                                   '\r\n'
                                   "def print_ram(prefix=''):\r\n"
                                   '    print("RAM", prefix, process.memory_info().rss / '
                                   '1024. / 1024.)\r\n'
                                   '\r\n'
                                   '\r\n'
                                   "if __name__ == '__main__':\r\n"
                                   '\r\n'
                                   '    if len(sys.argv) == 1:\r\n'
                                   "        model_filename = 'saved_model.pb'\r\n"
                                   '    else:\r\n'
                                   '        model_filename = sys.argv[1]\r\n'
                                   '\r\n'
                                   "    with gfile.FastGFile(model_filename, 'rb') as "
                                   'f:\r\n'
                                   '        data = compat.as_bytes(f.read())\r\n'
                                   '        sm = saved_model_pb2.SavedModel()\r\n'
                                   '        sm.ParseFromString(data)\r\n'
                                   '        if 1 != len(sm.meta_graphs):\r\n'
                                   "            print('More than one graph found. Not "
                                   "sure which to write')\r\n"
                                   '            sys.exit(1)\r\n'
                                   '\r\n'
                                   '    img_url = '
                                   "'https://i.dailymail.co.uk/1s/2019/11/23/09/21370544-7717313-image-a-1_1574501083030.jpg'\r\n"
                                   '    image_data = urlopen(img_url).read()\r\n'
                                   '    decoded_data = '
                                   'numpy.array(Image.open(io.BytesIO(image_data)))\r\n'
                                   '    decoded_data = numpy.expand_dims(decoded_data, '
                                   'axis=0)\r\n'
                                   '\r\n'
                                   "    print_ram('before graph import')\r\n"
                                   '    graph = '
                                   'tf.import_graph_def(sm.meta_graphs[0].graph_def)\r\n'
                                   '\r\n'
                                   "    print_ram('before device')\r\n"
                                   '    with tf.device("/device:GPU:0"):\r\n'
                                   '        with tf.Session(graph=graph, config=None) as '
                                   'sess:\r\n'
                                   "            print_ram('after session')\r\n"
                                   '            output = '
                                   "sess.graph.get_tensor_by_name('import/predictions:0')\r\n"
                                   "            print_ram('before run')\r\n"
                                   '            for i in range(10000):\r\n'
                                   '                results = sess.run(output, '
                                   'feed_dict={"import/image_tensor:0": decoded_data})\r\n'
                                   "                print_ram('after run')\r\n"
                                   '```\r\n'
                                   '\r\n'
                                   '**Other info / logs**\r\n'
                                   '\r\n'
                                   'python3.6:\r\n'
                                   '```\r\n'
                                   'RAM before graph import 527.55078125\r\n'
                                   'RAM before device 856.59375\r\n'
                                   '2019-12-16 17:51:27.400388: I '
                                   'tensorflow/core/platform/cpu_feature_guard.cc:141] '
                                   'Your CPU supports instructions that this TensorFlow '
                                   'binary was not compiled to use: AVX2 FMA\r\n'
                                   '2019-12-16 17:51:27.425979: I '
                                   'tensorflow/core/platform/profile_utils/cpu_utils.cc:94] '
                                   'CPU Frequency: 3399580000 Hz\r\n'
                                   '2019-12-16 17:51:27.426637: I '
                                   'tensorflow/compiler/xla/service/service.cc:150] XLA '
                                   'service 0x229fee0 executing computations on platform '
                                   'Host. Devices:\r\n'
                                   '2019-12-16 17:51:27.426655: I '
                                   'tensorflow/compiler/xla/service/service.cc:158]   '
                                   'StreamExecutor device (0): <undefined>, '
                                   '<undefined>\r\n'
                                   'RAM after session 860.25\r\n'
                                   'RAM before run 860.25\r\n'
                                   'RAM after run 948.12109375\r\n'
                                   'RAM after run 998.0\r\n'
                                   'RAM after run 1022.2265625\r\n'
                                   'RAM after run 1038.984375\r\n'
                                   'RAM after run 1038.984375\r\n'
                                   'RAM after run 1056.0\r\n'
                                   'RAM after run 1092.1953125\r\n'
                                   'RAM after run 1097.09375\r\n'
                                   'RAM after run 1097.09375\r\n'
                                   'RAM after run 1097.09375\r\n'
                                   'RAM after run 1097.09375\r\n'
                                   'RAM after run 1097.09375\r\n'
                                   'RAM after run 1116.42578125\r\n'
                                   'RAM after run 1116.42578125\r\n'
                                   'RAM after run 1116.42578125\r\n'
                                   'RAM after run 1116.42578125\r\n'
                                   'RAM after run 1116.42578125\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'python3.7:\r\n'
                                   '```\r\n'
                                   'RAM before graph import 510.33984375\r\n'
                                   'RAM before device 752.87890625\r\n'
                                   '2019-12-16 17:26:00.118658: I '
                                   'tensorflow/core/platform/cpu_feature_guard.cc:141] '
                                   'Your CPU supports instructions that this TensorFlow '
                                   'binary was not compiled to use: AVX2 FMA\r\n'
                                   '2019-12-16 17:26:00.141979: I '
                                   'tensorflow/core/platform/profile_utils/cpu_utils.cc:94] '
                                   'CPU Frequency: 3399580000 Hz\r\n'
                                   '2019-12-16 17:26:00.142737: I '
                                   'tensorflow/compiler/xla/service/service.cc:150] XLA '
                                   'service 0x265aff0 executing computations on platform '
                                   'Host. Devices:\r\n'
                                   '2019-12-16 17:26:00.142775: I '
                                   'tensorflow/compiler/xla/service/service.cc:158]   '
                                   'StreamExecutor device (0): <undefined>, '
                                   '<undefined>\r\n'
                                   'RAM after session 756.5625\r\n'
                                   'RAM before run 756.5625\r\n'
                                   'RAM after run 2977.8515625\r\n'
                                   'RAM after run 3030.1640625\r\n'
                                   'RAM after run 3047.8046875\r\n'
                                   'RAM after run 3090.08203125\r\n'
                                   'RAM after run 3121.296875\r\n'
                                   'RAM after run 3122.0703125\r\n'
                                   'RAM after run 3123.1015625\r\n'
                                   'RAM after run 3123.1015625\r\n'
                                   'RAM after run 3135.9921875\r\n'
                                   '```',
                           'created_at': '2019-12-1'},
                          {'body': 'It looks like `experimental_run_tf_function` was '
                                   'removed from `tf.keras.Model.compile` in this commit '
                                   'a few days ago: '
                                   'https://github.com/tensorflow/tensorflow/commit/c73c99ca3e0bacf2bca313f270bb3eae28869530#diff-de9b96ac2d81503324cbbbe21732031fR1159\r\n'
                                   '\r\n'
                                   'In [Horovod](http://horovod.ai/), this flag / graph '
                                   'mode is necessary in order for '
                                   '`Optimizer.get_gradients()` to be called, which '
                                   'aggregates gradients across workers.  Since this flag '
                                   'has been removed, distributed training in Horovod '
                                   'with `tf.keras` is not working in our nightly '
                                   'builds.\r\n'
                                   '\r\n'
                                   'Is there a workaround to achieve the same behavior '
                                   'with the latest changes on master?\r\n'
                                   '\r\n'
                                   'Note that we cannot perform the allreduce aggregation '
                                   'in `apply_gradients` due to interactions with '
                                   'gradient clipping and loss scaling (see '
                                   'https://github.com/horovod/horovod/pull/1347).\r\n',
                           'created_at': '2019-12-1'},
                          {'body': '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): Yes\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Linux Ubuntu 16.04 in Docker\r\n'
                                   '- TensorFlow installed from (source or binary): pip '
                                   'install\r\n'
                                   '- TensorFlow version (use command below): '
                                   'v2.0.0-rc2-26-g64c3d38\r\n'
                                   '- Python version: 3.5\r\n'
                                   '- CUDA/cuDNN version: 10.0 / 7\r\n'
                                   '- GPU model and memory: GTX 1080Ti / 11175MiB\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   '\r\n'
                                   'Hi authors and developers,\r\n'
                                   '\r\n'
                                   'I am developing our project in tf=2.0.0 and '
                                   'eager_mode is disable.\r\n'
                                   '\r\n'
                                   'The main reason is tf=1.x will not be maintained but '
                                   'third party libraries have not been ready for tf=2.0 '
                                   'yet.\r\n'
                                   '\r\n'
                                   'I got bug when I was running custom loss keras model '
                                   'with tf.distribute.MirroredStrategy()\r\n'
                                   '\r\n'
                                   'This bug can be reproduced by the following minimal '
                                   'testcase:\r\n'
                                   '\r\n'
                                   '```python\r\n'
                                   '#%%\r\n'
                                   'from distutils.version import LooseVersion\r\n'
                                   'import numpy as np\r\n'
                                   'import tensorflow as tf\r\n'
                                   '\r\n'
                                   '# disable eager model for tf=2.x\r\n'
                                   'tf.compat.v1.disable_eager_execution()\r\n'
                                   '\r\n'
                                   'batch_size = 100\r\n'
                                   'img_h = 32\r\n'
                                   'img_w = 32\r\n'
                                   'img_min = 0\r\n'
                                   'img_max = 1\r\n'
                                   'channels = 3\r\n'
                                   'num_classes = 10\r\n'
                                   '\r\n'
                                   'strategy = tf.distribute.MirroredStrategy()\r\n'
                                   '#%%\r\n'
                                   'def download_data():\r\n'
                                   '\r\n'
                                   '    # get raw data\r\n'
                                   '    (trainX, trainY), (testX, testY) = '
                                   'tf.keras.datasets.cifar10.load_data()\r\n'
                                   '    trainX = trainX.astype(np.float32)\r\n'
                                   '    testX  = testX.astype(np.float32)\r\n'
                                   '\r\n'
                                   '    # ont-hot\r\n'
                                   '    trainY = tf.keras.utils.to_categorical(trainY, '
                                   '10)\r\n'
                                   '    testY  = tf.keras.utils.to_categorical(testY , '
                                   '10)\r\n'
                                   '\r\n'
                                   '    # get validation sets\r\n'
                                   '    training_size = 45000\r\n'
                                   '    validX = trainX[training_size:,:]\r\n'
                                   '    validY = trainY[training_size:,:]\r\n'
                                   '\r\n'
                                   '    trainX = trainX[:training_size,:]\r\n'
                                   '    trainY = trainY[:training_size,:]\r\n'
                                   '\r\n'
                                   '    return trainX, trainY, validX, validY, testX, '
                                   'testY\r\n'
                                   '\r\n'
                                   '#%%\r\n'
                                   'class DataGenerator:\r\n'
                                   '\r\n'
                                   '    def __init__(self, sess, dataX, dataY, total_len, '
                                   'batch_size):\r\n'
                                   '\r\n'
                                   '        super().__init__()\r\n'
                                   '\r\n'
                                   '        self.total_len  = total_len\r\n'
                                   '        self.batch_size = batch_size\r\n'
                                   '        self.cleanX = dataX\r\n'
                                   '        self.totalY = dataY\r\n'
                                   '        self.sess = sess\r\n'
                                   '        self.on_epoch_end()\r\n'
                                   '\r\n'
                                   '    def __build_pipeline(self, dataX, dataY):\r\n'
                                   '\r\n'
                                   '        # create dataset API\r\n'
                                   '        def preprocess_fn(dataX, dataY):\r\n'
                                   '            \r\n'
                                   '            dataX = '
                                   'tf.image.random_flip_left_right(dataX)\r\n'
                                   '\r\n'
                                   '            # workaround solution\r\n'
                                   '            if LooseVersion(tf.__version__) < '
                                   "LooseVersion('1.14.0'):\r\n"
                                   '                outputX = dataX\r\n'
                                   '            else:\r\n'
                                   '                outputX = (dataX, dataY)\r\n'
                                   '            return outputX, dataY\r\n'
                                   '\r\n'
                                   '        dataset = tf.data.Dataset.from_tensor_slices( '
                                   '(dataX, dataY) )\r\n'
                                   '        dataset = dataset.shuffle(batch_size * 8)\r\n'
                                   '        dataset = dataset.repeat()\r\n'
                                   '        dataset = dataset.batch(batch_size)\r\n'
                                   '        dataset = dataset.map(preprocess_fn, '
                                   'num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n'
                                   '        dataset = '
                                   'dataset.prefetch(tf.data.experimental.AUTOTUNE)\r\n'
                                   '\r\n'
                                   '        self.dataset   = dataset\r\n'
                                   '\r\n'
                                   '    def  __len__(self):\r\n'
                                   '\r\n'
                                   '        return self.total_len // self.batch_size\r\n'
                                   '\r\n'
                                   '    def on_epoch_end(self):\r\n'
                                   '\r\n'
                                   '        # run permutation\r\n'
                                   '        rand_idx = '
                                   'np.random.permutation(self.total_len)\r\n'
                                   '        cleanX = self.cleanX[rand_idx]\r\n'
                                   '        totalY = self.totalY[rand_idx]\r\n'
                                   '\r\n'
                                   '        self.__build_pipeline(cleanX, totalY)\r\n'
                                   '\r\n'
                                   '#%%\r\n'
                                   '# ref: https://keras.io/examples/cifar10_resnet/\r\n'
                                   'def build_clf():\r\n'
                                   '    #with strategy.scope():\r\n'
                                   "    with tf.compat.v1.variable_scope('optimizer'):\r\n"
                                   '        def resnet_layer(inputs,\r\n'
                                   '                        num_filters=16,\r\n'
                                   '                        kernel_size=3,\r\n'
                                   '                        strides=1,\r\n'
                                   "                        activation='relu',\r\n"
                                   '                        batch_normalization=True,\r\n'
                                   '                        conv_first=True):\r\n'
                                   '            """2D Convolution-Batch '
                                   'Normalization-Activation stack builder\r\n'
                                   '\r\n'
                                   '            # Arguments\r\n'
                                   '                inputs (tensor): input tensor from '
                                   'input image or previous layer\r\n'
                                   '                num_filters (int): Conv2D number of '
                                   'filters\r\n'
                                   '                kernel_size (int): Conv2D square '
                                   'kernel dimensions\r\n'
                                   '                strides (int): Conv2D square stride '
                                   'dimensions\r\n'
                                   '                activation (string): activation '
                                   'name\r\n'
                                   '                batch_normalization (bool): whether '
                                   'to include batch normalization\r\n'
                                   '                conv_first (bool): conv-bn-activation '
                                   '(True) or\r\n'
                                   '                    bn-activation-conv (False)\r\n'
                                   '\r\n'
                                   '            # Returns\r\n'
                                   '                x (tensor): tensor as input to the '
                                   'next layer\r\n'
                                   '            """\r\n'
                                   '            conv = '
                                   'tf.keras.layers.Conv2D(num_filters,\r\n'
                                   '                        kernel_size=kernel_size,\r\n'
                                   '                        strides=strides,\r\n'
                                   "                        padding='same',\r\n"
                                   '                        '
                                   "kernel_initializer='he_normal',\r\n"
                                   '                        '
                                   'kernel_regularizer=tf.keras.regularizers.l2(1e-4))\r\n'
                                   '\r\n'
                                   '            x = inputs\r\n'
                                   '            if conv_first:\r\n'
                                   '                x = conv(x)\r\n'
                                   '                if batch_normalization:\r\n'
                                   '                    x = '
                                   'tf.keras.layers.BatchNormalization()(x)\r\n'
                                   '                if activation is not None:\r\n'
                                   '                    x = '
                                   'tf.keras.layers.Activation(activation)(x)\r\n'
                                   '            else:\r\n'
                                   '                if batch_normalization:\r\n'
                                   '                    x = '
                                   'tf.keras.layers.BatchNormalization()(x)\r\n'
                                   '                if activation is not None:\r\n'
                                   '                    x = '
                                   'tf.keras.layers.Activation(activation)(x)\r\n'
                                   '                x = conv(x)\r\n'
                                   '            return x\r\n'
                                   '\r\n'
                                   '        def cw_loss(y_true, y_pred):\r\n'
                                   '            label_mask  = label_ref\r\n'
                                   '            pre_softmax = x\r\n'
                                   '            if LooseVersion(tf.__version__) < '
                                   "LooseVersion('1.14.0'):\r\n"
                                   '                correct_logit = '
                                   'tf.reduce_sum(label_mask * pre_softmax, axis=1, '
                                   'keep_dims=True)\r\n'
                                   '            else:\r\n'
                                   '                correct_logit = '
                                   'tf.reduce_sum(label_mask * pre_softmax, axis=1, '
                                   'keepdims=True)\r\n'
                                   '            distance = tf.nn.relu( pre_softmax - '
                                   'correct_logit + (1-label_mask) * 10)\r\n'
                                   '            inactivate = tf.cast( '
                                   'tf.less_equal(distance, 1e-9), dtype=tf.float32)\r\n'
                                   '            weight = '
                                   "tf.keras.layers.Activation('softmax')(-1e9*inactivate "
                                   '+ distance)\r\n'
                                   '            loss = tf.reduce_sum((1-label_mask) * '
                                   'distance * weight, axis=1)\r\n'
                                   '            loss = tf.math.reduce_mean(loss)\r\n'
                                   '            return loss\r\n'
                                   '\r\n'
                                   "        # set model's parameters (depth = n * 6 + "
                                   '2)\r\n'
                                   '        n = 8\r\n'
                                   '        num_filters = 16\r\n'
                                   '\r\n'
                                   '        clf_input = '
                                   'tf.keras.layers.Input(shape=(img_h, img_w, channels), '
                                   'name="model/input")\r\n'
                                   '        label_ref = '
                                   'tf.keras.layers.Input(shape=(num_classes,), '
                                   "name='label_ref')\r\n"
                                   '        input_list = [clf_input, label_ref]\r\n'
                                   '\r\n'
                                   '        x = resnet_layer(inputs=clf_input)\r\n'
                                   '        for stack in range(3):\r\n'
                                   '            for res_block in range(n):\r\n'
                                   '                strides = 1\r\n'
                                   '                if stack > 0 and res_block == 0:  # '
                                   'first layer but not first stack\r\n'
                                   '                    strides = 2  # downsample\r\n'
                                   '                y = resnet_layer(inputs=x,\r\n'
                                   '                                '
                                   'num_filters=num_filters,\r\n'
                                   '                                strides=strides)\r\n'
                                   '                y = resnet_layer(inputs=y,\r\n'
                                   '                                '
                                   'num_filters=num_filters,\r\n'
                                   '                                activation=None)\r\n'
                                   '                if stack > 0 and res_block == 0:  # '
                                   'first layer but not first stack\r\n'
                                   '                    # linear projection residual '
                                   'shortcut connection to match\r\n'
                                   '                    # changed dims\r\n'
                                   '                    x = resnet_layer(inputs=x,\r\n'
                                   '                                    '
                                   'num_filters=num_filters,\r\n'
                                   '                                    kernel_size=1,\r\n'
                                   '                                    '
                                   'strides=strides,\r\n'
                                   '                                    '
                                   'activation=None,\r\n'
                                   '                                    '
                                   'batch_normalization=False)\r\n'
                                   '                x = tf.keras.layers.Add()([x, y])\r\n'
                                   '                x = '
                                   "tf.keras.layers.Activation('relu')(x)\r\n"
                                   '            num_filters *= 2\r\n'
                                   '\r\n'
                                   '        x = '
                                   'tf.keras.layers.AveragePooling2D(pool_size=8)(x)\r\n'
                                   '        x = tf.keras.layers.Flatten()(x)\r\n'
                                   '        x = tf.keras.layers.Dense(num_classes , '
                                   "kernel_initializer='he_normal', "
                                   'activation=None)(x)\r\n'
                                   '        y = '
                                   "tf.keras.layers.Activation('softmax')(x)\r\n"
                                   '\r\n'
                                   '        optimizer = '
                                   'tf.keras.optimizers.Adam(lr=0.001)\r\n'
                                   '        clf_model = '
                                   'tf.keras.models.Model(inputs=input_list, outputs=y, '
                                   "name='clf_model')\r\n"
                                   '        '
                                   "clf_model.compile(loss='categorical_crossentropy', "
                                   "optimizer=optimizer, metrics=['accuracy', "
                                   'cw_loss])\r\n'
                                   '    clf_model.summary()\r\n'
                                   '\r\n'
                                   '    return clf_model\r\n'
                                   '\r\n'
                                   '#%%\r\n'
                                   "if __name__ == '__main__':\r\n"
                                   '\r\n'
                                   '    # set GPU\r\n'
                                   '    import os\r\n'
                                   '    if os.environ.get("CUDA_VISIBLE_DEVICES") is '
                                   'None:\r\n'
                                   '        os.environ["CUDA_VISIBLE_DEVICES"] = "0"\r\n'
                                   '\r\n'
                                   '    # reset tf session\r\n'
                                   '    tf.compat.v1.keras.backend.clear_session()\r\n'
                                   '    gpu_options = '
                                   'tf.compat.v1.GPUOptions(allow_growth=True)\r\n'
                                   '    sess = '
                                   'tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\r\n'
                                   '    tf.compat.v1.keras.backend.set_session(sess)\r\n'
                                   '\r\n'
                                   '    # Hyperparameters\r\n'
                                   '    batch_size = 100\r\n'
                                   '    epochs = 1\r\n'
                                   '\r\n'
                                   '    # prepare data\r\n'
                                   '    trainX, trainY, validX, validY, testX, testY = '
                                   'download_data()\r\n'
                                   '    train_gen = DataGenerator(sess, trainX, trainY, '
                                   'trainY.shape[0], batch_size)\r\n'
                                   '    valid_gen = DataGenerator(sess, validX, validY, '
                                   'validY.shape[0], batch_size)\r\n'
                                   '    test_gen  = DataGenerator(sess, testX, testY, '
                                   'testY.shape[0], batch_size)\r\n'
                                   '\r\n'
                                   '    # build model\r\n'
                                   '    model = build_clf()\r\n'
                                   '\r\n'
                                   '    # train model\r\n'
                                   '    model.fit(train_gen.dataset,\r\n'
                                   '                    epochs=epochs,\r\n'
                                   '                    steps_per_epoch = '
                                   'train_gen.__len__(),\r\n'
                                   '                    '
                                   'validation_data=valid_gen.dataset,\r\n'
                                   '                    validation_steps= '
                                   'valid_gen.__len__(),\r\n'
                                   '                    verbose=1)\r\n'
                                   '\r\n'
                                   '    # print result\r\n'
                                   "    meta_string = '[Testing]'\r\n"
                                   "    prefix_string = ''\r\n"
                                   '    output = model.evaluate(test_gen.dataset, steps = '
                                   'test_gen.__len__())\r\n'
                                   '    for ii in range( len( model.metrics_names) ):\r\n'
                                   "        meta_string = meta_string + '- {:s}{:s}: "
                                   "{:.3f} '.format(prefix_string, "
                                   'model.metrics_names[ii], output[ii])\r\n'
                                   '\r\n'
                                   '    print(meta_string)\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'First, this testing case looks good without enabling '
                                   '`tf.distribute.MirroredStrategy()`\r\n'
                                   '\r\n'
                                   'There is the output for normal case:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'Train on 450 steps, validate on 50 steps\r\n'
                                   '2019-12-13 16:20:30.625379: I '
                                   'tensorflow/stream_executor/platform/default/dso_loader.cc:44] '
                                   'Successfully opened dynamic library '
                                   'libcublas.so.10.0\r\n'
                                   '2019-12-13 16:20:31.217430: I '
                                   'tensorflow/stream_executor/platform/default/dso_loader.cc:44] '
                                   'Successfully opened dynamic library libcudnn.so.7\r\n'
                                   '2019-12-13 16:20:33.007150: W '
                                   'tensorflow/stream_executor/cuda/redzone_allocator.cc:312] '
                                   'Not found: ./bin/ptxas not found\r\n'
                                   'Relying on driver to perform ptx compilation. This '
                                   'message will be only logged once.\r\n'
                                   '450/450 [==============================] - 40s '
                                   '88ms/step - loss: 1.8299 - accuracy: 0.4744 - '
                                   'cw_loss: 9.5022 - val_loss: 1.9870 - val_accuracy: '
                                   '0.4528 - val_cw_loss: 9.6570\r\n'
                                   '100/100 [==============================] - 3s '
                                   '26ms/step - loss: 2.0089 - accuracy: 0.4511 - '
                                   'cw_loss: 9.6708\r\n'
                                   '[Testing]- loss: 2.009 - accuracy: 0.451 - cw_loss: '
                                   '9.671\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'Next, we tried to enable '
                                   '`tf.distribute.MirroredStrategy()` so we modified the '
                                   'testcase by the following patch:\r\n'
                                   '\r\n'
                                   '```diff\r\n'
                                   'def build_clf():\r\n'
                                   '-    #with strategy.scope():\r\n'
                                   '-    with '
                                   "tf.compat.v1.variable_scope('optimizer'):\r\n"
                                   'def build_clf():\r\n'
                                   '+    with strategy.scope():\r\n'
                                   '+    #with '
                                   "tf.compat.v1.variable_scope('optimizer'):\r\n"
                                   '```\r\n'
                                   '\r\n'
                                   'And we got the error message:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'Traceback (most recent call last):\r\n'
                                   '  File "bug.py", line 233, in <module>\r\n'
                                   '    verbose=1)\r\n'
                                   '  File '
                                   '"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training.py", '
                                   'line 717, in fit\r\n'
                                   '    use_multiprocessing=use_multiprocessing)\r\n'
                                   '  File '
                                   '"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py", '
                                   'line 685, in fit\r\n'
                                   "    steps_name='steps_per_epoch')\r\n"
                                   '  File '
                                   '"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py", '
                                   'line 299, in model_iteration\r\n'
                                   '    batch_outs = f(actual_inputs)\r\n'
                                   '  File '
                                   '"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/backend.py", '
                                   'line 3580, in __call__\r\n'
                                   '    run_metadata=self.run_metadata)\r\n'
                                   '  File '
                                   '"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/client/session.py", '
                                   'line 1472, in __call__\r\n'
                                   '    run_metadata_ptr)\r\n'
                                   'tensorflow.python.framework.errors_impl.InvalidArgumentError: '
                                   '2 root error(s) found.\r\n'
                                   '  (0) Invalid argument: You must feed a value for '
                                   "placeholder tensor 'model/input' with dtype float and "
                                   'shape [?,32,32,3]\r\n'
                                   '         [[{{node model/input}}]]\r\n'
                                   '         '
                                   '[[batch_normalization_9/cond/else/_325/FusedBatchNormV3/ReadVariableOp/_2529]]\r\n'
                                   '  (1) Invalid argument: You must feed a value for '
                                   "placeholder tensor 'model/input' with dtype float and "
                                   'shape [?,32,32,3]\r\n'
                                   '         [[{{node model/input}}]]\r\n'
                                   '0 successful operations.\r\n'
                                   '0 derived errors ignored.\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'This error is very similar to the previous issue '
                                   '#34866.\r\n'
                                   '\r\n'
                                   'I guess that those two issues may have some strong '
                                   'connection.\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   '\r\n'
                                   'It should work properly.\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   '\r\n'
                                   'Please see the section of **Describe the current '
                                   'behavior**\r\n'
                                   '\r\n'
                                   '**Other info / logs**\r\n'
                                   '\r\n'
                                   'The following message is the result generated by '
                                   '`tf_env_collect.sh`\r\n'
                                   '```\r\n'
                                   '== check python '
                                   '===================================================\r\n'
                                   'python version: 3.5.2\r\n'
                                   'python branch:\r\n'
                                   "python build version: ('default', 'Oct  8 2019 "
                                   "13:06:37')\r\n"
                                   'python compiler version: GCC 5.4.0 20160609\r\n'
                                   'python implementation: CPython\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '== check os platform '
                                   '===============================================\r\n'
                                   'os: Linux\r\n'
                                   'os kernel version: #40~18.04.1-Ubuntu SMP Thu Nov 14 '
                                   '12:06:39 UTC 2019\r\n'
                                   'os release version: 5.0.0-37-generic\r\n'
                                   'os platform: '
                                   'Linux-5.0.0-37-generic-x86_64-with-Ubuntu-16.04-xenial\r\n'
                                   "linux distribution: ('Ubuntu', '16.04', 'xenial')\r\n"
                                   "linux os distribution: ('Ubuntu', '16.04', "
                                   "'xenial')\r\n"
                                   "mac version: ('', ('', '', ''), '')\r\n"
                                   "uname: uname_result(system='Linux', "
                                   "node='f7f509f1dacf', release='5.0.0-37-generic', "
                                   "version='#40~18.04.1-Ubuntu SMP Thu Nov 14 12:06:39 "
                                   "UTC 2019', machine='x86_64', processor='x86_64')\r\n"
                                   "architecture: ('64bit', 'ELF')\r\n"
                                   'machine: x86_64\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '== are we in docker '
                                   '=============================================\r\n'
                                   'Yes\r\n'
                                   '\r\n'
                                   '== compiler '
                                   '=====================================================\r\n'
                                   'c++ (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 '
                                   '20160609\r\n'
                                   'Copyright (C) 2015 Free Software Foundation, Inc.\r\n'
                                   'This is free software; see the source for copying '
                                   'conditions.  There is NO\r\n'
                                   'warranty; not even for MERCHANTABILITY or FITNESS FOR '
                                   'A PARTICULAR PURPOSE.\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '== check pips '
                                   '===================================================\r\n'
                                   'numpy                  1.17.4\r\n'
                                   'protobuf               3.11.1\r\n'
                                   'tensorflow-estimator   2.0.1\r\n'
                                   'tensorflow-gpu         2.0.0\r\n'
                                   'tensorflow-probability 0.8.0\r\n'
                                   '\r\n'
                                   '== check for virtualenv '
                                   '=========================================\r\n'
                                   'False\r\n'
                                   '\r\n'
                                   '== tensorflow import '
                                   '============================================\r\n'
                                   'tf.version.VERSION = 2.0.0\r\n'
                                   'tf.version.GIT_VERSION = v2.0.0-rc2-26-g64c3d38\r\n'
                                   'tf.version.COMPILER_VERSION = 7.3.1 20180303\r\n'
                                   'Sanity check: array([1], dtype=int32)\r\n'
                                   '       443:     find library=libpthread.so.0 [0]; '
                                   'searching\r\n'
                                   '       443:      search '
                                   'path=/usr/local/nvidia/lib/tls/x86_64:/usr/local/nvidia/lib/tls:/usr/local/nvidia/lib/x86_64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64/tls/x86_64:/usr/local/nvidia/lib64/tls:/usr/local/nvidia/lib64/x86_64:/usr/local/nvidia/lib64          '
                                   '(LD_LIBRARY_PATH)\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/nvidia/lib/tls/x86_64/libpthread.so.0\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/nvidia/lib/tls/libpthread.so.0\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/nvidia/lib/x86_64/libpthread.so.0\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/nvidia/lib/libpthread.so.0\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/nvidia/lib64/tls/x86_64/libpthread.so.0\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/nvidia/lib64/tls/libpthread.so.0\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/nvidia/lib64/x86_64/libpthread.so.0\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/nvidia/lib64/libpthread.so.0\r\n'
                                   '       443:      search cache=/etc/ld.so.cache\r\n'
                                   '       443:       trying '
                                   'file=/lib/x86_64-linux-gnu/libpthread.so.0\r\n'
                                   '       443:\r\n'
                                   '       443:     find library=libc.so.6 [0]; '
                                   'searching\r\n'
                                   '       443:      search path=           '
                                   '(LD_LIBRARY_PATH)\r\n'
                                   '       443:      search cache=/etc/ld.so.cache\r\n'
                                   '       443:       trying '
                                   'file=/lib/x86_64-linux-gnu/libc.so.6\r\n'
                                   '       443:\r\n'
                                   '       443:     find library=libdl.so.2 [0]; '
                                   'searching\r\n'
                                   '       443:      search path=           '
                                   '(LD_LIBRARY_PATH)\r\n'
                                   '       443:      search cache=/etc/ld.so.cache\r\n'
                                   '       443:       trying '
                                   'file=/lib/x86_64-linux-gnu/libdl.so.2\r\n'
                                   '       443:\r\n'
                                   '       443:     find library=libutil.so.1 [0]; '
                                   'searching\r\n'
                                   '       443:      search path=           '
                                   '(LD_LIBRARY_PATH)\r\n'
                                   '       443:      search cache=/etc/ld.so.cache\r\n'
                                   '       443:       trying '
                                   'file=/lib/x86_64-linux-gnu/libutil.so.1\r\n'
                                   '       443:\r\n'
                                   '       443:     find library=libexpat.so.1 [0]; '
                                   'searching\r\n'
                                   '       443:      search path=           '
                                   '(LD_LIBRARY_PATH)\r\n'
                                   '       443:      search cache=/etc/ld.so.cache\r\n'
                                   '       443:       trying '
                                   'file=/lib/x86_64-linux-gnu/libexpat.so.1\r\n'
                                   '       443:\r\n'
                                   '       443:     find library=libz.so.1 [0]; '
                                   'searching\r\n'
                                   '       443:      search path=           '
                                   '(LD_LIBRARY_PATH)\r\n'
                                   '       443:      search cache=/etc/ld.so.cache\r\n'
                                   '       443:       trying '
                                   'file=/lib/x86_64-linux-gnu/libz.so.1\r\n'
                                   '       443:\r\n'
                                   '       443:     find library=libm.so.6 [0]; '
                                   'searching\r\n'
                                   '       443:      search path=           '
                                   '(LD_LIBRARY_PATH)\r\n'
                                   '       443:      search cache=/etc/ld.so.cache\r\n'
                                   '       443:       trying '
                                   'file=/lib/x86_64-linux-gnu/libm.so.6\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/lib/x86_64-linux-gnu/libpthread.so.0\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/lib/x86_64-linux-gnu/libc.so.6\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/lib/x86_64-linux-gnu/libm.so.6\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/lib/x86_64-linux-gnu/libz.so.1\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/lib/x86_64-linux-gnu/libexpat.so.1\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/lib/x86_64-linux-gnu/libutil.so.1\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/lib/x86_64-linux-gnu/libdl.so.2\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     initialize program: '
                                   '/usr/local/bin/python\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     transferring control: '
                                   '/usr/local/bin/python\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/lib/python3.5/lib-dynload/_opcode.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:     find '
                                   'library=libopenblasp-r0-34a18dc3.3.7.so [0]; '
                                   'searching\r\n'
                                   '       443:      search '
                                   'path=/usr/local/lib/python3.5/dist-packages/numpy/core/../.libs/tls/x86_64:/usr/local/lib/python3.5/dist-packages/numpy/core/../.libs/tls:/usr/local/lib/python3.5/dist-packages/numpy/core/../.libs/x86_64:/usr/local/lib/python3.5/dist-packages/numpy/core/../.libs            '
                                   '(RPATH from file '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/core/_multiarray_umath.cpython-35m-x86_64-linux-gnu.so)\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/numpy/core/../.libs/tls/x86_64/libopenblasp-r0-34a18dc3.3.7.so\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/numpy/core/../.libs/tls/libopenblasp-r0-34a18dc3.3.7.so\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/numpy/core/../.libs/x86_64/libopenblasp-r0-34a18dc3.3.7.so\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/numpy/core/../.libs/libopenblasp-r0-34a18dc3.3.7.so\r\n'
                                   '       443:\r\n'
                                   '       443:     find '
                                   'library=libgfortran-ed201abd.so.3.0.0 [0]; '
                                   'searching\r\n'
                                   '       443:      search '
                                   'path=/usr/local/lib/python3.5/dist-packages/numpy/core/../.libs         '
                                   '(RPATH from file '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/core/_multiarray_umath.cpython-35m-x86_64-linux-gnu.so)\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/numpy/core/../.libs/libgfortran-ed201abd.so.3.0.0\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/core/../.libs/libgfortran-ed201abd.so.3.0.0\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/core/../.libs/libopenblasp-r0-34a18dc3.3.7.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/core/_multiarray_umath.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/core/_multiarray_tests.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/linalg/lapack_lite.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/linalg/_umath_linalg.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:     find library=libbz2.so.1.0 [0]; '
                                   'searching\r\n'
                                   '       443:      search path=           '
                                   '(LD_LIBRARY_PATH)\r\n'
                                   '       443:      search cache=/etc/ld.so.cache\r\n'
                                   '       443:       trying '
                                   'file=/lib/x86_64-linux-gnu/libbz2.so.1.0\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/lib/x86_64-linux-gnu/libbz2.so.1.0\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/lib/python3.5/lib-dynload/_bz2.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:     find library=liblzma.so.5 [0]; '
                                   'searching\r\n'
                                   '       443:      search path=           '
                                   '(LD_LIBRARY_PATH)\r\n'
                                   '       443:      search cache=/etc/ld.so.cache\r\n'
                                   '       443:       trying '
                                   'file=/lib/x86_64-linux-gnu/liblzma.so.5\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/lib/x86_64-linux-gnu/liblzma.so.5\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/lib/python3.5/lib-dynload/_lzma.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:     find library=libmpdec.so.2 [0]; '
                                   'searching\r\n'
                                   '       443:      search path=           '
                                   '(LD_LIBRARY_PATH)\r\n'
                                   '       443:      search cache=/etc/ld.so.cache\r\n'
                                   '       443:       trying '
                                   'file=/usr/lib/x86_64-linux-gnu/libmpdec.so.2\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/lib/x86_64-linux-gnu/libmpdec.so.2\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/lib/python3.5/lib-dynload/_decimal.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/fft/_pocketfft_internal.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/random/mtrand.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/random/common.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/random/bounded_integers.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/random/mt19937.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/random/bit_generator.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:     find library=libcrypto.so.1.0.0 [0]; '
                                   'searching\r\n'
                                   '       443:      search path=           '
                                   '(LD_LIBRARY_PATH)\r\n'
                                   '       443:      search cache=/etc/ld.so.cache\r\n'
                                   '       443:       trying '
                                   'file=/lib/x86_64-linux-gnu/libcrypto.so.1.0.0\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/lib/x86_64-linux-gnu/libcrypto.so.1.0.0\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/lib/python3.5/lib-dynload/_hashlib.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/random/philox.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/random/pcg64.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/random/sfc64.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/random/generator.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:     find '
                                   'library=libtensorflow_framework.so.2 [0]; '
                                   'searching\r\n'
                                   '       443:      search '
                                   'path=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/x86_64:/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls:/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/x86_64:/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow:/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/tls/x86_64:/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/tls:/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/x86_64:/usr/local/lib/python3.5/dist-packages/tensorflow_core/python:/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../tls/x86_64:/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../tls:/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../x86_64:/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/..            '
                                   '(RPATH from file '
                                   '/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/x86_64/libtensorflow_framework.so.2\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/libtensorflow_framework.so.2\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/x86_64/libtensorflow_framework.so.2\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/libtensorflow_framework.so.2\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/tls/x86_64/libtensorflow_framework.so.2\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/tls/libtensorflow_framework.so.2\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/x86_64/libtensorflow_framework.so.2\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/libtensorflow_framework.so.2\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../tls/x86_64/libtensorflow_framework.so.2\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../tls/libtensorflow_framework.so.2\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../x86_64/libtensorflow_framework.so.2\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.2\r\n'
                                   '       443:\r\n'
                                   '       443:     find library=librt.so.1 [0]; '
                                   'searching\r\n'
                                   '       443:      search '
                                   'path=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python:/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/..             '
                                   '(RPATH from file '
                                   '/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/librt.so.1\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../librt.so.1\r\n'
                                   '       443:      search path=           '
                                   '(LD_LIBRARY_PATH)\r\n'
                                   '       443:      search cache=/etc/ld.so.cache\r\n'
                                   '       443:       trying '
                                   'file=/lib/x86_64-linux-gnu/librt.so.1\r\n'
                                   '       443:\r\n'
                                   '       443:     find library=libstdc++.so.6 [0]; '
                                   'searching\r\n'
                                   '       443:      search '
                                   'path=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python:/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/..             '
                                   '(RPATH from file '
                                   '/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/libstdc++.so.6\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../libstdc++.so.6\r\n'
                                   '       443:      search path=           '
                                   '(LD_LIBRARY_PATH)\r\n'
                                   '       443:      search cache=/etc/ld.so.cache\r\n'
                                   '       443:       trying '
                                   'file=/usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n'
                                   '       443:\r\n'
                                   '       443:     find library=libgcc_s.so.1 [0]; '
                                   'searching\r\n'
                                   '       443:      search '
                                   'path=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python:/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/..             '
                                   '(RPATH from file '
                                   '/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/libgcc_s.so.1\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../libgcc_s.so.1\r\n'
                                   '       443:      search path=           '
                                   '(LD_LIBRARY_PATH)\r\n'
                                   '       443:      search cache=/etc/ld.so.cache\r\n'
                                   '       443:       trying '
                                   'file=/lib/x86_64-linux-gnu/libgcc_s.so.1\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/lib/x86_64-linux-gnu/libgcc_s.so.1\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/lib/x86_64-linux-gnu/librt.so.1\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.2\r\n'
                                   '       443:\r\n'
                                   '       443:     find library=libhdfs.so [0]; '
                                   'searching\r\n'
                                   '       443:      search '
                                   'path=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/..           '
                                   '(RPATH from file '
                                   '/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../libhdfs.so\r\n'
                                   '       443:      search '
                                   'path=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python:/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/..             '
                                   '(RPATH from file '
                                   '/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/libhdfs.so\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../libhdfs.so\r\n'
                                   '       443:      search path=           '
                                   '(LD_LIBRARY_PATH)\r\n'
                                   '       443:      search cache=/etc/ld.so.cache\r\n'
                                   '       443:      search '
                                   'path=/lib/x86_64-linux-gnu/tls/x86_64:/lib/x86_64-linux-gnu/tls:/lib/x86_64-linux-gnu/x86_64:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu/tls/x86_64:/usr/lib/x86_64-linux-gnu/tls:/usr/lib/x86_64-linux-gnu/x86_64:/usr/lib/x86_64-linux-gnu:/lib/tls/x86_64:/lib/tls:/lib/x86_64:/lib:/usr/lib/tls/x86_64:/usr/lib/tls:/usr/lib/x86_64:/usr/lib              '
                                   '(system search path)\r\n'
                                   '       443:       trying '
                                   'file=/lib/x86_64-linux-gnu/tls/x86_64/libhdfs.so\r\n'
                                   '       443:       trying '
                                   'file=/lib/x86_64-linux-gnu/tls/libhdfs.so\r\n'
                                   '       443:       trying '
                                   'file=/lib/x86_64-linux-gnu/x86_64/libhdfs.so\r\n'
                                   '       443:       trying '
                                   'file=/lib/x86_64-linux-gnu/libhdfs.so\r\n'
                                   '       443:       trying '
                                   'file=/usr/lib/x86_64-linux-gnu/tls/x86_64/libhdfs.so\r\n'
                                   '       443:       trying '
                                   'file=/usr/lib/x86_64-linux-gnu/tls/libhdfs.so\r\n'
                                   '       443:       trying '
                                   'file=/usr/lib/x86_64-linux-gnu/x86_64/libhdfs.so\r\n'
                                   '       443:       trying '
                                   'file=/usr/lib/x86_64-linux-gnu/libhdfs.so\r\n'
                                   '       443:       trying '
                                   'file=/lib/tls/x86_64/libhdfs.so\r\n'
                                   '       443:       trying file=/lib/tls/libhdfs.so\r\n'
                                   '       443:       trying '
                                   'file=/lib/x86_64/libhdfs.so\r\n'
                                   '       443:       trying file=/lib/libhdfs.so\r\n'
                                   '       443:       trying '
                                   'file=/usr/lib/tls/x86_64/libhdfs.so\r\n'
                                   '       443:       trying '
                                   'file=/usr/lib/tls/libhdfs.so\r\n'
                                   '       443:       trying '
                                   'file=/usr/lib/x86_64/libhdfs.so\r\n'
                                   '       443:       trying file=/usr/lib/libhdfs.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/google/protobuf/internal/_api_implementation.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/google/protobuf/pyext/_message.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/lib/python3.5/lib-dynload/_csv.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/lib/python3.5/lib-dynload/termios.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/fast_tensor_util.so\r\n'
                                   '       443:\r\n'
                                   '       443:     find library=libuuid.so.1 [0]; '
                                   'searching\r\n'
                                   '       443:      search path=           '
                                   '(LD_LIBRARY_PATH)\r\n'
                                   '       443:      search cache=/etc/ld.so.cache\r\n'
                                   '       443:       trying '
                                   'file=/lib/x86_64-linux-gnu/libuuid.so.1\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/lib/x86_64-linux-gnu/libuuid.so.1\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/wrapt/_wrappers.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/lib/python3.5/lib-dynload/_json.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:     find library=libssl.so.1.0.0 [0]; '
                                   'searching\r\n'
                                   '       443:      search path=           '
                                   '(LD_LIBRARY_PATH)\r\n'
                                   '       443:      search cache=/etc/ld.so.cache\r\n'
                                   '       443:       trying '
                                   'file=/lib/x86_64-linux-gnu/libssl.so.1.0.0\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/lib/x86_64-linux-gnu/libssl.so.1.0.0\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/lib/python3.5/lib-dynload/_ssl.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:     find '
                                   'library=libhdf5-49599f4e.so.103.0.0 [0]; searching\r\n'
                                   '       443:      search '
                                   'path=/usr/local/lib/python3.5/dist-packages/h5py/.libs/tls/x86_64:/usr/local/lib/python3.5/dist-packages/h5py/.libs/tls:/usr/local/lib/python3.5/dist-packages/h5py/.libs/x86_64:/usr/local/lib/python3.5/dist-packages/h5py/.libs                '
                                   '(RPATH from file '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/_errors.cpython-35m-x86_64-linux-gnu.so)\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/h5py/.libs/tls/x86_64/libhdf5-49599f4e.so.103.0.0\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/h5py/.libs/tls/libhdf5-49599f4e.so.103.0.0\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/h5py/.libs/x86_64/libhdf5-49599f4e.so.103.0.0\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/h5py/.libs/libhdf5-49599f4e.so.103.0.0\r\n'
                                   '       443:\r\n'
                                   '       443:     find '
                                   'library=libhdf5_hl-db841637.so.100.1.1 [0]; '
                                   'searching\r\n'
                                   '       443:      search '
                                   'path=/usr/local/lib/python3.5/dist-packages/h5py/.libs          '
                                   '(RPATH from file '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/_errors.cpython-35m-x86_64-linux-gnu.so)\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/h5py/.libs/libhdf5_hl-db841637.so.100.1.1\r\n'
                                   '       443:\r\n'
                                   '       443:     find library=libsz-1c7dd0cf.so.2.0.1 '
                                   '[0]; searching\r\n'
                                   '       443:      search '
                                   'path=/usr/local/lib/python3.5/dist-packages/h5py/.libs/./tls/x86_64:/usr/local/lib/python3.5/dist-packages/h5py/.libs/./tls:/usr/local/lib/python3.5/dist-packages/h5py/.libs/./x86_64:/usr/local/lib/python3.5/dist-packages/h5py/.libs/.                '
                                   '(RPATH from file '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/.libs/libhdf5-49599f4e.so.103.0.0)\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/h5py/.libs/./tls/x86_64/libsz-1c7dd0cf.so.2.0.1\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/h5py/.libs/./tls/libsz-1c7dd0cf.so.2.0.1\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/h5py/.libs/./x86_64/libsz-1c7dd0cf.so.2.0.1\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/h5py/.libs/./libsz-1c7dd0cf.so.2.0.1\r\n'
                                   '       443:\r\n'
                                   '       443:     find library=libaec-2147abcd.so.0.0.4 '
                                   '[0]; searching\r\n'
                                   '       443:      search '
                                   'path=/usr/local/lib/python3.5/dist-packages/h5py/.libs/.                '
                                   '(RPATH from file '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/.libs/libhdf5-49599f4e.so.103.0.0)\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/h5py/.libs/./libaec-2147abcd.so.0.0.4\r\n'
                                   '       443:\r\n'
                                   '       443:     find library=libz-a147dcb0.so.1.2.3 '
                                   '[0]; searching\r\n'
                                   '       443:      search '
                                   'path=/usr/local/lib/python3.5/dist-packages/h5py/.libs/.                '
                                   '(RPATH from file '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/.libs/libhdf5-49599f4e.so.103.0.0)\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/h5py/.libs/./libz-a147dcb0.so.1.2.3\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/.libs/./libz-a147dcb0.so.1.2.3\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/.libs/./libaec-2147abcd.so.0.0.4\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/.libs/./libsz-1c7dd0cf.so.2.0.1\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/.libs/libhdf5-49599f4e.so.103.0.0\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/.libs/libhdf5_hl-db841637.so.100.1.1\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/_errors.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/defs.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/_objects.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/_conv.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5r.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5t.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/utils.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       452:     find library=libc.so.6 [0]; '
                                   'searching\r\n'
                                   '       452:      search '
                                   'path=/usr/local/nvidia/lib/tls/x86_64:/usr/local/nvidia/lib/tls:/usr/local/nvidia/lib/x86_64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64/tls/x86_64:/usr/local/nvidia/lib64/tls:/usr/local/nvidia/lib64/x86_64:/usr/local/nvidia/lib64          '
                                   '(LD_LIBRARY_PATH)\r\n'
                                   '       452:       trying '
                                   'file=/usr/local/nvidia/lib/tls/x86_64/libc.so.6\r\n'
                                   '       452:       trying '
                                   'file=/usr/local/nvidia/lib/tls/libc.so.6\r\n'
                                   '       452:       trying '
                                   'file=/usr/local/nvidia/lib/x86_64/libc.so.6\r\n'
                                   '       452:       trying '
                                   'file=/usr/local/nvidia/lib/libc.so.6\r\n'
                                   '       452:       trying '
                                   'file=/usr/local/nvidia/lib64/tls/x86_64/libc.so.6\r\n'
                                   '       452:       trying '
                                   'file=/usr/local/nvidia/lib64/tls/libc.so.6\r\n'
                                   '       452:       trying '
                                   'file=/usr/local/nvidia/lib64/x86_64/libc.so.6\r\n'
                                   '       452:       trying '
                                   'file=/usr/local/nvidia/lib64/libc.so.6\r\n'
                                   '       452:      search cache=/etc/ld.so.cache\r\n'
                                   '       452:       trying '
                                   'file=/lib/x86_64-linux-gnu/libc.so.6\r\n'
                                   '       452:\r\n'
                                   '       452:\r\n'
                                   '       452:     calling init: '
                                   '/lib/x86_64-linux-gnu/libc.so.6\r\n'
                                   '       452:\r\n'
                                   '       452:\r\n'
                                   '       452:     initialize program: /bin/sh\r\n'
                                   '       452:\r\n'
                                   '       452:\r\n'
                                   '       452:     transferring control: /bin/sh\r\n'
                                   '       452:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5z.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5a.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5s.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5p.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5ac.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/_proxy.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5d.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5ds.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5f.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5g.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5i.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5fd.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5pl.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5o.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5l.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/_lib/_ccallback_c.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/sparse/_sparsetools.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/sparse/_csparsetools.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/sparse/csgraph/_shortest_path.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/sparse/csgraph/_tools.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/sparse/csgraph/_traversal.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/sparse/csgraph/_min_spanning_tree.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/sparse/csgraph/_reordering.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:     find '
                                   'library=libjpeg-3b10b538.so.9.3.0 [0]; searching\r\n'
                                   '       443:      search '
                                   'path=/usr/local/lib/python3.5/dist-packages/PIL/.libs/tls/x86_64:/usr/local/lib/python3.5/dist-packages/PIL/.libs/tls:/usr/local/lib/python3.5/dist-packages/PIL/.libs/x86_64:/usr/local/lib/python3.5/dist-packages/PIL/.libs            '
                                   '(RPATH from file '
                                   '/usr/local/lib/python3.5/dist-packages/PIL/_imaging.cpython-35m-x86_64-linux-gnu.so)\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/PIL/.libs/tls/x86_64/libjpeg-3b10b538.so.9.3.0\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/PIL/.libs/tls/libjpeg-3b10b538.so.9.3.0\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/PIL/.libs/x86_64/libjpeg-3b10b538.so.9.3.0\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/PIL/.libs/libjpeg-3b10b538.so.9.3.0\r\n'
                                   '       443:\r\n'
                                   '       443:     find '
                                   'library=libopenjp2-b3d7668a.so.2.3.1 [0]; '
                                   'searching\r\n'
                                   '       443:      search '
                                   'path=/usr/local/lib/python3.5/dist-packages/PIL/.libs           '
                                   '(RPATH from file '
                                   '/usr/local/lib/python3.5/dist-packages/PIL/_imaging.cpython-35m-x86_64-linux-gnu.so)\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/PIL/.libs/libopenjp2-b3d7668a.so.2.3.1\r\n'
                                   '       443:\r\n'
                                   '       443:     find '
                                   'library=libtiff-8267adfe.so.5.4.0 [0]; searching\r\n'
                                   '       443:      search '
                                   'path=/usr/local/lib/python3.5/dist-packages/PIL/.libs           '
                                   '(RPATH from file '
                                   '/usr/local/lib/python3.5/dist-packages/PIL/_imaging.cpython-35m-x86_64-linux-gnu.so)\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/PIL/.libs/libtiff-8267adfe.so.5.4.0\r\n'
                                   '       443:\r\n'
                                   '       443:     find '
                                   'library=liblzma-6cd627ed.so.5.2.4 [0]; searching\r\n'
                                   '       443:      search '
                                   'path=/usr/local/lib/python3.5/dist-packages/PIL/.libs/./tls/x86_64:/usr/local/lib/python3.5/dist-packages/PIL/.libs/./tls:/usr/local/lib/python3.5/dist-packages/PIL/.libs/./x86_64:/usr/local/lib/python3.5/dist-packages/PIL/.libs/.            '
                                   '(RPATH from file '
                                   '/usr/local/lib/python3.5/dist-packages/PIL/.libs/libtiff-8267adfe.so.5.4.0)\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/PIL/.libs/./tls/x86_64/liblzma-6cd627ed.so.5.2.4\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/PIL/.libs/./tls/liblzma-6cd627ed.so.5.2.4\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/PIL/.libs/./x86_64/liblzma-6cd627ed.so.5.2.4\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/PIL/.libs/./liblzma-6cd627ed.so.5.2.4\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/PIL/.libs/./liblzma-6cd627ed.so.5.2.4\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/PIL/.libs/libjpeg-3b10b538.so.9.3.0\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/PIL/.libs/libtiff-8267adfe.so.5.4.0\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/PIL/.libs/libopenjp2-b3d7668a.so.2.3.1\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/PIL/_imaging.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/ndimage/_nd_image.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/ndimage/_ni_label.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:     find '
                                   'library=libopenblasp-r0-2ecf47d5.3.7.dev.so [0]; '
                                   'searching\r\n'
                                   '       443:      search '
                                   'path=/usr/local/lib/python3.5/dist-packages/scipy/linalg/../.libs/tls/x86_64:/usr/local/lib/python3.5/dist-packages/scipy/linalg/../.libs/tls:/usr/local/lib/python3.5/dist-packages/scipy/linalg/../.libs/x86_64:/usr/local/lib/python3.5/dist-packages/scipy/linalg/../.libs            '
                                   '(RPATH from file '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/linalg/_fblas.cpython-35m-x86_64-linux-gnu.so)\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/scipy/linalg/../.libs/tls/x86_64/libopenblasp-r0-2ecf47d5.3.7.dev.so\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/scipy/linalg/../.libs/tls/libopenblasp-r0-2ecf47d5.3.7.dev.so\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/scipy/linalg/../.libs/x86_64/libopenblasp-r0-2ecf47d5.3.7.dev.so\r\n'
                                   '       443:       trying '
                                   'file=/usr/local/lib/python3.5/dist-packages/scipy/linalg/../.libs/libopenblasp-r0-2ecf47d5.3.7.dev.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/linalg/../.libs/libopenblasp-r0-2ecf47d5.3.7.dev.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/linalg/_fblas.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/linalg/_flapack.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/linalg/_flinalg.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/linalg/_solve_toeplitz.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/linalg/_decomp_update.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/linalg/cython_blas.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/linalg/cython_lapack.cpython-35m-x86_64-linux-gnu.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling init: '
                                   '/usr/local/lib/python3.5/dist-packages/tensorflow_core/lite/experimental/microfrontend/python/ops/_audio_microfrontend_op.so\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: /usr/local/bin/python '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/lib/x86_64-linux-gnu/libutil.so.1 [0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/lib/x86_64-linux-gnu/libexpat.so.1 [0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/lib/x86_64-linux-gnu/libz.so.1 [0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/lib/python3.5/lib-dynload/_opcode.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/core/_multiarray_umath.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/core/_multiarray_tests.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/linalg/lapack_lite.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/linalg/_umath_linalg.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/core/../.libs/libopenblasp-r0-34a18dc3.3.7.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/lib/python3.5/lib-dynload/_bz2.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/lib/x86_64-linux-gnu/libbz2.so.1.0 [0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/lib/python3.5/lib-dynload/_lzma.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/lib/x86_64-linux-gnu/liblzma.so.5 [0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/lib/python3.5/lib-dynload/_decimal.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/lib/x86_64-linux-gnu/libmpdec.so.2 [0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/fft/_pocketfft_internal.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/random/mtrand.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/random/common.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/random/bounded_integers.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/random/mt19937.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/random/bit_generator.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n' \
                                   '       443:     calling fini: ' \
                                   '/usr/lib/python3.5/lib-dynload/_hashlib.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n' \
                                   '       443:     calling fini: ' \
                                   '/usr/local/lib/python3.5/dist-packages/numpy/random/philox.cpython-35m-x86_64-linux-gnu.so ' \
                                   '[0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: ' \
                                   '/usr/local/lib/python3.5/dist-packages/numpy/random/pcg64.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: ' \
                                   '/usr/local/lib/python3.5/dist-packages/numpy/random/sfc64.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n' \
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/random/generator.cpython-35m-x86_64-linux-gnu.so ' \
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n' \
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so '
                                   '[0]\r\n' \
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/google/protobuf/internal/_api_implementation.cpython-35m-x86_64-linux-gnu.so ' \
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/google/protobuf/pyext/_message.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/lib/python3.5/lib-dynload/_csv.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n' \
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/lib/python3.5/lib-dynload/termios.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n' \
                                   '       443:     calling fini: ' \
                                   '/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/fast_tensor_util.so '
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/lib/x86_64-linux-gnu/libuuid.so.1 [0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: ' \
                                   '/usr/local/lib/python3.5/dist-packages/wrapt/_wrappers.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n' \
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/lib/python3.5/lib-dynload/_json.cpython-35m-x86_64-linux-gnu.so ' \
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: ' \
                                   '/usr/lib/python3.5/lib-dynload/_ssl.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/lib/x86_64-linux-gnu/libssl.so.1.0.0 [0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/lib/x86_64-linux-gnu/libcrypto.so.1.0.0 [0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/_errors.cpython-35m-x86_64-linux-gnu.so ' \
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n' \
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n' \
                                   '       443:     calling fini: ' \
                                   '/usr/local/lib/python3.5/dist-packages/h5py/defs.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n' \
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/_objects.cpython-35m-x86_64-linux-gnu.so ' \
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/_conv.cpython-35m-x86_64-linux-gnu.so ' \
                                   '[0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5r.cpython-35m-x86_64-linux-gnu.so ' \
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: ' \
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5t.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/utils.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n' \
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: ' \
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5z.cpython-35m-x86_64-linux-gnu.so ' \
                                   '[0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5a.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5s.cpython-35m-x86_64-linux-gnu.so ' \
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n' \
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5p.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: ' \
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5ac.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/_proxy.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n' \
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5d.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: ' \
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5ds.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: ' \
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5f.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5g.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5i.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5fd.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n' \
                                   '       443:     calling fini: ' \
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5pl.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n' \
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5o.cpython-35m-x86_64-linux-gnu.so ' \
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n' \
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/h5l.cpython-35m-x86_64-linux-gnu.so ' \
                                   '[0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n' \
                                   '       443:     calling fini: ' \
                                   '/usr/local/lib/python3.5/dist-packages/h5py/.libs/libhdf5_hl-db841637.so.100.1.1 '
                                   '[0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: ' \
                                   '/usr/local/lib/python3.5/dist-packages/h5py/.libs/libhdf5-49599f4e.so.103.0.0 ' \
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/.libs/./libsz-1c7dd0cf.so.2.0.1 ' \
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/.libs/./libaec-2147abcd.so.0.0.4 '
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/_lib/_ccallback_c.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n' \
                                   '       443:     calling fini: ' \
                                   '/usr/local/lib/python3.5/dist-packages/scipy/sparse/_sparsetools.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/sparse/_csparsetools.cpython-35m-x86_64-linux-gnu.so ' \
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/sparse/csgraph/_shortest_path.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/sparse/csgraph/_tools.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/sparse/csgraph/_traversal.cpython-35m-x86_64-linux-gnu.so ' \
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: ' \
                                   '/usr/local/lib/python3.5/dist-packages/scipy/sparse/csgraph/_min_spanning_tree.cpython-35m-x86_64-linux-gnu.so ' \
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n' \
                                   '       443:     calling fini: ' \
                                   '/usr/local/lib/python3.5/dist-packages/scipy/sparse/csgraph/_reordering.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/PIL/_imaging.cpython-35m-x86_64-linux-gnu.so ' \
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n' \
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/PIL/.libs/libopenjp2-b3d7668a.so.2.3.1 ' \
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/PIL/.libs/libtiff-8267adfe.so.5.4.0 '
                                   '[0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n' \
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/PIL/.libs/libjpeg-3b10b538.so.9.3.0 '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/h5py/.libs/./libz-a147dcb0.so.1.2.3 '
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: ' \
                                   '/usr/local/lib/python3.5/dist-packages/PIL/.libs/./liblzma-6cd627ed.so.5.2.4 '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/ndimage/_nd_image.cpython-35m-x86_64-linux-gnu.so ' \
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/ndimage/_ni_label.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/linalg/_fblas.cpython-35m-x86_64-linux-gnu.so ' \
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/linalg/_flapack.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: ' \
                                   '/usr/local/lib/python3.5/dist-packages/scipy/linalg/_flinalg.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n' \
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/linalg/_solve_toeplitz.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/linalg/_decomp_update.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/linalg/cython_blas.cpython-35m-x86_64-linux-gnu.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/linalg/cython_lapack.cpython-35m-x86_64-linux-gnu.so ' \
                                   '[0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n' \
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/scipy/linalg/../.libs/libopenblasp-r0-2ecf47d5.3.7.dev.so '
                                   '[0]\r\n' \
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/numpy/core/../.libs/libgfortran-ed201abd.so.3.0.0 ' \
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n' \
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/tensorflow_core/lite/experimental/microfrontend/python/ops/_audio_microfrontend_op.so '
                                   '[0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.2 '
                                   '[0]\r\n' \
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/usr/lib/x86_64-linux-gnu/libstdc++.so.6 [0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/lib/x86_64-linux-gnu/libgcc_s.so.1 [0]\r\n' \
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: ' \
                                   '/lib/x86_64-linux-gnu/librt.so.1 [0]\r\n'
                                   '       443:\r\n'
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/lib/x86_64-linux-gnu/libm.so.6 [0]\r\n'
                                   '       443:\r\n' \
                                   '       443:\r\n' \
                                   '       443:     calling fini: '
                                   '/lib/x86_64-linux-gnu/libdl.so.2 [0]\r\n' \
                                   '       443:\r\n' \
                                   '       443:\r\n'
                                   '       443:     calling fini: '
                                   '/lib/x86_64-linux-gnu/libpthread.so.0 [0]\r\n'
                                   '       443:\r\n' \
                                   '\r\n'
                                   '```',
                           'created_at': '2019-12-1'}],
            '2020-03-1': [{'body': '- adding example cwrapper which generates the '
                                   'projects with simple api\r\n'
                                   '- adding make library option to the makefile '
                                   'template\r\n'
                                   '- make project have the compiler path defined ' \
                                   'setting\r\n'
                                   '- adds a parser to pull out only the used ops from a ' \
                                   'tflite model',
                           'created_at': '2020-01-1'},
                          {'body': '**System information**\r\n' \
                                   '- Have I written custom code (as opposed to using a '
                                   'stock example script provided in TensorFlow): No\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Ubuntu 18.04\r\n' \
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device: No\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'source\r\n'
                                   '- TensorFlow version (use command below): 2.1.0\r\n' \
                                   '- Python version: 3.6.8\r\n' \
                                   '- Bazel version (if compiling from source): 0.29.1\r\n'
                                   '- GCC/Compiler version (if compiling from source): '
                                   'GCC 7.4.0\r\n' \
                                   '- CUDA/cuDNN version: 10.1,10.2 CuDNN 7\r\n'
                                   '- GPU model and memory: NVidia GTX 1080 Ti\r\n'
                                   '- TensorRT: version 6 or 7.\r\n' \
                                   '\r\n'
                                   '**Describe the current behavior**\r\n' \
                                   'Compiling from source, as indicated in the official '
                                   'tensorflow manual, compilation fails, with the error '
                                   'listed in the log below.\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   'Compilation should successfully complete\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   'No code needed. After a checkout of the current '
                                   'v.2.1.0, configuration is carried out with no changes '
                                   'from default (other than enabling CUDA). \r\n'
                                   '\r\n'
                                   '**Other info / logs**\r\n'
                                   'Log: see attached log.txt\r\n' \
                                   '[log.txt](https://github.com/tensorflow/tensorflow/files/4068010/log.txt)\r\n'
                                   '\r\n'
                                   '                                                                                                                                                   \r\n',
                           'created_at': '2020-01-1'},
                          {'body': '**System information**\r\n'
                                   '- Have I written custom code: Yes\r\n' \
                                   '- OS Platform and Distribution: Windows 10\r\n'
                                   '- TensorFlow installed from: binary\r\n'
                                   '- TensorFlow version: Same issue using '
                                   'tf2.0.0-beta1-cpu\r\n'
                                   ' and tf1.14.0-gpu\r\n'
                                   '- Python version: 3.6.9\r\n' \
                                   '- CUDA/cuDNN version: CUDA 10.1.168/cuDNN 7.6.2\r\n'
                                   '- GPU model and memory: NVIDIA GeForce RTX 2060, 6GB '
                                   'dedicated memory\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'A convolutional reggression (last layer has linear ' \
                                   'activation and one neuron) network built with ' \
                                   'tf.keras is shown to fit the MNIST dataset (I know ' \
                                   'that MNIST is a classification task; this is an '
                                   'example) when converted to a dataset.\r\n'
                                   '\r\n'
                                   'When the same model is packaged into an estimator ' \
                                   'using  `tf.keras.estimator.model_to_estimator` no ' \
                                   'error messages occur, however the model no longer '
                                   'fits. The loss does not decrease.\r\n'
                                   '\r\n' \
                                   'I had made a Stackoverflow question about this '
                                   '(https://stackoverflow.com/q/59631744/9988487) with ' \
                                   'no traction whatsoever. After some more trying to get '
                                   'it to work, I believe it is a bug.\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n' \
                                   'The keras estimator should have the same behaviour as '
                                   'the underlying model. Change the USE_ESTIMATOR '
                                   'variable to see that the underlying model works.\r\n' \
                                   '**Code to reproduce the issue**\r\n'
                                   '```\r\n' \
                                   '# python 3.6. Tested with tensorflow-gpu-1.14 and '
                                   'tensorflow-cpu-2.0\r\n'
                                   'import tensorflow as tf\r\n'
                                   'import numpy as np\r\n' \
                                   '\r\n'
                                   '\r\n'
                                   'def get_model(IM_WIDTH=28, num_color_channels=1):\r\n'
                                   '    """Create a very simple convolutional neural '
                                   'network using a tf.keras Functional Model."""\r\n'
                                   '    input = tf.keras.Input(shape=(IM_WIDTH, IM_WIDTH, '
                                   'num_color_channels))\r\n'
                                   '    x = tf.keras.layers.Conv2D(32, 3, '
                                   "activation='relu')(input)\r\n"
                                   '    x = tf.keras.layers.MaxPooling2D(3)(x)\r\n'
                                   '    x = tf.keras.layers.Conv2D(64, 3, '
                                   "activation='relu')(x)\r\n"
                                   '    x = tf.keras.layers.MaxPooling2D(3)(x)\r\n'
                                   '    x = tf.keras.layers.Flatten()(x)\r\n'
                                   '    x = tf.keras.layers.Dense(64, ' \
                                   "activation='relu')(x)\r\n"
                                   '    output = tf.keras.layers.Dense(1, '
                                   "activation='linear')(x)\r\n"
                                   '    model = tf.keras.Model(inputs=[input], ' \
                                   'outputs=[output])\r\n'
                                   '    model.compile(optimizer=\'adam\', loss="mae",\r\n'
                                   "                  metrics=['mae'])\r\n"
                                   '    model.summary()\r\n' \
                                   '    return model\r\n'
                                   '\r\n' \
                                   '\r\n'
                                   'def input_fun(train=True):\r\n'
                                   '    """Load MNIST and return the training or test set ' \
                                   'as a tf.data.Dataset; Valid input function for '
                                   'tf.estimator"""\r\n'
                                   '    (train_images, train_labels), (eval_images, '
                                   'eval_labels) = tf.keras.datasets.mnist.load_data()\r\n'
                                   '    train_images = train_images.reshape((60_000, 28, ' \
                                   '28, 1)).astype(np.float32) / 255.\r\n'
                                   '    eval_images = eval_images.reshape((10_000, 28, '
                                   '28, 1)).astype(np.float32) / 255.\r\n'
                                   '    # train_labels = train_labels.astype(np.float32)  '
                                   "# these two lines don't affect behaviour.\r\n"
                                   '    # eval_labels = eval_labels.astype(np.float32)\r\n'
                                   '    # For a neural network with one neuron in the ' \
                                   "final layer, it doesn't seem to matter if target data " \
                                   'is float or int.\r\n' \
                                   '\r\n'
                                   '    if train:\r\n' \
                                   '        dataset = ' \
                                   'tf.data.Dataset.from_tensor_slices((train_images, '
                                   'train_labels))\r\n'
                                   '        dataset = '
                                   'dataset.shuffle(buffer_size=100).repeat(None).batch(32).prefetch(1)\r\n'
                                   '    else:\r\n'
                                   '        dataset = ' \
                                   'tf.data.Dataset.from_tensor_slices((eval_images, '
                                   'eval_labels))\r\n'
                                   '        dataset = dataset.batch(32).prefetch(1)  # ' \
                                   'note: prefetching does not affect behaviour\r\n'
                                   '\r\n'
                                   '    return dataset\r\n'
                                   '\r\n' \
                                   '\r\n'
                                   'model = get_model()\r\n'
                                   'train_input_fn = lambda: input_fun(train=True)\r\n'
                                   'eval_input_fn = lambda: input_fun(train=False)\r\n'
                                   '\r\n'
                                   'NUM_EPOCHS, STEPS_PER_EPOCH = 4, 1875  # 1875 = ' \
                                   'number_of_train_images(=60.000)  /  ' \
                                   'batch_size(=32)\r\n' \
                                   'USE_ESTIMATOR = False  # change this to compare '
                                   'model/estimator. Estimator performs much worse for no '
                                   'apparent reason\r\n' \
                                   'if USE_ESTIMATOR:\r\n' \
                                   '    estimator = '
                                   'tf.keras.estimator.model_to_estimator(\r\n'
                                   '        keras_model=model, '
                                   'model_dir="model_directory",\r\n' \
                                   '        '
                                   'config=tf.estimator.RunConfig(save_checkpoints_steps=200, '
                                   'save_summary_steps=200))\r\n'
                                   '\r\n'
                                   '    train_spec = '
                                   'tf.estimator.TrainSpec(input_fn=train_input_fn, '
                                   'max_steps=STEPS_PER_EPOCH * NUM_EPOCHS)\r\n'
                                   '    eval_spec = ' \
                                   'tf.estimator.EvalSpec(input_fn=eval_input_fn, '
                                   'throttle_secs=0)\r\n'
                                   '\r\n'
                                   '    tf.estimator.train_and_evaluate(estimator, '
                                   'train_spec, eval_spec)\r\n'
                                   '    print("Training complete. Evaluating ' \
                                   'Estimator:")\r\n'
                                   '    print(estimator.evaluate(eval_input_fn))\r\n' \
                                   '    # final train loss with estimator: ~2.5 (mean '
                                   'abs. error).\r\n'
                                   'else:\r\n'
                                   '    dataset = train_input_fn()\r\n'
                                   '    model.fit(dataset, '
                                   'steps_per_epoch=STEPS_PER_EPOCH, ' \
                                   'epochs=NUM_EPOCHS)\r\n'
                                   '    print("Training complete. Evaluating Keras '
                                   'model:")\r\n'
                                   '    print(model.evaluate(eval_input_fn()))\r\n'
                                   '    # final train loss with Keras model: ~0.4 (mean '
                                   'abs. error).\r\n' \
                                   '```\r\n',
                           'created_at': '2020-01-1'},
                          {'body': '**System information**\r\n'
                                   '- Custom code (as opposed to using a stock example '
                                   'script provided in TensorFlow): Yes\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu ' \
                                   '16.04): Google Colab\r\n' \
                                   '- TensorFlow installed from (source or binary): use '
                                   'of `%tensorflow_version 2.x`\r\n' \
                                   '- TensorFlow version (use command below): ' \
                                   '2.1.0-rc1\r\n'
                                   '- Python version: 3.6.9\r\n'
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   '\r\n' \
                                   "I tried to run @huan's Google Colab Notebook " \
                                   'mentioned ' \
                                   '[here](https://stackoverflow.com/questions/55541881/how-to-convert-tf-keras-model-to-tpu-using-tensorflow-2-0-in-google-colab/55686370#55686370) '
                                   'and available '
                                   '[here](https://colab.research.google.com/github/huan/tensorflow-handbook-tpu/blob/master/tensorflow-handbook-tpu-example.ipynb). ' \
                                   'It raises the following error:\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   '---------------------------------------------------------------------------\r\n'
                                   'InternalError                             Traceback '
                                   '(most recent call last)\r\n'
                                   '<ipython-input-7-79d308ea228d> in <module>()\r\n'
                                   '      4   steps_per_epoch=60,\r\n'
                                   '      5   validation_data=(x_test.astype(np.float32), '
                                   'y_test.astype(np.float32)),\r\n'
                                   '----> 6   validation_freq=5\r\n'
                                   '      7 )\r\n'
                                   '      8 \r\n'
                                   '\r\n'
                                   '11 frames\r\n'
                                   '/usr/local/lib/python3.6/dist-packages/six.py in '
                                   'raise_from(value, from_value)\r\n'
                                   '\r\n'
                                   'InternalError: Assigned device '
                                   "'/job:worker/replica:0/task:0/device:TPU:0' does not "
                                   'have registered OpKernel support for _Arg\r\n'
                                   '\t [[{{node iteratorgetnext_iterator}}]] '
                                   '[Op:__inference_distributed_function_2822]\r\n'
                                   '```\r\n'
                                   '\r\n'
                                   'I tried `tf.compat.v1.disable_eager_execution()` as '
                                   'discussed '
                                   '[here](https://github.com/huan/tensorflow-handbook-tpu/issues/1) ' \
                                   "but it doesn't work:\r\n"
                                   '\r\n'
                                   '```\r\n'
                                   '---------------------------------------------------------------------------\r\n'
                                   'RuntimeError                              Traceback ' \
                                   '(most recent call last)\r\n'
                                   '<ipython-input-15-5118e7c1b79a> in <module>()\r\n'
                                   '      6   steps_per_epoch=60,\r\n'
                                   '      7   validation_data=(x_test.astype(np.float32), '
                                   'y_test.astype(np.float32)),\r\n'
                                   '----> 8   validation_freq=5\r\n' \
                                   '      9 )\r\n'
                                   '     10 \r\n'
                                   '\r\n'
                                   '25 frames\r\n'
                                   '/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py '
                                   'in convert_to_tensor(value, dtype, name, as_ref, ' \
                                   'preferred_dtype, dtype_hint, ctx, '
                                   'accepted_result_types)\r\n'
                                   '   1278       graph = get_default_graph()\r\n'
                                   '   1279       if not graph.building_function:\r\n'
                                   '-> 1280         raise RuntimeError("Attempting to '
                                   'capture an EagerTensor without "\r\n'
                                   '   1281                            "building a '
                                   'function.")\r\n'
                                   '   1282       return graph.capture(value, '
                                   'name=name)\r\n'
                                   '\r\n' \
                                   'RuntimeError: Attempting to capture an EagerTensor '
                                   'without building a function.\r\n' \
                                   '```\r\n'
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   '\r\n'
                                   "Not sure if @huan's example should be working given "
                                   'what he explained on '
                                   '[stackoverflow](https://stackoverflow.com/questions/55541881/how-to-convert-tf-keras-model-to-tpu-using-tensorflow-2-0-in-google-colab/55686370#55686370), '
                                   'but I think it should with TF 2.1.0 version.\r\n' \
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   "Again, @huan's work available "
                                   '[here](https://colab.research.google.com/github/huan/tensorflow-handbook-tpu/blob/master/tensorflow-handbook-tpu-example.ipynb).\r\n'
                                   '\r\n' \
                                   '**Other info / logs**\r\n'
                                   'I had the same issue with personal code and thought '
                                   'first it was due to `ImageDataGenerator` (see my last '
                                   'comment '
                                   '[here](https://github.com/tensorflow/tensorflow/issues/34346)), '
                                   "however it seems not to be as @huan's example doesn't " \
                                   'use it.\r\n'
                                   "I have the same issue on @huan's code with TF 2.1.0 "
                                   'installed with `!pip install tensorflow==2.1.0` in '
                                   'his notebook.', \
                           'created_at': '2020-01-1'},
                          {'body': '**System information**\r\n'
                                   '- Have I written custom code (as opposed to using a ' \
                                   'stock example script provided in TensorFlow):\r\n'
                                   'yes\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04):\r\n'
                                   'Windows 10\r\n' \
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device:\r\n'
                                   '- TensorFlow installed from (source or binary):\r\n' \
                                   'pip\r\n'
                                   '- TensorFlow version (use command below):\r\n' \
                                   'v2.0.0-rc2-26-g64c3d382ca 2.0.0\r\n'
                                   '- Python version: \r\n'
                                   '3.6.9\r\n' \
                                   '- Bazel version (if compiling from source):\r\n'
                                   '- GCC/Compiler version (if compiling from source):\r\n'
                                   '- CUDA/cuDNN version:\r\n'
                                   '10.0, 7.6.2\r\n' \
                                   '- GPU model and memory:\r\n' \
                                   'GeForce GTX 1070 and GeForce GTX 1080\r\n' \
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   'Crash when writing Checkpoint (or stuck when writing ' \
                                   'log for tensorboard)\r\n' \
                                   '\r\n'
                                   '**Describe the expected behavior**\r\n'
                                   'Write a checkpoint and a Tensorboardlog\r\n'
                                   '\r\n' \
                                   '**Code to reproduce the issue**\r\n' \
                                   '```\r\n'
                                   "os.environ['TF_CONFIG'] = json.dumps({\r\n"
                                   "    'cluster': {\r\n" \
                                   '        "worker": ["10.10.1.168:1234"],\r\n'
                                   '        \'chief\': ["10.10.1.60:2345"]\r\n'
                                   '    },\r\n'
                                   "    'task': {'type': 'chief', 'index': 0}\r\n" \
                                   '})\r\n'
                                   'strategy = '
                                   'tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\n'
                                   '\r\n'
                                   'def get_label(file_path, class_names):\r\n'
                                   '  parts = tf.strings.split(file_path, os.path.sep)\r\n' \
                                   '  return parts[-2] == class_names\r\n'
                                   '\r\n'
                                   'def parse_image(filename):\r\n' \
                                   '    parts = tf.strings.split(filename, "\\\\")\r\n'
                                   '    label = get_label(filename, CLASS_NAMES)\r\n'
                                   '    image = tf.io.read_file(filename)\r\n'
                                   '    image = tf.image.decode_png(image, channels=3)\r\n' \
                                   '    image = tf.image.convert_image_dtype(image, '
                                   'tf.float32)\r\n'
                                   '    image = tf.image.resize(image, [299,299])\r\n'
                                   '    return image, label\r\n'
                                   '\r\n' \
                                   'def make_dataset_unbatched():\r\n' \
                                   '    images_ds = list_ds.map(parse_image, '
                                   'num_parallel_calls=AUTOTUNE)\r\n'
                                   '    images_ds = images_ds.shuffle(BATCH_SIZE)\r\n'
                                   '    images_ds = images_ds.repeat(epochs)\r\n'
                                   '    images_ds = images_ds.prefetch(BUFFER_SIZE)\r\n'
                                   '    return images_ds\r\n'
                                   '\r\n'
                                   'datasetFilePath = "D:\\TrainData\\BalancedData"\r\n'
                                   'IMAGESIZE = 299\r\n'
                                   'AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n'
                                   'datasetPath = pathlib.Path(datasetFilePath)\r\n'
                                   'list_ds = '
                                   'tf.data.Dataset.list_files(str(datasetPath/"*/*"))\r\n'
                                   'num_elements = '
                                   'tf.data.experimental.cardinality(list_ds).numpy()\r\n'
                                   '\r\n'
                                   'CLASS_NAMES = np.array([item.name for item in '
                                   "datasetPath.glob('*')])\r\n"
                                   '\r\n'
                                   'epochs = 2\r\n'
                                   'def build_and_compile_model():\r\n'
                                   '    base_model '
                                   '=tf.keras.applications.InceptionV3(include_top=False, '
                                   'weights = "imagenet", input_shape=(299,299,3))\r\n'
                                   '\r\n'
                                   '    base_model.trainable = True\r\n'
                                   '    x = base_model.output\r\n'
                                   '    x = ' \
                                   'tf.keras.layers.GlobalAveragePooling2D(name="avg_pool")(x)\r\n'
                                   '    x = tf.keras.layers.Dense(256, '
                                   'activation="relu")(x)\r\n' \
                                   '    predictions = tf.keras.layers.Dense(2, '
                                   'activation="softmax")(x)\r\n'
                                   '    model = '
                                   'tf.keras.models.Model(inputs=base_model.input, ' \
                                   'outputs=predictions)\r\n'
                                   '\r\n'
                                   '    base_learning_rate = 0.00001\r\n'
                                   '    '
                                   'model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\r\n'
                                   '                 loss="categorical_crossentropy",\r\n' \
                                   '                 metrics=["accuracy"])\r\n'
                                   '    return model\r\n'
                                   'logdir = '
                                   'os.path.join("Z:\\Tensorflow\\TensorboardLogs", '
                                   'datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))\r\n' \
                                   'callbacks = '
                                   '[tf.keras.callbacks.ModelCheckpoint(filepath="Z:\\Tensorflow\\Checkpoints"), \r\n'
                                   '             tf.keras.callbacks.TensorBoard(logdir, '
                                   'histogram_freq=1)]\r\n'
                                   '\r\n' \
                                   'with strategy.scope():\r\n'
                                   '    dataset = '
                                   'make_dataset_unbatched().batch(BATCH_SIZE, '
                                   'drop_remainder=True)\r\n'
                                   '    multi_worker_model = build_and_compile_model()\r\n' \
                                   '\r\n'
                                   'history = multi_worker_model.fit(dataset, '
                                   'epochs=epochs, steps_per_epoch=50, '
                                   'callbacks=callbacks)\r\n' \
                                   '``` \r\n'
                                   '\r\n' \
                                   '**Other info / logs**\r\n' \
                                   '[ckpt_error.txt](https://github.com/tensorflow/tensorflow/files/4040557/ckpt_error.txt)\r\n'
                                   '\r\n'
                                   'This log happens with the checkpoint in the code, and '
                                   'with only the tensorboard-log as checkpoint the chief ' \
                                   'stops right at the end of the first epoch and nothing '
                                   'else happens.\r\n'
                                   '\r\n'
                                   'I hope someone can help me with this.\r\n',
                           'created_at': '2020-01-0'}, \
                          {'body': '<em>Please make sure that this is a '
                                   'build/installation issue. As per our [GitHub '
                                   'Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), ' \
                                   'we only address code/doc bugs, performance issues, ' \
                                   'feature requests and build/installation issues on '
                                   'GitHub. tag:build_template</em>\r\n'
                                   '\r\n'
                                   '**System information**\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): Windows 10\r\n' \
                                   '- Mobile device (e.g. iPhone 8, Pixel 2, Samsung '
                                   'Galaxy) if the issue happens on mobile device:\r\n' \
                                   '- TensorFlow installed from (source or binary): '
                                   'source\r\n'
                                   '- TensorFlow version: 2.0.0\r\n'
                                   '- Python version: 3.6.4\r\n'
                                   '- Installed using virtualenv? pip? conda?: pip\r\n' \
                                   '- Bazel version (if compiling from source): 0.26.1\r\n'
                                   '- GCC/Compiler version (if compiling from source):\r\n'
                                   '- CUDA/cuDNN version: 10/7\r\n' \
                                   '- GPU model and memory: NVIDIA GeForce MX150\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '**Describe the problem**\r\n' \
                                   'I am trying to build tensorflow with AVX2 '
                                   'instructions for my CPU to increase speeds, but bazel ' \
                                   'keeps failing when loading tensorflow\r\n' \
                                   '\r\n'
                                   '**Provide the exact sequence of commands / steps that '
                                   'you executed before running into the problem**\r\n'
                                   '1. Cloned the tensorflow source from github and ' \
                                   'checked out the r2.0 branch.\r\n'
                                   '2. Ran python ./configure.py\r\n'
                                   '3. Proceded through steps, selecting no for all other ' \
                                   'builds and set the bazel config option to '
                                   '/arch:AVC2\r\n'
                                   '4. Ran bazel build --config=opt '
                                   '//tensorflow/tools/pip_package:build_pip_package\r\n'
                                   '\r\n' \
                                   '**Any other info / logs**\r\n'
                                   'Include any logs or source code that would be helpful ' \
                                   'to diagnose the problem. If including tracebacks, '
                                   'please include the full traceback. Large logs and '
                                   'files should be attached.\r\n' \
                                   'The error text is attached here:\r\n'
                                   '[error.txt](https://github.com/tensorflow/tensorflow/files/4032375/error.txt)\r\n', \
                           'created_at': '2020-01-0'}, \
                          {'body': '**System information**\r\n' \
                                   '- Custom implementation of ALBERT for TF2.0\r\n'
                                   '- Training on DataBricks\r\n'
                                   '- TensorFlow installed from (source or binary): ' \
                                   'Binary pypi\r\n' \
                                   '- TensorFlow version (use command below): 2.0-gpu\r\n'
                                   '- Python version: 3.7\r\n'
                                   '- CUDA/cuDNN version: 10.1\r\n' \
                                   '- GPU model and memory: Databricks 4xGPU cluster '
                                   'X8\r\n' \
                                   '\r\n'
                                   '**Describe the current behavior**\r\n'
                                   '\r\n'
                                   'Current behavior: Training proceeds through 3 epochs ' \
                                   'and barfs on Train Step 399/1330 in the ' \
                                   '_save_checkpoint routine. We are using ADLSgen2 to '
                                   'store data, and we are mounting to that filesystem. '
                                   'Filesystem works transparently for all tasks so far & ' \
                                   'we have DataBricks team support. There are many '
                                   'read/writes to this mount point so I am not quick to '
                                   "blame the filesystem - but it's still worth "
                                   'noting.\r\n'
                                   '\r\n' \
                                   'The actual error is:\r\n'
                                   '2020-01-03 20:51:34.688654: W ' \
                                   'tensorflow/core/framework/op_kernel.cc:1622] '
                                   'OP_REQUIRES failed at save_restore_v2_ops.cc:137 : '
                                   'Invalid argument: '
                                   '/dbfs/mnt/devscoutprototype/eval_out/checkpoint/ctl_step_399.ckpt-3_temp_08f0418651184fbd97263e13fc11b45c/part-00001-of-00002.data-00000-of-00001.tempstate9461307533243821894; '
                                   'Invalid argument\r\n'
                                   '\r\n'
                                   'When we navigate to this location we find the folder '
                                   'is genuinely there, however inside that folder there ' \
                                   'is not this temp file. Instead there are two '
                                   'files:\r\n'
                                   '1)part-00000-of-00002.data-00000-of-00001\r\n'
                                   '2)part-00000-of-00002.index\r\n'
                                   '\r\n' \
                                   '**Describe the expected behavior**\r\n'
                                   '\r\n'
                                   'I would expect to see a new checkpoint at this '
                                   'step.\r\n'
                                   '\r\n'
                                   '**Code to reproduce the issue**\r\n'
                                   'This is made following the examples of ' \
                                   'https://github.com/kamalkraj/ALBERT-TF2.0\r\n'
                                   'If you simply run this example top to bottom on ' \
                                   'DataBricks you will encounter this error.\r\n'
                                   '\r\n' \
                                   '**Other info / logs**\r\n'
                                   '\r\n'
                                   'loss = 0.2804690897464752\r\n' \
                                   'I0103 20:48:47.790678 140033029736192 ' \
                                   'model_training_utils.py:346] Train Step: 396/1330  / '
                                   'loss = 0.3561434745788574\r\n'
                                   'I0103 20:48:50.499201 140033029736192 '
                                   'model_training_utils.py:346] Train Step: 397/1330  / ' \
                                   'loss = 0.26206889748573303\r\n' \
                                   'I0103 20:48:53.168039 140033029736192 '
                                   'model_training_utils.py:346] Train Step: 398/1330  / '
                                   'loss = 0.3312344551086426\r\n' \
                                   'I0103 20:48:55.838387 140033029736192 '
                                   'model_training_utils.py:346] Train Step: 399/1330  / '
                                   'loss = 0.41013699769973755\r\n'
                                   '2020-01-03 20:51:34.688654: W '
                                   'tensorflow/core/framework/op_kernel.cc:1622] '
                                   'OP_REQUIRES failed at save_restore_v2_ops.cc:137 : ' \
                                   'Invalid argument: '
                                   '/dbfs/mnt/devscoutprototype/eval_out/checkpoint/ctl_step_399.ckpt-3_temp_08f0418651184fbd97263e13fc11b45c/part-00001-of-00002.data-00000-of-00001.tempstate9461307533243821894; ' \
                                   'Invalid argument\r\n' \
                                   'Traceback (most recent call last):\r\n'
                                   '  File '
                                   '"/dbfs/mnt/devscoutprototype/ALBERT-TF2.0-master/run_classifer.py", '
                                   'line 455, in <module>\r\n'
                                   '    app.run(main)\r\n'
                                   '  File '
                                   '"/databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/absl/app.py", '
                                   'line 299, in run\r\n'
                                   '    _run_main(main, args)\r\n'
                                   '  File '
                                   '"/databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/absl/app.py", '
                                   'line 250, in _run_main\r\n'
                                   '    sys.exit(main(argv))\r\n'
                                   '  File '
                                   '"/dbfs/mnt/devscoutprototype/ALBERT-TF2.0-master/run_classifer.py", '
                                   'line 356, in main\r\n'
                                   '    custom_callbacks = custom_callbacks)\r\n'
                                   '  File '
                                   '"/dbfs/mnt/devscoutprototype/ALBERT-TF2.0-master/model_training_utils.py", '
                                   'line 354, in run_customized_training_loop\r\n'
                                   '    checkpoint_name.format(step=current_step))\r\n'
                                   '  File '
                                   '"/dbfs/mnt/devscoutprototype/ALBERT-TF2.0-master/model_training_utils.py", '
                                   'line 33, in _save_checkpoint\r\n'
                                   '    saved_path = checkpoint.save(checkpoint_path)\r\n'
                                   '  File '
                                   '"/databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py", '
                                   'line 1889, in save\r\n'
                                   '    file_path = self.write("%s-%d" % (file_prefix, '
                                   'checkpoint_number))\r\n' \
                                   '  File '
                                   '"/databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py", '
                                   'line 1819, in write\r\n'
                                   '    output = '
                                   'self._saver.save(file_prefix=file_prefix)\r\n'
                                   '  File '
                                   '"/databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py", '
                                   'line 1155, in save\r\n'
                                   '    file_prefix=file_prefix_tensor, '
                                   'object_graph_tensor=object_graph_tensor)\r\n'
                                   '  File '
                                   '"/databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py", ' \
                                   'line 1103, in _save_cached_when_graph_building\r\n'
                                   '    save_op = saver.save(file_prefix)\r\n'
                                   '  File '
                                   '"/databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py", '
                                   'line 230, in save\r\n'
                                   '    sharded_saves.append(saver.save(shard_prefix))\r\n'
                                   '  File ' \
                                   '"/databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py", '
                                   'line 72, in save\r\n' \
                                   '    return io_ops.save_v2(file_prefix, tensor_names, '
                                   'tensor_slices, tensors)\r\n'
                                   '  File '
                                   '"/databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_io_ops.py", '
                                   'line 1933, in save_v2\r\n'
                                   '    ctx=_ctx)\r\n' \
                                   '  File '
                                   '"/databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_io_ops.py", '
                                   'line 1970, in save_v2_eager_fallback\r\n'
                                   '    ctx=_ctx, name=name)\r\n'
                                   '  File '
                                   '"/databricks/conda/envs/databricks-ml-gpu/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py", '
                                   'line 67, in quick_execute\r\n'
                                   '    six.raise_from(core._status_to_exception(e.code, '
                                   'message), None)\r\n' \
                                   '  File "<string>", line 3, in raise_from\r\n'
                                   'tensorflow.python.framework.errors_impl.InvalidArgumentError: '
                                   '/dbfs/mnt/devscoutprototype/eval_out/checkpoint/ctl_step_399.ckpt-3_temp_08f0418651184fbd97263e13fc11b45c/part-00001-of-00002.data-00000-of-00001.tempstate9461307533243821894; '
                                   'Invalid argument [Op:SaveV2]\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '\r\n'
                                   '---------------------------------------------------------------------------\r\n'
                                   'CalledProcessError                        Traceback '
                                   '(most recent call last)\r\n'
                                   '<command-1805221645764486> in <module>\r\n' \
                                   "----> 1 get_ipython().run_cell_magic('sh', '', "
                                   '"\\n# Running classifier:\\n\\nexport '
                                   "GLUE_DIR='/dbfs/mnt/devscoutprototype/dataset/'\\nexport "
                                   "ALBERT_DIR='/dbfs/mnt/devscoutprototype/models/base_2/'\\nexport "
                                   "TASK_NAME='CoLA'\\nexport " \
                                   "OUTPUT_DIR='/dbfs/mnt/devscoutprototype/train_out'\\nexport "
                                   "MODEL_DIR='/dbfs/mnt/devscoutprototype/eval_out/'\\n\\npython "
                                   '/dbfs/mnt/devscoutprototype/ALBERT-TF2.0-master/run_classifer.py '
                                   '--train_data_path=${OUTPUT_DIR}/${TASK_NAME}_train.tf_record ' \
                                   '--eval_data_path=${OUTPUT_DIR}/${TASK_NAME}_eval.tf_record '
                                   '--input_meta_data_path=${OUTPUT_DIR}/${TASK_NAME}_meta_data '
                                   '--init_checkpoint=${ALBERT_DIR}/tf2_model.h5 '
                                   '--spm_model_file=${ALBERT_DIR}/vocab/30k-clean.model '
                                   '--albert_config_file=${ALBERT_DIR}/config.json '
                                   '--output_dir=${MODEL_DIR} --do_train '
                                   '--task_name=${TASK_NAME} --do_eval '
                                   '--custom_training_loop --train_batch_size=64 '
                                   '--learning_rate=1e-5 --num_train_epochs=10\\n")\r\n'
                                   '\r\n'
                                   '/databricks/python/lib/python3.7/site-packages/IPython/core/interactiveshell.py ' \
                                   'in run_cell_magic(self, magic_name, line, cell)\r\n'
                                   '   2350             with self.builtin_trap:\r\n'
                                   '   2351                 args = (magic_arg_s, cell)\r\n'
                                   '-> 2352                 result = fn(*args, '
                                   '**kwargs)\r\n'
                                   '   2353             return result\r\n' \
                                   '   2354 \r\n'
                                   '\r\n'
                                   '/databricks/python/lib/python3.7/site-packages/IPython/core/magics/script.py '
                                   'in named_script_magic(line, cell)\r\n'
                                   '    140             else:\r\n'
                                   '    141                 line = script\r\n'
                                   '--> 142             return self.shebang(line, '
                                   'cell)\r\n'
                                   '    143 \r\n'
                                   '    144         # write a basic docstring:\r\n'
                                   '\r\n'
                                   '</databricks/python/lib/python3.7/site-packages/decorator.py:decorator-gen-110> '
                                   'in shebang(self, line, cell)\r\n' \
                                   '\r\n'
                                   '/databricks/python/lib/python3.7/site-packages/IPython/core/magic.py '
                                   'in <lambda>(f, *a, **k)\r\n' \
                                   "    185     # but it's overkill for just that one bit "
                                   'of state.\r\n'
                                   '    186     def magic_deco(arg):\r\n' \
                                   '--> 187         call = lambda f, *a, **k: f(*a, '
                                   '**k)\r\n'
                                   '    188 \r\n' \
                                   '    189         if callable(arg):\r\n'
                                   '\r\n' \
                                   '/databricks/python/lib/python3.7/site-packages/IPython/core/magics/script.py '
                                   'in shebang(self, line, cell)\r\n'
                                   '    243             sys.stderr.flush()\r\n' \
                                   '    244         if args.raise_error and '
                                   'p.returncode!=0:\r\n'
                                   '--> 245             raise '
                                   'CalledProcessError(p.returncode, cell, output=out, ' \
                                   'stderr=err)\r\n'
                                   '    246 \r\n'
                                   '    247     def _run_script(self, p, cell, ' \
                                   'to_close):\r\n'
                                   '\r\n' \
                                   'CalledProcessError: Command \'b"\\n# Running '
                                   'classifier:\\n\\nexport '
                                   "GLUE_DIR='/dbfs/mnt/devscoutprototype/dataset/'\\nexport "
                                   "ALBERT_DIR='/dbfs/mnt/devscoutprototype/models/base_2/'\\nexport " \
                                   "TASK_NAME='CoLA'\\nexport "
                                   "OUTPUT_DIR='/dbfs/mnt/devscoutprototype/train_out'\\nexport "
                                   "MODEL_DIR='/dbfs/mnt/devscoutprototype/eval_out/'\\n\\npython "
                                   '/dbfs/mnt/devscoutprototype/ALBERT-TF2.0-master/run_classifer.py ',
                           'created_at': '2020-01-0'},
                          {'body': 'Got the following error output from Databricks; '
                                   'exported the notebook to the attached file; error '
                                   'occurs in cell 10.\r\n'
                                   '\r\n'
                                   'INFO:tensorflow:Converted call: <function '
                                   'read.<locals>.<lambda> at 0x7fbde97eae18>\r\n'
                                   "    args: (<tf.Tensor 'args_0:0' shape=() "
                                   'dtype=string>,)\r\n'
                                   '    kwargs: {}\r\n'
                                   '\r\n' \
                                   'INFO:tensorflow:Not whitelisted: <method-wrapper '
                                   "'__call__' of function object at 0x7fbde97eae18>: "
                                   'default rule\r\n'
                                   'INFO:tensorflow:Not whitelisted: <function '
                                   'read.<locals>.<lambda> at 0x7fbde97eae18>: default '
                                   'rule\r\n'
                                   'INFO:tensorflow:Entity <function ' \
                                   'read.<locals>.<lambda> at 0x7fbde97eae18> is not '
                                   'cached for key <code object <lambda> at '
                                   '0x7fbde9888f60, file "<command-608347>", line 138> '
                                   'subkey '
                                   '(<tensorflow.python.autograph.core.converter.ConversionOptions '
                                   "object at 0x7fbdddf7c0b8>, frozenset({'mean', "
                                   "'var'}))\r\n"
                                   'INFO:tensorflow:Converting <function ' \
                                   'read.<locals>.<lambda> at 0x7fbde97eae18>\r\n' \
                                   'INFO:tensorflow:Error transforming entity <function '
                                   'read.<locals>.<lambda> at 0x7fbde97eae18>\r\n'
                                   'Traceback (most recent call last):\r\n'
                                   '  File '
                                   '"/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/parser.py", '
                                   'line 78, in parse_entity\r\n'
                                   '    return parse_str(source, '
                                   'preamble_len=len(future_features)), source\r\n'
                                   '  File '
                                   '"/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/parser.py", '
                                   'line 139, in parse_str\r\n'
                                   '    module_node = gast.parse(src)\r\n'
                                   '  File '
                                   '"/databricks/python/lib/python3.7/site-packages/gast/gast.py", ' \
                                   'line 240, in parse\r\n'
                                   '    return ast_to_gast(_ast.parse(*args, '
                                   '**kwargs))\r\n' \
                                   '  File "/usr/lib/python3.7/ast.py", line 35, in '
                                   'parse\r\n'
                                   '    return compile(source, filename, mode, '
                                   'PyCF_ONLY_AST)\r\n'
                                   '  File "<unknown>", line 4\r\n'
                                   '    .map(lambda x: decode(x, mean, var))\r\n'
                                   '    ^\r\n'
                                   'SyntaxError: invalid syntax\r\n' \
                                   '\r\n'
                                   'During handling of the above exception, another '
                                   'exception occurred:\r\n' \
                                   '\r\n'
                                   'Traceback (most recent call last):\r\n'
                                   '  File ' \
                                   '"/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py", '
                                   'line 506, in converted_call\r\n'
                                   '    converted_f = conversion.convert(target_entity, '
                                   'program_ctx)\r\n' \
                                   '  File '
                                   '"/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py", '
                                   'line 322, in convert\r\n'
                                   '    free_nonglobal_var_names)\r\n' \
                                   '  File '
                                   '"/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py", '
                                   'line 240, in _convert_with_cache\r\n' \
                                   '    entity, program_ctx)\r\n' \
                                   '  File '
                                   '"/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py", '
                                   'line 469, in convert_entity_to_ast\r\n'
                                   '    nodes, name, entity_info = convert_func_to_ast(o, ' \
                                   'program_ctx)\r\n'
                                   '  File '
                                   '"/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py", '
                                   'line 630, in convert_func_to_ast\r\n'
                                   '    node, source = parser.parse_entity(f, ' \
                                   'future_features=future_features)\r\n' \
                                   '  File '
                                   '"/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/parser.py", '
                                   'line 118, in parse_entity\r\n'
                                   '    return parse_str(source, '
                                   'preamble_len=len(future_features)), source\r\n'
                                   '  File '
                                   '"/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/parser.py", '
                                   'line 145, in parse_str\r\n'
                                   "    raise ValueError('expected exactly one node node, "
                                   "found {}'.format(nodes))\r\n"
                                   'ValueError: expected exactly one node node, found ' \
                                   '[]\r\n'
                                   'WARNING:tensorflow:Entity <function ' \
                                   'read.<locals>.<lambda> at 0x7fbde97eae18> could not '
                                   'be transformed and will be executed as-is. Please '
                                   'report this to the AutoGraph\r\n' \
                                   ' team. When filing the bug, set the verbosity to 10 '
                                   '(on Linux, `export AUTOGRAPH_VERBOSITY=10`) and '
                                   'attach the full output. Cause: expected exactly one '
                                   'node node, found []\r\n'
                                   '[v2_compute_ndcg_geov4.02.ipynb.zip](https://github.com/tensorflow/tensorflow/files/4011226/v2_compute_ndcg_geov4.02.ipynb.zip)',
                           'created_at': '2019-12-3'},
                          {'body': 'Added usage examples for tf.math (subtract, ' \
                                   'scalar_mul, truediv, divide_no_nan, multiply_no_nan, '
                                   'floordiv, reduce_prod, reduce_min, reduce_max, '
                                   'sigmoid, log_sigmoid, unsorted_segmentation, '
                                   'unsorted_segment_sqrt_n, polyval)',
                           'created_at': '2019-12-2'},
                          {'body': '**System information**\r\n'
                                   '- OS Platform and Distribution (e.g., Linux Ubuntu '
                                   '16.04): MacOS 10.15.1\r\n'
                                   '- TensorFlow installed from (source or binary): '
                                   'binary\r\n'
                                   '- TensorFlow version (or github SHA if from source): '
                                   'tf-nightly==2.1.0.dev20191203\r\n'
                                   '\r\n'
                                   '**Command used to run the converter or code if youre ' \
                                   'using the Python API**\r\n'
                                   '\r\n'
                                   '```\r\n'
                                   'import pathlib\r\n' \
                                   '\r\n'
                                   'inpt = tf.keras.layers.Input(shape=[256, 256, 3])\r\n' \
                                   'out = tf.keras.layers.Lambda(lambda x: '
                                   'tf.keras.activations.softmax(x))(inpt)\r\n'
                                   'out = tf.keras.layers.Lambda(lambda x: '
                                   'tf.nn.softmax(x))(out)\r\n' \
                                   'model = tf.keras.Model(inpt, out)\r\n'
                                   '\r\n' \
                                   'converter = '
                                   'tf.lite.TFLiteConverter.from_keras_model(model)\r\n'
                                   'tflite_model = converter.convert()\r\n'
                                   "pathlib.Path('out.tflite').write_bytes(tflite_model)\r\n" \
                                   '```\r\n'
                                   '\r\n'
                                   '**Failure details**\r\n'
                                   '![image](https://user-images.githubusercontent.com/1422280/71025023-3904e880-20d4-11ea-95fb-29cfea49a44d.png)\r\n'
                                   'This graph shows the difference between the different '
                                   'softmax methods.  When using '
                                   '`tf.keras.activations.softmax`, there is '
                                   '[code](https://github.com/tensorflow/tensorflow/blob/v2.1.0-rc1/tensorflow/python/keras/activations.py#L43-L79) '
                                   'with a workaround for multiple dimensions.  It looks '
                                   'like this was written before the tensorflow op had '
                                   'multi-dimension support. ',
                           'created_at': '2019-12-1'},
                          {'body': "We've had feedback from multiple developers that it's "
                                   'hard to figure out how to calculate the right  int8 '
                                   'values for quantized inputs, and understand what int8 ' \
                                   'values mean as outputs.\r\n'
                                   '\r\n'
                                   'For example, when feeding an image to uint8 quantized '
                                   'inputs, the values can be left as in their source 0 '
                                   'to 255 range. For int8 inputs, the developer will '
                                   'typically need to subtract 128 from each value, but '
                                   'this knowledge (and how the offset value is '
                                   'calculated) is not documented. In the same way, users '
                                   'will need to map the -128 to 127 output values to the ' \
                                   'actual real number range of their outputs, but this '
                                   'process is unclear.\r\n'
                                   '\r\n'
                                   'Tagging the @tensorflow/micro team.',
                           'created_at': '2019-12-1'}]}
    content = bodies_process(test)
    pprint(content)
    import json

    f = open('./tesst_processed_pieces.txt', 'w')
    json.dump(content, f)
